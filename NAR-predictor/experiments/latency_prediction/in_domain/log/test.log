2024-04-05 12:46:17,020-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=3, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 12:46:17,020-main.py:76-INFO-Loading dataset:
2024-04-05 12:46:17,352-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-05 12:55:16,690-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=3, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 12:55:16,690-main.py:76-INFO-Loading dataset:
2024-04-05 12:57:54,973-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 16:59:03,579-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 16:59:03,580-main.py:76-INFO-Loading dataset:
2024-04-05 16:59:05,802-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 16:59:07,110-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 16:59:07,111-main.py:109-INFO-Loading model:
2024-04-05 16:59:07,112-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:00:50,155-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:00:50,155-main.py:76-INFO-Loading dataset:
2024-04-05 17:00:52,374-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:00:53,161-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 17:00:53,162-main.py:109-INFO-Loading model:
2024-04-05 17:00:53,163-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:01:35,159-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:01:35,160-main.py:76-INFO-Loading dataset:
2024-04-05 17:01:37,358-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:01:38,126-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 17:01:38,127-main.py:109-INFO-Loading model:
2024-04-05 17:01:38,128-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:01:38,147-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:06:15,725-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:06:15,725-main.py:76-INFO-Loading dataset:
2024-04-05 17:06:18,097-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:06:18,863-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 17:06:18,863-main.py:109-INFO-Loading model:
2024-04-05 17:06:18,865-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:06:18,872-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:07:01,990-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:07:01,990-main.py:76-INFO-Loading dataset:
2024-04-05 17:09:47,202-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:09:47,997-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 17:09:47,998-main.py:109-INFO-Loading model:
2024-04-05 17:09:47,998-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:09:48,005-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:21:33,585-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=1, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:21:33,585-main.py:76-INFO-Loading dataset:
2024-04-05 17:21:35,795-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:21:48,063-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:21:48,063-main.py:76-INFO-Loading dataset:
2024-04-05 17:21:50,166-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:21:50,940-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 17:21:50,940-main.py:109-INFO-Loading model:
2024-04-05 17:21:50,941-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:21:50,948-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:28:58,651-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:28:58,651-main.py:76-INFO-Loading dataset:
2024-04-05 17:29:00,751-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:29:01,511-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 17:29:01,512-main.py:109-INFO-Loading model:
2024-04-05 17:29:01,513-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:29:01,520-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:31:54,931-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:31:54,931-main.py:76-INFO-Loading dataset:
2024-04-05 17:31:57,018-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 17:31:57,761-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 17:31:57,762-main.py:109-INFO-Loading model:
2024-04-05 17:31:57,765-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:31:57,773-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 17:52:42,537-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 17:52:42,537-main.py:76-INFO-Loading dataset:
2024-04-05 18:00:10,545-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 18:00:11,340-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 18:00:11,340-main.py:109-INFO-Loading model:
2024-04-05 18:00:11,342-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 18:00:11,348-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 18:00:27,925-main.py:458-INFO- ------------------------------------------------------------------
2024-04-05 18:00:27,925-main.py:459-INFO- * Speed: 8264.11247 ms/iter
2024-04-05 18:00:27,925-main.py:460-INFO- * MAPE: 0.12323
2024-04-05 18:00:27,926-main.py:461-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-05 18:00:27,926-main.py:462-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-05 18:00:27,926-main.py:463-INFO- ------------------------------------------------------------------
2024-04-05 18:00:27,926-main.py:466-INFO- Average Latency : 7871.85275555 ms
2024-04-05 19:08:17,535-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-05 19:08:17,535-main.py:76-INFO-Loading dataset:
2024-04-05 19:08:19,642-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-05 19:08:20,488-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-05 19:08:20,489-main.py:109-INFO-Loading model:
2024-04-05 19:08:20,490-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-05 19:08:20,497-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-05 19:08:36,980-main.py:458-INFO- ------------------------------------------------------------------
2024-04-05 19:08:36,980-main.py:459-INFO- * Speed: 8216.77065 ms/iter
2024-04-05 19:08:36,980-main.py:460-INFO- * MAPE: 0.12323
2024-04-05 19:08:36,981-main.py:461-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-05 19:08:36,981-main.py:462-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-05 19:08:36,981-main.py:463-INFO- ------------------------------------------------------------------
2024-04-05 19:08:36,981-main.py:466-INFO- Average Latency : 7833.70399475 ms
2024-04-06 10:46:22,572-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-06 10:46:23,205-main.py:76-INFO-Loading dataset:
2024-04-06 10:46:27,076-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-06 10:46:28,356-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-06 10:46:28,357-main.py:109-INFO-Loading model:
2024-04-06 10:46:28,358-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-06 10:46:28,378-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-06 10:46:46,929-main.py:458-INFO- ------------------------------------------------------------------
2024-04-06 10:46:46,930-main.py:459-INFO- * Speed: 9215.80791 ms/iter
2024-04-06 10:46:46,930-main.py:460-INFO- * MAPE: 0.12323
2024-04-06 10:46:46,930-main.py:461-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-06 10:46:46,930-main.py:462-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-06 10:46:46,930-main.py:463-INFO- ------------------------------------------------------------------
2024-04-06 10:46:46,930-main.py:466-INFO- Average Latency : 7607.45859146 ms
2024-04-06 10:59:32,889-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-06 10:59:32,889-main.py:76-INFO-Loading dataset:
2024-04-06 10:59:35,348-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-06 10:59:36,087-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-06 10:59:36,088-main.py:109-INFO-Loading model:
2024-04-06 10:59:36,091-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-06 10:59:36,097-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-06 10:59:55,758-main.py:458-INFO- ------------------------------------------------------------------
2024-04-06 10:59:55,759-main.py:459-INFO- * Speed: 9807.49345 ms/iter
2024-04-06 10:59:55,759-main.py:460-INFO- * MAPE: 0.12323
2024-04-06 10:59:55,759-main.py:461-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-06 10:59:55,759-main.py:462-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-06 10:59:55,759-main.py:463-INFO- ------------------------------------------------------------------
2024-04-06 10:59:55,759-main.py:466-INFO- Average Latency : 9471.10521793 ms
2024-04-06 18:03:50,125-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-06 18:03:50,125-main.py:76-INFO-Loading dataset:
2024-04-06 18:03:52,608-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-06 18:03:53,403-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-06 18:03:53,404-main.py:109-INFO-Loading model:
2024-04-06 18:03:53,406-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:03:53,413-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:04:09,257-main.py:458-INFO- ------------------------------------------------------------------
2024-04-06 18:04:09,257-main.py:459-INFO- * Speed: 7898.19407 ms/iter
2024-04-06 18:04:09,258-main.py:460-INFO- * MAPE: 0.12323
2024-04-06 18:04:09,258-main.py:461-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-06 18:04:09,258-main.py:462-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-06 18:04:09,258-main.py:463-INFO- ------------------------------------------------------------------
2024-04-06 18:04:09,258-main.py:466-INFO- Average Latency : 7527.23538876 ms
2024-04-06 18:10:27,751-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-06 18:10:27,752-main.py:76-INFO-Loading dataset:
2024-04-06 18:10:30,241-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-06 18:10:31,028-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-06 18:10:31,029-main.py:109-INFO-Loading model:
2024-04-06 18:10:31,033-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:10:31,045-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:11:33,770-main.py:458-INFO- ------------------------------------------------------------------
2024-04-06 18:11:33,770-main.py:459-INFO- * Speed: 31339.83684 ms/iter
2024-04-06 18:11:33,771-main.py:460-INFO- * MAPE: 0.12323
2024-04-06 18:11:33,771-main.py:461-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-06 18:11:33,771-main.py:462-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-06 18:11:33,771-main.py:463-INFO- ------------------------------------------------------------------
2024-04-06 18:11:33,771-main.py:466-INFO- Average Latency : 7486.89532280 ms
2024-04-06 18:11:43,010-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-06 18:11:43,011-main.py:76-INFO-Loading dataset:
2024-04-06 18:11:45,485-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-06 18:11:46,249-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-06 18:11:46,249-main.py:109-INFO-Loading model:
2024-04-06 18:11:46,253-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:11:46,262-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:12:01,980-main.py:459-INFO- ------------------------------------------------------------------
2024-04-06 18:12:01,980-main.py:460-INFO- * Speed: 7834.75852 ms/iter
2024-04-06 18:12:01,981-main.py:461-INFO- * MAPE: 0.12323
2024-04-06 18:12:01,981-main.py:462-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-06 18:12:01,981-main.py:463-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-06 18:12:01,981-main.py:464-INFO- ------------------------------------------------------------------
2024-04-06 18:12:01,981-main.py:467-INFO- Average Latency : 7473.68144989 ms
2024-04-06 18:24:43,855-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-06 18:24:43,855-main.py:76-INFO-Loading dataset:
2024-04-06 18:24:46,359-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-06 18:24:47,126-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-06 18:24:47,127-main.py:109-INFO-Loading model:
2024-04-06 18:24:47,131-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:24:47,142-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:25:03,073-main.py:459-INFO- ------------------------------------------------------------------
2024-04-06 18:25:03,073-main.py:460-INFO- * Speed: 7942.70849 ms/iter
2024-04-06 18:25:03,074-main.py:461-INFO- * MAPE: 0.12323
2024-04-06 18:25:03,074-main.py:462-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-06 18:25:03,074-main.py:463-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-06 18:25:03,074-main.py:464-INFO- ------------------------------------------------------------------
2024-04-06 18:25:03,074-main.py:467-INFO- Average Latency : 7571.96307182 ms
2024-04-06 18:28:30,082-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-06 18:28:30,082-main.py:76-INFO-Loading dataset:
2024-04-06 18:28:32,636-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-06 18:28:33,412-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-06 18:28:33,413-main.py:109-INFO-Loading model:
2024-04-06 18:28:33,416-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:28:33,422-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-06 18:28:49,036-main.py:459-INFO- ------------------------------------------------------------------
2024-04-06 18:28:49,036-main.py:460-INFO- * Speed: 7784.17277 ms/iter
2024-04-06 18:28:49,037-main.py:461-INFO- * MAPE: 0.12323
2024-04-06 18:28:49,037-main.py:462-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-06 18:28:49,037-main.py:463-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-06 18:28:49,037-main.py:464-INFO- ------------------------------------------------------------------
2024-04-06 18:28:49,037-main.py:467-INFO- Average Latency : 7437.68084049 ms
2024-04-08 14:06:10,598-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 14:06:10,599-main.py:76-INFO-Loading dataset:
2024-04-08 14:06:13,625-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-08 14:06:14,911-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-08 14:06:14,912-main.py:109-INFO-Loading model:
2024-04-08 14:06:14,913-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-08 14:06:14,931-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-08 14:06:32,552-main.py:459-INFO- ------------------------------------------------------------------
2024-04-08 14:06:32,552-main.py:460-INFO- * Speed: 8747.83862 ms/iter
2024-04-08 14:06:32,552-main.py:461-INFO- * MAPE: 0.12323
2024-04-08 14:06:32,552-main.py:462-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-08 14:06:32,552-main.py:463-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-08 14:06:32,552-main.py:464-INFO- ------------------------------------------------------------------
2024-04-08 14:06:32,553-main.py:467-INFO- Average Latency : 7650.27070045 ms
2024-04-08 19:02:14,172-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 19:02:14,173-main.py:76-INFO-Loading dataset:
2024-04-08 19:02:16,482-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-08 19:02:17,249-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-08 19:02:17,249-main.py:109-INFO-Loading model:
2024-04-08 19:02:17,250-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-08 19:02:17,257-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-08 19:02:32,923-main.py:461-INFO- ------------------------------------------------------------------
2024-04-08 19:02:32,924-main.py:462-INFO- * Speed: 7809.51822 ms/iter
2024-04-08 19:02:32,924-main.py:463-INFO- * MAPE: 0.12323
2024-04-08 19:02:32,924-main.py:464-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-08 19:02:32,924-main.py:465-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-08 19:02:32,924-main.py:466-INFO- ------------------------------------------------------------------
2024-04-08 19:02:32,924-main.py:469-INFO- Average Latency : 7439.88156319 ms
2024-04-08 19:03:24,914-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 19:03:24,914-main.py:76-INFO-Loading dataset:
2024-04-08 19:10:49,556-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-04-08 19:10:50,304-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-08 19:10:50,305-main.py:109-INFO-Loading model:
2024-04-08 19:10:50,306-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-08 19:10:50,312-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-08 19:11:06,025-main.py:461-INFO- ------------------------------------------------------------------
2024-04-08 19:11:06,025-main.py:462-INFO- * Speed: 7834.05793 ms/iter
2024-04-08 19:11:06,026-main.py:463-INFO- * MAPE: 0.12323
2024-04-08 19:11:06,026-main.py:464-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-04-08 19:11:06,026-main.py:465-INFO- * Kendall's Tau: 0.8620518965916852
2024-04-08 19:11:06,026-main.py:466-INFO- ------------------------------------------------------------------
2024-04-08 19:11:06,026-main.py:469-INFO- Average Latency : 7495.01216412 ms
2024-04-08 22:50:45,716-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1024, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 22:50:45,716-main.py:76-INFO-Loading dataset:
2024-04-08 22:50:46,134-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 22:52:56,475-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 22:52:56,475-main.py:76-INFO-Loading dataset:
2024-04-08 22:52:56,889-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 22:53:30,834-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 22:53:30,834-main.py:76-INFO-Loading dataset:
2024-04-08 22:53:31,249-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 23:03:00,137-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 23:03:00,137-main.py:76-INFO-Loading dataset:
2024-04-08 23:03:00,555-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 23:04:47,554-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 23:04:47,554-main.py:76-INFO-Loading dataset:
2024-04-08 23:04:47,885-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 23:05:09,458-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 23:05:09,459-main.py:76-INFO-Loading dataset:
2024-04-08 23:05:09,882-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 23:20:54,790-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 23:20:54,790-main.py:76-INFO-Loading dataset:
2024-04-08 23:21:00,886-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 23:27:17,648-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 23:27:17,649-main.py:76-INFO-Loading dataset:
2024-04-08 23:27:18,075-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-08 23:33:59,127-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-08 23:33:59,128-main.py:76-INFO-Loading dataset:
2024-04-08 23:33:59,555-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-09 11:22:09,564-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-09 11:22:09,565-main.py:76-INFO-Loading dataset:
2024-04-09 11:22:09,992-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-30 12:04:04,913-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 12:04:04,913-main.py:76-INFO-Loading dataset:
2024-04-30 12:04:05,346-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-30 12:15:48,374-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 12:15:48,374-main.py:76-INFO-Loading dataset:
2024-04-30 12:15:48,712-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-30 12:15:53,355-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 12:15:53,355-main.py:76-INFO-Loading dataset:
2024-04-30 12:15:53,701-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-30 12:16:36,826-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 12:16:36,826-main.py:76-INFO-Loading dataset:
2024-04-30 12:16:37,159-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-30 12:37:10,048-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 12:37:10,048-main.py:76-INFO-Loading dataset:
2024-04-30 12:37:10,377-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-30 12:47:14,630-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 12:47:14,630-main.py:76-INFO-Loading dataset:
2024-04-30 12:47:14,954-main.py:274-INFO-Train data = 0, Test data = 0
2024-04-30 13:16:57,285-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 13:16:57,285-main.py:76-INFO-Loading dataset:
2024-04-30 13:16:57,626-main.py:274-INFO-Train data = 0, Test data = 1
2024-04-30 13:18:02,676-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 13:18:02,676-main.py:76-INFO-Loading dataset:
2024-04-30 13:18:03,015-main.py:274-INFO-Train data = 0, Test data = 1
2024-04-30 13:24:25,340-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 13:24:25,340-main.py:76-INFO-Loading dataset:
2024-04-30 13:24:25,668-main.py:274-INFO-Train data = 0, Test data = 1
2024-04-30 13:24:45,796-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 13:24:45,797-main.py:76-INFO-Loading dataset:
2024-04-30 13:24:46,131-main.py:274-INFO-Train data = 1, Test data = 1
2024-04-30 13:24:47,422-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-30 13:24:47,422-main.py:109-INFO-Loading model:
2024-04-30 13:24:47,424-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:24:47,443-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:24:48,406-main.py:461-INFO- ------------------------------------------------------------------
2024-04-30 13:24:48,406-main.py:462-INFO- * Speed: 838.59921 ms/iter
2024-04-30 13:24:48,407-main.py:463-INFO- * MAPE: 0.73813
2024-04-30 13:24:48,407-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-04-30 13:24:48,407-main.py:465-INFO- * Kendall's Tau: nan
2024-04-30 13:24:48,408-main.py:466-INFO- ------------------------------------------------------------------
2024-04-30 13:24:48,408-main.py:469-INFO- Average Latency : 825.59919357 ms
2024-04-30 13:34:51,944-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 13:34:51,944-main.py:76-INFO-Loading dataset:
2024-04-30 13:34:52,276-main.py:274-INFO-Train data = 1, Test data = 1
2024-04-30 13:34:53,049-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-30 13:34:53,049-main.py:109-INFO-Loading model:
2024-04-30 13:34:53,052-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:34:53,059-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:34:53,487-main.py:461-INFO- ------------------------------------------------------------------
2024-04-30 13:34:53,487-main.py:462-INFO- * Speed: 370.69082 ms/iter
2024-04-30 13:34:53,487-main.py:463-INFO- * MAPE: 0.73813
2024-04-30 13:34:53,487-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-04-30 13:34:53,487-main.py:465-INFO- * Kendall's Tau: nan
2024-04-30 13:34:53,488-main.py:466-INFO- ------------------------------------------------------------------
2024-04-30 13:34:53,488-main.py:469-INFO- Average Latency : 368.69096756 ms
2024-04-30 13:47:11,924-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 13:47:11,924-main.py:76-INFO-Loading dataset:
2024-04-30 13:47:12,262-main.py:274-INFO-Train data = 1, Test data = 1
2024-04-30 13:47:13,024-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-30 13:47:13,025-main.py:109-INFO-Loading model:
2024-04-30 13:47:13,027-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:47:13,034-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:47:13,448-main.py:461-INFO- ------------------------------------------------------------------
2024-04-30 13:47:13,448-main.py:462-INFO- * Speed: 362.99968 ms/iter
2024-04-30 13:47:13,448-main.py:463-INFO- * MAPE: 0.73813
2024-04-30 13:47:13,448-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-04-30 13:47:13,448-main.py:465-INFO- * Kendall's Tau: nan
2024-04-30 13:47:13,449-main.py:466-INFO- ------------------------------------------------------------------
2024-04-30 13:47:13,449-main.py:469-INFO- Average Latency : 360.99982262 ms
2024-04-30 13:55:06,886-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 13:55:06,886-main.py:76-INFO-Loading dataset:
2024-04-30 13:55:07,210-main.py:274-INFO-Train data = 1, Test data = 1
2024-04-30 13:55:07,970-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-30 13:55:07,971-main.py:109-INFO-Loading model:
2024-04-30 13:55:07,973-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:55:07,980-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-30 13:55:08,405-main.py:461-INFO- ------------------------------------------------------------------
2024-04-30 13:55:08,405-main.py:462-INFO- * Speed: 368.99972 ms/iter
2024-04-30 13:55:08,405-main.py:463-INFO- * MAPE: 0.73813
2024-04-30 13:55:08,405-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-04-30 13:55:08,406-main.py:465-INFO- * Kendall's Tau: nan
2024-04-30 13:55:08,406-main.py:466-INFO- ------------------------------------------------------------------
2024-04-30 13:55:08,406-main.py:469-INFO- Average Latency : 366.00017548 ms
2024-04-30 14:04:19,581-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-04-30 14:04:19,582-main.py:76-INFO-Loading dataset:
2024-04-30 14:04:19,924-main.py:274-INFO-Train data = 1, Test data = 2
2024-04-30 14:04:20,686-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-04-30 14:04:20,686-main.py:109-INFO-Loading model:
2024-04-30 14:04:20,689-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-04-30 14:04:20,696-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-04-30 14:04:21,116-main.py:461-INFO- ------------------------------------------------------------------
2024-04-30 14:04:21,116-main.py:462-INFO- * Speed: 186.46026 ms/iter
2024-04-30 14:04:21,116-main.py:463-INFO- * MAPE: 0.73768
2024-04-30 14:04:21,117-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-04-30 14:04:21,117-main.py:465-INFO- * Kendall's Tau: nan
2024-04-30 14:04:21,117-main.py:466-INFO- ------------------------------------------------------------------
2024-04-30 14:04:21,117-main.py:469-INFO- Average Latency : 184.46040154 ms
2024-05-07 10:08:03,346-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:08:03,346-main.py:76-INFO-Loading dataset:
2024-05-07 10:08:03,725-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-07 10:08:05,018-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:08:05,018-main.py:109-INFO-Loading model:
2024-05-07 10:08:05,020-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:08:05,037-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:08:05,859-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:08:05,859-main.py:462-INFO- * Speed: 231.53647 ms/iter
2024-05-07 10:08:05,859-main.py:463-INFO- * MAPE: 0.73457
2024-05-07 10:08:05,859-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:08:05,860-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 10:08:05,860-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:08:05,860-main.py:469-INFO- Average Latency : 224.86948967 ms
2024-05-07 10:15:04,382-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:15:04,382-main.py:76-INFO-Loading dataset:
2024-05-07 10:15:04,711-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-07 10:15:05,494-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:15:05,495-main.py:109-INFO-Loading model:
2024-05-07 10:15:05,496-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:15:05,502-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:15:05,923-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:15:05,923-main.py:462-INFO- * Speed: 124.66645 ms/iter
2024-05-07 10:15:05,924-main.py:463-INFO- * MAPE: 0.73457
2024-05-07 10:15:05,924-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:15:05,924-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 10:15:05,924-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:15:05,924-main.py:469-INFO- Average Latency : 122.99982707 ms
2024-05-07 10:15:34,553-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:15:34,554-main.py:76-INFO-Loading dataset:
2024-05-07 10:15:34,904-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-07 10:15:35,673-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:15:35,673-main.py:109-INFO-Loading model:
2024-05-07 10:15:35,674-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:15:35,681-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:15:36,099-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:15:36,099-main.py:462-INFO- * Speed: 123.24913 ms/iter
2024-05-07 10:15:36,100-main.py:463-INFO- * MAPE: 0.65788
2024-05-07 10:15:36,100-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:15:36,100-main.py:465-INFO- * Kendall's Tau: -0.816496580927726
2024-05-07 10:15:36,100-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:15:36,100-main.py:469-INFO- Average Latency : 122.24912643 ms
2024-05-07 10:16:24,999-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:16:24,999-main.py:76-INFO-Loading dataset:
2024-05-07 10:16:25,340-main.py:274-INFO-Train data = 1, Test data = 1
2024-05-07 10:16:26,096-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:16:26,096-main.py:109-INFO-Loading model:
2024-05-07 10:16:26,097-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:16:26,104-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:16:26,525-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:16:26,526-main.py:462-INFO- * Speed: 371.99974 ms/iter
2024-05-07 10:16:26,526-main.py:463-INFO- * MAPE: 0.49829
2024-05-07 10:16:26,526-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:16:26,527-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 10:16:26,527-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:16:26,527-main.py:469-INFO- Average Latency : 368.99971962 ms
2024-05-07 10:18:11,328-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:18:11,329-main.py:76-INFO-Loading dataset:
2024-05-07 10:18:11,700-main.py:274-INFO-Train data = 1, Test data = 1
2024-05-07 10:18:12,464-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:18:12,465-main.py:109-INFO-Loading model:
2024-05-07 10:18:12,466-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:18:12,472-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:18:12,896-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:18:12,896-main.py:462-INFO- * Speed: 376.28341 ms/iter
2024-05-07 10:18:12,896-main.py:463-INFO- * MAPE: 0.49829
2024-05-07 10:18:12,897-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:18:12,897-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 10:18:12,897-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:18:12,897-main.py:469-INFO- Average Latency : 373.28386307 ms
2024-05-07 10:21:01,828-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:21:01,828-main.py:76-INFO-Loading dataset:
2024-05-07 10:21:02,162-main.py:274-INFO-Train data = 1, Test data = 0
2024-05-07 10:21:02,922-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:21:02,922-main.py:109-INFO-Loading model:
2024-05-07 10:21:02,923-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:21:02,930-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:21:28,118-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:21:28,118-main.py:76-INFO-Loading dataset:
2024-05-07 10:21:28,445-main.py:274-INFO-Train data = 1, Test data = 0
2024-05-07 10:21:29,205-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:21:29,205-main.py:109-INFO-Loading model:
2024-05-07 10:21:29,206-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:21:29,213-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:22:52,690-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:22:52,691-main.py:76-INFO-Loading dataset:
2024-05-07 10:23:34,855-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:23:34,855-main.py:76-INFO-Loading dataset:
2024-05-07 10:23:35,197-main.py:274-INFO-Train data = 1, Test data = 2
2024-05-07 10:23:35,956-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:23:35,957-main.py:109-INFO-Loading model:
2024-05-07 10:23:35,958-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:23:35,965-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:23:36,390-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:23:36,390-main.py:462-INFO- * Speed: 186.75685 ms/iter
2024-05-07 10:23:36,390-main.py:463-INFO- * MAPE: 0.49829
2024-05-07 10:23:36,390-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:23:36,390-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 10:23:36,390-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:23:36,391-main.py:469-INFO- Average Latency : 184.75139141 ms
2024-05-07 10:36:30,999-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:36:30,999-main.py:76-INFO-Loading dataset:
2024-05-07 10:36:31,346-main.py:274-INFO-Train data = 2, Test data = 1
2024-05-07 10:36:32,100-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:36:32,100-main.py:109-INFO-Loading model:
2024-05-07 10:36:32,101-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:36:32,108-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:36:32,531-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:36:32,531-main.py:462-INFO- * Speed: 376.31297 ms/iter
2024-05-07 10:36:32,531-main.py:463-INFO- * MAPE: 0.49829
2024-05-07 10:36:32,531-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:36:32,531-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 10:36:32,532-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:36:32,532-main.py:469-INFO- Average Latency : 374.31263924 ms
2024-05-07 10:43:30,832-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 10:43:30,833-main.py:76-INFO-Loading dataset:
2024-05-07 10:43:31,178-main.py:274-INFO-Train data = 2, Test data = 1
2024-05-07 10:43:31,936-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 10:43:31,937-main.py:109-INFO-Loading model:
2024-05-07 10:43:31,938-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:43:31,944-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 10:43:32,366-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 10:43:32,366-main.py:462-INFO- * Speed: 375.61822 ms/iter
2024-05-07 10:43:32,366-main.py:463-INFO- * MAPE: 0.49829
2024-05-07 10:43:32,367-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 10:43:32,367-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 10:43:32,367-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 10:43:32,367-main.py:469-INFO- Average Latency : 372.61843681 ms
2024-05-07 11:17:29,768-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 11:17:29,768-main.py:76-INFO-Loading dataset:
2024-05-07 11:17:30,099-main.py:274-INFO-Train data = 2, Test data = 1
2024-05-07 11:17:30,860-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 11:17:30,860-main.py:109-INFO-Loading model:
2024-05-07 11:17:30,861-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:17:30,868-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:17:31,285-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 11:17:31,285-main.py:462-INFO- * Speed: 371.32239 ms/iter
2024-05-07 11:17:31,285-main.py:463-INFO- * MAPE: 0.49829
2024-05-07 11:17:31,285-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 11:17:31,285-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 11:17:31,286-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 11:17:31,286-main.py:469-INFO- Average Latency : 368.32261086 ms
2024-05-07 11:19:00,043-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 11:19:00,044-main.py:76-INFO-Loading dataset:
2024-05-07 11:19:00,399-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-07 11:19:01,156-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 11:19:01,156-main.py:109-INFO-Loading model:
2024-05-07 11:19:01,157-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:19:01,163-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:19:01,590-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 11:19:01,590-main.py:462-INFO- * Speed: 126.66663 ms/iter
2024-05-07 11:19:01,590-main.py:463-INFO- * MAPE: 0.57794
2024-05-07 11:19:01,590-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 11:19:01,590-main.py:465-INFO- * Kendall's Tau: -0.9999999999999999
2024-05-07 11:19:01,590-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 11:19:01,590-main.py:469-INFO- Average Latency : 124.99992053 ms
2024-05-07 11:19:45,996-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 11:19:45,996-main.py:76-INFO-Loading dataset:
2024-05-07 11:19:46,320-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-07 11:19:47,075-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 11:19:47,075-main.py:109-INFO-Loading model:
2024-05-07 11:19:47,076-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:19:47,082-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:19:47,520-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 11:19:47,520-main.py:462-INFO- * Speed: 128.78251 ms/iter
2024-05-07 11:19:47,520-main.py:463-INFO- * MAPE: 0.57794
2024-05-07 11:19:47,520-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 11:19:47,520-main.py:465-INFO- * Kendall's Tau: -0.9999999999999999
2024-05-07 11:19:47,520-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 11:19:47,521-main.py:469-INFO- Average Latency : 125.78264872 ms
2024-05-07 11:26:34,515-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 11:26:34,516-main.py:76-INFO-Loading dataset:
2024-05-07 11:26:34,870-main.py:274-INFO-Train data = 1, Test data = 4
2024-05-07 11:26:35,635-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 11:26:35,635-main.py:109-INFO-Loading model:
2024-05-07 11:26:35,636-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:26:35,643-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:26:36,078-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 11:26:36,078-main.py:462-INFO- * Speed: 96.51083 ms/iter
2024-05-07 11:26:36,078-main.py:463-INFO- * MAPE: 1.22955
2024-05-07 11:26:36,079-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 11:26:36,079-main.py:465-INFO- * Kendall's Tau: -0.7745966692414834
2024-05-07 11:26:36,079-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 11:26:36,079-main.py:469-INFO- Average Latency : 95.01075745 ms
2024-05-07 11:32:02,092-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 11:32:02,093-main.py:76-INFO-Loading dataset:
2024-05-07 11:32:02,421-main.py:274-INFO-Train data = 1, Test data = 4
2024-05-07 11:32:03,168-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 11:32:03,168-main.py:109-INFO-Loading model:
2024-05-07 11:32:03,169-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:32:03,176-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:32:03,608-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 11:32:03,608-main.py:462-INFO- * Speed: 96.41767 ms/iter
2024-05-07 11:32:03,608-main.py:463-INFO- * MAPE: 1.22955
2024-05-07 11:32:03,609-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 11:32:03,609-main.py:465-INFO- * Kendall's Tau: -0.7745966692414834
2024-05-07 11:32:03,609-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 11:32:03,609-main.py:469-INFO- Average Latency : 95.16757727 ms
2024-05-07 11:34:08,397-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 11:34:08,397-main.py:76-INFO-Loading dataset:
2024-05-07 11:34:08,722-main.py:274-INFO-Train data = 1, Test data = 4
2024-05-07 11:34:09,481-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 11:34:09,481-main.py:109-INFO-Loading model:
2024-05-07 11:34:09,482-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:34:09,488-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 11:34:09,934-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 11:34:09,934-main.py:462-INFO- * Speed: 97.99987 ms/iter
2024-05-07 11:34:09,934-main.py:463-INFO- * MAPE: 1.22955
2024-05-07 11:34:09,934-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 11:34:09,934-main.py:465-INFO- * Kendall's Tau: -0.7745966692414834
2024-05-07 11:34:09,934-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 11:34:09,934-main.py:469-INFO- Average Latency : 96.49991989 ms
2024-05-07 13:33:27,132-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 13:33:27,133-main.py:76-INFO-Loading dataset:
2024-05-07 13:33:27,489-main.py:274-INFO-Train data = 1, Test data = 4
2024-05-07 13:33:28,241-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 13:33:28,241-main.py:109-INFO-Loading model:
2024-05-07 13:33:28,242-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:33:28,249-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:33:28,690-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 13:33:28,690-main.py:462-INFO- * Speed: 98.65218 ms/iter
2024-05-07 13:33:28,690-main.py:463-INFO- * MAPE: 1.11244
2024-05-07 13:33:28,690-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 13:33:28,690-main.py:465-INFO- * Kendall's Tau: 0.2357022603955159
2024-05-07 13:33:28,690-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 13:33:28,690-main.py:469-INFO- Average Latency : 96.90231085 ms
2024-05-07 13:35:07,974-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 13:35:07,974-main.py:76-INFO-Loading dataset:
2024-05-07 13:35:08,331-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-07 13:35:09,074-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 13:35:09,075-main.py:109-INFO-Loading model:
2024-05-07 13:35:09,076-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:35:09,083-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:35:09,509-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 13:35:09,509-main.py:462-INFO- * Speed: 127.11120 ms/iter
2024-05-07 13:35:09,509-main.py:463-INFO- * MAPE: 1.31715
2024-05-07 13:35:09,509-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 13:35:09,509-main.py:465-INFO- * Kendall's Tau: 0.0
2024-05-07 13:35:09,509-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 13:35:09,509-main.py:469-INFO- Average Latency : 125.11110306 ms
2024-05-07 13:42:49,104-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 13:42:49,105-main.py:76-INFO-Loading dataset:
2024-05-07 13:42:49,467-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-07 13:42:50,220-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 13:42:50,220-main.py:109-INFO-Loading model:
2024-05-07 13:42:50,222-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:42:50,228-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:42:50,665-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 13:42:50,666-main.py:462-INFO- * Speed: 130.04263 ms/iter
2024-05-07 13:42:50,666-main.py:463-INFO- * MAPE: 1.31715
2024-05-07 13:42:50,666-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 13:42:50,666-main.py:465-INFO- * Kendall's Tau: 0.0
2024-05-07 13:42:50,666-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 13:42:50,666-main.py:469-INFO- Average Latency : 128.37600708 ms
2024-05-07 13:44:05,596-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 13:44:05,596-main.py:76-INFO-Loading dataset:
2024-05-07 13:44:05,953-main.py:274-INFO-Train data = 3, Test data = 1
2024-05-07 13:44:06,711-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 13:44:06,712-main.py:109-INFO-Loading model:
2024-05-07 13:44:06,713-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:44:06,719-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:44:07,144-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 13:44:07,144-main.py:462-INFO- * Speed: 374.76659 ms/iter
2024-05-07 13:44:07,144-main.py:463-INFO- * MAPE: 0.53902
2024-05-07 13:44:07,144-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 13:44:07,145-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 13:44:07,145-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 13:44:07,145-main.py:469-INFO- Average Latency : 371.76632881 ms
2024-05-07 13:46:02,253-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 13:46:02,254-main.py:76-INFO-Loading dataset:
2024-05-07 13:46:02,626-main.py:274-INFO-Train data = 3, Test data = 1
2024-05-07 13:46:03,384-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 13:46:03,385-main.py:109-INFO-Loading model:
2024-05-07 13:46:03,386-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:46:03,392-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:46:03,825-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 13:46:03,826-main.py:462-INFO- * Speed: 384.66620 ms/iter
2024-05-07 13:46:03,826-main.py:463-INFO- * MAPE: 0.22804
2024-05-07 13:46:03,826-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 13:46:03,826-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 13:46:03,826-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 13:46:03,826-main.py:469-INFO- Average Latency : 382.66587257 ms
2024-05-07 13:47:46,123-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 13:47:46,124-main.py:76-INFO-Loading dataset:
2024-05-07 13:47:46,481-main.py:274-INFO-Train data = 3, Test data = 1
2024-05-07 13:47:47,238-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 13:47:47,238-main.py:109-INFO-Loading model:
2024-05-07 13:47:47,240-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:47:47,246-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:47:47,674-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 13:47:47,674-main.py:462-INFO- * Speed: 380.62215 ms/iter
2024-05-07 13:47:47,675-main.py:463-INFO- * MAPE: 0.22804
2024-05-07 13:47:47,675-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 13:47:47,675-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 13:47:47,675-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 13:47:47,675-main.py:469-INFO- Average Latency : 378.62205505 ms
2024-05-07 13:47:56,917-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 13:47:56,918-main.py:76-INFO-Loading dataset:
2024-05-07 13:47:57,256-main.py:274-INFO-Train data = 2, Test data = 2
2024-05-07 13:47:58,011-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 13:47:58,012-main.py:109-INFO-Loading model:
2024-05-07 13:47:58,013-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:47:58,020-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 13:47:58,444-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 13:47:58,445-main.py:462-INFO- * Speed: 189.36312 ms/iter
2024-05-07 13:47:58,445-main.py:463-INFO- * MAPE: 0.38353
2024-05-07 13:47:58,445-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 13:47:58,445-main.py:465-INFO- * Kendall's Tau: 1.0
2024-05-07 13:47:58,445-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 13:47:58,445-main.py:469-INFO- Average Latency : 188.36307526 ms
2024-05-07 14:41:01,803-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 14:41:01,803-main.py:76-INFO-Loading dataset:
2024-05-07 14:41:05,813-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-05-07 14:41:06,566-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 14:41:06,566-main.py:109-INFO-Loading model:
2024-05-07 14:41:06,568-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 14:41:06,575-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 14:41:07,293-main.py:454-INFO-[50/2000] MAPE: 0.08457 ErrBnd: [0.7254902  0.56862745 0.23529412], Tau: 0.92941
2024-05-07 14:41:07,597-main.py:454-INFO-[100/2000] MAPE: 0.12248 ErrBnd: [0.67326733 0.5049505  0.20792079], Tau: 0.86139
2024-05-07 14:41:07,903-main.py:454-INFO-[150/2000] MAPE: 0.12351 ErrBnd: [0.67549669 0.52317881 0.1986755 ], Tau: 0.85448
2024-05-07 14:41:08,221-main.py:454-INFO-[200/2000] MAPE: 0.11452 ErrBnd: [0.68656716 0.54228856 0.19402985], Tau: 0.86776
2024-05-07 14:41:08,527-main.py:454-INFO-[250/2000] MAPE: 0.11220 ErrBnd: [0.68525896 0.53784861 0.17928287], Tau: 0.87574
2024-05-07 14:41:08,849-main.py:454-INFO-[300/2000] MAPE: 0.11135 ErrBnd: [0.68438538 0.5448505  0.18604651], Tau: 0.87148
2024-05-07 14:41:09,162-main.py:454-INFO-[350/2000] MAPE: 0.10917 ErrBnd: [0.6951567  0.55270655 0.18233618], Tau: 0.87630
2024-05-07 14:41:09,485-main.py:454-INFO-[400/2000] MAPE: 0.11380 ErrBnd: [0.6882793  0.5436409  0.18952618], Tau: 0.87042
2024-05-07 14:41:09,803-main.py:454-INFO-[450/2000] MAPE: 0.11274 ErrBnd: [0.6962306  0.54988914 0.19290466], Tau: 0.87389
2024-05-07 14:41:10,107-main.py:454-INFO-[500/2000] MAPE: 0.11532 ErrBnd: [0.69461078 0.5489022  0.18762475], Tau: 0.86915
2024-05-07 14:41:10,436-main.py:454-INFO-[550/2000] MAPE: 0.11861 ErrBnd: [0.68239564 0.53357532 0.17604356], Tau: 0.86195
2024-05-07 14:41:10,756-main.py:454-INFO-[600/2000] MAPE: 0.11944 ErrBnd: [0.67387687 0.52911814 0.17304493], Tau: 0.86275
2024-05-07 14:41:11,071-main.py:454-INFO-[650/2000] MAPE: 0.11990 ErrBnd: [0.67895545 0.53149002 0.16743472], Tau: 0.86312
2024-05-07 14:41:11,403-main.py:454-INFO-[700/2000] MAPE: 0.12050 ErrBnd: [0.67047076 0.52496434 0.16405136], Tau: 0.86387
2024-05-07 14:41:11,693-main.py:454-INFO-[750/2000] MAPE: 0.12033 ErrBnd: [0.66977364 0.52463382 0.16245007], Tau: 0.86376
2024-05-07 14:41:12,025-main.py:454-INFO-[800/2000] MAPE: 0.11905 ErrBnd: [0.67166042 0.52933833 0.16354557], Tau: 0.86553
2024-05-07 14:41:12,335-main.py:454-INFO-[850/2000] MAPE: 0.11728 ErrBnd: [0.6733255  0.52643948 0.16098707], Tau: 0.86924
2024-05-07 14:41:12,654-main.py:454-INFO-[900/2000] MAPE: 0.11582 ErrBnd: [0.67702553 0.52719201 0.15871254], Tau: 0.86909
2024-05-07 14:41:12,985-main.py:454-INFO-[950/2000] MAPE: 0.11557 ErrBnd: [0.67718191 0.5278654  0.15667718], Tau: 0.87003
2024-05-07 14:41:13,333-main.py:454-INFO-[1000/2000] MAPE: 0.11534 ErrBnd: [0.67732268 0.52747253 0.15884116], Tau: 0.86985
2024-05-07 14:41:13,686-main.py:454-INFO-[1050/2000] MAPE: 0.11660 ErrBnd: [0.67459562 0.52521408 0.15984776], Tau: 0.86725
2024-05-07 14:41:14,042-main.py:454-INFO-[1100/2000] MAPE: 0.11622 ErrBnd: [0.67393279 0.52497729 0.16076294], Tau: 0.86939
2024-05-07 14:41:14,395-main.py:454-INFO-[1150/2000] MAPE: 0.11643 ErrBnd: [0.67332754 0.52128584 0.15899218], Tau: 0.87084
2024-05-07 14:41:14,764-main.py:454-INFO-[1200/2000] MAPE: 0.11830 ErrBnd: [0.66944213 0.51956703 0.1582015 ], Tau: 0.86716
2024-05-07 14:41:15,126-main.py:454-INFO-[1250/2000] MAPE: 0.11988 ErrBnd: [0.66666667 0.51558753 0.15667466], Tau: 0.86410
2024-05-07 14:41:15,493-main.py:454-INFO-[1300/2000] MAPE: 0.11995 ErrBnd: [0.66717909 0.51729439 0.15833974], Tau: 0.86396
2024-05-07 14:41:15,846-main.py:454-INFO-[1350/2000] MAPE: 0.12134 ErrBnd: [0.66469282 0.51665433 0.15914138], Tau: 0.86413
2024-05-07 14:41:16,216-main.py:454-INFO-[1400/2000] MAPE: 0.12063 ErrBnd: [0.66452534 0.51748751 0.16131335], Tau: 0.86481
2024-05-07 14:41:16,651-main.py:454-INFO-[1450/2000] MAPE: 0.12188 ErrBnd: [0.66023432 0.51619573 0.16195727], Tau: 0.86374
2024-05-07 14:41:17,093-main.py:454-INFO-[1500/2000] MAPE: 0.12180 ErrBnd: [0.65756163 0.51499001 0.15922718], Tau: 0.86466
2024-05-07 14:41:17,541-main.py:454-INFO-[1550/2000] MAPE: 0.12147 ErrBnd: [0.65699549 0.51450677 0.15731786], Tau: 0.86566
2024-05-07 14:41:18,002-main.py:454-INFO-[1600/2000] MAPE: 0.12210 ErrBnd: [0.65708932 0.51405372 0.15677701], Tau: 0.86414
2024-05-07 14:41:18,454-main.py:454-INFO-[1650/2000] MAPE: 0.12356 ErrBnd: [0.65475469 0.51181102 0.15445185], Tau: 0.86201
2024-05-07 14:41:18,918-main.py:454-INFO-[1700/2000] MAPE: 0.12316 ErrBnd: [0.65667255 0.51205173 0.15402704], Tau: 0.86305
2024-05-07 14:41:19,339-main.py:454-INFO-[1750/2000] MAPE: 0.12349 ErrBnd: [0.65790977 0.5117076  0.1536265 ], Tau: 0.86253
2024-05-07 14:41:19,771-main.py:454-INFO-[1800/2000] MAPE: 0.12346 ErrBnd: [0.65963354 0.5141588  0.15546918], Tau: 0.86069
2024-05-07 14:41:20,152-main.py:454-INFO-[1850/2000] MAPE: 0.12299 ErrBnd: [0.66072393 0.51377634 0.15667207], Tau: 0.86117
2024-05-07 14:41:20,588-main.py:454-INFO-[1900/2000] MAPE: 0.12311 ErrBnd: [0.66017885 0.51183588 0.15570752], Tau: 0.86096
2024-05-07 14:41:21,055-main.py:454-INFO-[1950/2000] MAPE: 0.12392 ErrBnd: [0.65709892 0.50896976 0.15427986], Tau: 0.86035
2024-05-07 14:41:21,536-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 14:41:21,536-main.py:462-INFO- * Speed: 7.45354 ms/iter
2024-05-07 14:41:21,536-main.py:463-INFO- * MAPE: 0.12323
2024-05-07 14:41:21,536-main.py:464-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-05-07 14:41:21,537-main.py:465-INFO- * Kendall's Tau: 0.862052897094688
2024-05-07 14:41:21,537-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 14:41:21,537-main.py:469-INFO- Average Latency : 3.77010930 ms
2024-05-07 14:49:05,127-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 14:49:05,127-main.py:76-INFO-Loading dataset:
2024-05-07 14:49:07,611-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-05-07 14:49:08,357-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 14:49:08,358-main.py:109-INFO-Loading model:
2024-05-07 14:49:08,359-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 14:49:08,365-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 14:49:09,100-main.py:454-INFO-[50/2000] MAPE: 0.08457 ErrBnd: [0.7254902  0.56862745 0.23529412], Tau: 0.92941
2024-05-07 14:49:09,434-main.py:454-INFO-[100/2000] MAPE: 0.12248 ErrBnd: [0.67326733 0.5049505  0.20792079], Tau: 0.86139
2024-05-07 14:49:09,747-main.py:454-INFO-[150/2000] MAPE: 0.12351 ErrBnd: [0.67549669 0.52317881 0.1986755 ], Tau: 0.85448
2024-05-07 14:49:10,086-main.py:454-INFO-[200/2000] MAPE: 0.11452 ErrBnd: [0.68656716 0.54228856 0.19402985], Tau: 0.86776
2024-05-07 14:49:10,406-main.py:454-INFO-[250/2000] MAPE: 0.11220 ErrBnd: [0.68525896 0.53784861 0.17928287], Tau: 0.87574
2024-05-07 14:49:10,742-main.py:454-INFO-[300/2000] MAPE: 0.11135 ErrBnd: [0.68438538 0.5448505  0.18604651], Tau: 0.87148
2024-05-07 14:49:11,082-main.py:454-INFO-[350/2000] MAPE: 0.10917 ErrBnd: [0.6951567  0.55270655 0.18233618], Tau: 0.87630
2024-05-07 14:49:11,429-main.py:454-INFO-[400/2000] MAPE: 0.11380 ErrBnd: [0.6882793  0.5436409  0.18952618], Tau: 0.87042
2024-05-07 14:49:11,773-main.py:454-INFO-[450/2000] MAPE: 0.11274 ErrBnd: [0.6962306  0.54988914 0.19290466], Tau: 0.87389
2024-05-07 14:49:12,090-main.py:454-INFO-[500/2000] MAPE: 0.11532 ErrBnd: [0.69461078 0.5489022  0.18762475], Tau: 0.86915
2024-05-07 14:49:12,428-main.py:454-INFO-[550/2000] MAPE: 0.11861 ErrBnd: [0.68239564 0.53357532 0.17604356], Tau: 0.86195
2024-05-07 14:49:12,768-main.py:454-INFO-[600/2000] MAPE: 0.11944 ErrBnd: [0.67387687 0.52911814 0.17304493], Tau: 0.86275
2024-05-07 14:49:13,109-main.py:454-INFO-[650/2000] MAPE: 0.11990 ErrBnd: [0.67895545 0.53149002 0.16743472], Tau: 0.86312
2024-05-07 14:49:13,450-main.py:454-INFO-[700/2000] MAPE: 0.12050 ErrBnd: [0.67047076 0.52496434 0.16405136], Tau: 0.86387
2024-05-07 14:49:13,750-main.py:454-INFO-[750/2000] MAPE: 0.12033 ErrBnd: [0.66977364 0.52463382 0.16245007], Tau: 0.86376
2024-05-07 14:49:14,128-main.py:454-INFO-[800/2000] MAPE: 0.11905 ErrBnd: [0.67166042 0.52933833 0.16354557], Tau: 0.86553
2024-05-07 14:49:14,503-main.py:454-INFO-[850/2000] MAPE: 0.11728 ErrBnd: [0.6733255  0.52643948 0.16098707], Tau: 0.86924
2024-05-07 14:49:14,893-main.py:454-INFO-[900/2000] MAPE: 0.11582 ErrBnd: [0.67702553 0.52719201 0.15871254], Tau: 0.86909
2024-05-07 14:49:15,255-main.py:454-INFO-[950/2000] MAPE: 0.11557 ErrBnd: [0.67718191 0.5278654  0.15667718], Tau: 0.87003
2024-05-07 14:49:15,648-main.py:454-INFO-[1000/2000] MAPE: 0.11534 ErrBnd: [0.67732268 0.52747253 0.15884116], Tau: 0.86985
2024-05-07 14:49:16,031-main.py:454-INFO-[1050/2000] MAPE: 0.11660 ErrBnd: [0.67459562 0.52521408 0.15984776], Tau: 0.86725
2024-05-07 14:49:16,430-main.py:454-INFO-[1100/2000] MAPE: 0.11622 ErrBnd: [0.67393279 0.52497729 0.16076294], Tau: 0.86939
2024-05-07 14:49:16,833-main.py:454-INFO-[1150/2000] MAPE: 0.11643 ErrBnd: [0.67332754 0.52128584 0.15899218], Tau: 0.87084
2024-05-07 14:49:17,231-main.py:454-INFO-[1200/2000] MAPE: 0.11830 ErrBnd: [0.66944213 0.51956703 0.1582015 ], Tau: 0.86716
2024-05-07 14:49:17,642-main.py:454-INFO-[1250/2000] MAPE: 0.11988 ErrBnd: [0.66666667 0.51558753 0.15667466], Tau: 0.86410
2024-05-07 14:49:18,109-main.py:454-INFO-[1300/2000] MAPE: 0.11995 ErrBnd: [0.66717909 0.51729439 0.15833974], Tau: 0.86396
2024-05-07 14:49:18,492-main.py:454-INFO-[1350/2000] MAPE: 0.12134 ErrBnd: [0.66469282 0.51665433 0.15914138], Tau: 0.86413
2024-05-07 14:49:18,909-main.py:454-INFO-[1400/2000] MAPE: 0.12063 ErrBnd: [0.66452534 0.51748751 0.16131335], Tau: 0.86481
2024-05-07 14:49:19,307-main.py:454-INFO-[1450/2000] MAPE: 0.12188 ErrBnd: [0.66023432 0.51619573 0.16195727], Tau: 0.86374
2024-05-07 14:49:19,726-main.py:454-INFO-[1500/2000] MAPE: 0.12180 ErrBnd: [0.65756163 0.51499001 0.15922718], Tau: 0.86466
2024-05-07 14:49:20,146-main.py:454-INFO-[1550/2000] MAPE: 0.12147 ErrBnd: [0.65699549 0.51450677 0.15731786], Tau: 0.86566
2024-05-07 14:49:20,630-main.py:454-INFO-[1600/2000] MAPE: 0.12210 ErrBnd: [0.65708932 0.51405372 0.15677701], Tau: 0.86414
2024-05-07 14:49:21,126-main.py:454-INFO-[1650/2000] MAPE: 0.12356 ErrBnd: [0.65475469 0.51181102 0.15445185], Tau: 0.86201
2024-05-07 14:49:21,589-main.py:454-INFO-[1700/2000] MAPE: 0.12316 ErrBnd: [0.65667255 0.51205173 0.15402704], Tau: 0.86305
2024-05-07 14:49:22,014-main.py:454-INFO-[1750/2000] MAPE: 0.12349 ErrBnd: [0.65790977 0.5117076  0.1536265 ], Tau: 0.86253
2024-05-07 14:49:22,454-main.py:454-INFO-[1800/2000] MAPE: 0.12346 ErrBnd: [0.65963354 0.5141588  0.15546918], Tau: 0.86069
2024-05-07 14:49:22,772-main.py:454-INFO-[1850/2000] MAPE: 0.12299 ErrBnd: [0.66072393 0.51377634 0.15667207], Tau: 0.86117
2024-05-07 14:49:23,166-main.py:454-INFO-[1900/2000] MAPE: 0.12311 ErrBnd: [0.66017885 0.51183588 0.15570752], Tau: 0.86096
2024-05-07 14:49:23,578-main.py:454-INFO-[1950/2000] MAPE: 0.12392 ErrBnd: [0.65709892 0.50896976 0.15427986], Tau: 0.86035
2024-05-07 14:49:23,980-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 14:49:23,980-main.py:462-INFO- * Speed: 7.78300 ms/iter
2024-05-07 14:49:23,980-main.py:463-INFO- * MAPE: 0.12323
2024-05-07 14:49:23,981-main.py:464-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-05-07 14:49:23,981-main.py:465-INFO- * Kendall's Tau: 0.862052897094688
2024-05-07 14:49:23,981-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 14:49:23,981-main.py:469-INFO- Average Latency : 4.66009080 ms
2024-05-07 15:02:56,251-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 15:02:56,252-main.py:76-INFO-Loading dataset:
2024-05-07 15:02:56,604-main.py:274-INFO-Train data = 2, Test data = 0
2024-05-07 15:02:57,362-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 15:02:57,363-main.py:109-INFO-Loading model:
2024-05-07 15:02:57,364-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 15:02:57,372-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 15:03:29,501-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 15:03:29,502-main.py:76-INFO-Loading dataset:
2024-05-07 15:03:29,894-main.py:274-INFO-Train data = 2, Test data = 1
2024-05-07 15:03:30,656-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 15:03:30,656-main.py:109-INFO-Loading model:
2024-05-07 15:03:30,657-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 15:03:30,665-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 15:03:31,096-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 15:03:31,096-main.py:462-INFO- * Speed: 381.23441 ms/iter
2024-05-07 15:03:31,096-main.py:463-INFO- * MAPE: 0.07517
2024-05-07 15:03:31,096-main.py:464-INFO- * ErrorBound: [1. 0. 0.]
2024-05-07 15:03:31,096-main.py:465-INFO- * Kendall's Tau: nan
2024-05-07 15:03:31,096-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 15:03:31,096-main.py:469-INFO- Average Latency : 379.23431396 ms
2024-05-07 15:13:00,434-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-07 15:13:00,434-main.py:76-INFO-Loading dataset:
2024-05-07 15:13:00,851-main.py:274-INFO-Train data = 2, Test data = 3
2024-05-07 15:13:01,617-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-07 15:13:01,618-main.py:109-INFO-Loading model:
2024-05-07 15:13:01,619-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-07 15:13:01,626-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-07 15:13:02,061-main.py:461-INFO- ------------------------------------------------------------------
2024-05-07 15:13:02,061-main.py:462-INFO- * Speed: 128.99995 ms/iter
2024-05-07 15:13:02,062-main.py:463-INFO- * MAPE: 1.30511
2024-05-07 15:13:02,062-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-07 15:13:02,062-main.py:465-INFO- * Kendall's Tau: -0.816496580927726
2024-05-07 15:13:02,062-main.py:466-INFO- ------------------------------------------------------------------
2024-05-07 15:13:02,062-main.py:469-INFO- Average Latency : 127.33332316 ms
2024-05-13 17:06:31,846-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 17:06:31,846-main.py:76-INFO-Loading dataset:
2024-05-13 17:07:07,952-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 17:07:07,952-main.py:76-INFO-Loading dataset:
2024-05-13 17:07:08,351-main.py:274-INFO-Train data = 2, Test data = 3
2024-05-13 17:07:09,647-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 17:07:09,647-main.py:109-INFO-Loading model:
2024-05-13 17:07:09,648-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 17:07:09,669-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 17:07:10,483-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 17:07:10,483-main.py:462-INFO- * Speed: 229.06502 ms/iter
2024-05-13 17:07:10,484-main.py:463-INFO- * MAPE: 1.30511
2024-05-13 17:07:10,484-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-13 17:07:10,484-main.py:465-INFO- * Kendall's Tau: -0.816496580927726
2024-05-13 17:07:10,484-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 17:07:10,485-main.py:469-INFO- Average Latency : 223.08508555 ms
2024-05-13 18:40:07,043-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 18:40:07,043-main.py:76-INFO-Loading dataset:
2024-05-13 18:40:07,445-main.py:274-INFO-Train data = 2, Test data = 4
2024-05-13 18:40:08,204-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 18:40:08,204-main.py:109-INFO-Loading model:
2024-05-13 18:40:08,205-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 18:40:08,212-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 18:40:08,639-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 18:40:08,639-main.py:462-INFO- * Speed: 94.82193 ms/iter
2024-05-13 18:40:08,639-main.py:463-INFO- * MAPE: 10.89691
2024-05-13 18:40:08,640-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-13 18:40:08,640-main.py:465-INFO- * Kendall's Tau: -0.18257418583505539
2024-05-13 18:40:08,640-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 18:40:08,640-main.py:469-INFO- Average Latency : 93.32734346 ms
2024-05-13 18:56:19,940-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 18:56:19,941-main.py:76-INFO-Loading dataset:
2024-05-13 18:56:35,141-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 18:56:35,141-main.py:76-INFO-Loading dataset:
2024-05-13 18:56:35,540-main.py:274-INFO-Train data = 2, Test data = 5
2024-05-13 18:56:36,291-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 18:56:36,291-main.py:109-INFO-Loading model:
2024-05-13 18:56:36,292-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 18:56:36,299-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 18:56:36,726-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 18:56:36,727-main.py:462-INFO- * Speed: 75.94595 ms/iter
2024-05-13 18:56:36,727-main.py:463-INFO- * MAPE: 9.28823
2024-05-13 18:56:36,727-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-13 18:56:36,727-main.py:465-INFO- * Kendall's Tau: 0.10540925533894598
2024-05-13 18:56:36,727-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 18:56:36,728-main.py:469-INFO- Average Latency : 74.55081940 ms
2024-05-13 19:17:02,255-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:17:02,255-main.py:76-INFO-Loading dataset:
2024-05-13 19:17:02,587-main.py:274-INFO-Train data = 2, Test data = 5
2024-05-13 19:17:03,349-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:17:03,350-main.py:109-INFO-Loading model:
2024-05-13 19:17:03,351-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:17:03,358-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:17:03,787-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:17:03,787-main.py:462-INFO- * Speed: 76.34478 ms/iter
2024-05-13 19:17:03,788-main.py:463-INFO- * MAPE: 9.28823
2024-05-13 19:17:03,788-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-13 19:17:03,788-main.py:465-INFO- * Kendall's Tau: 0.10540925533894598
2024-05-13 19:17:03,788-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:17:03,788-main.py:469-INFO- Average Latency : 74.75166321 ms
2024-05-13 19:18:35,499-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:18:35,499-main.py:76-INFO-Loading dataset:
2024-05-13 19:18:35,824-main.py:274-INFO-Train data = 2, Test data = 5
2024-05-13 19:18:36,581-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:18:36,582-main.py:109-INFO-Loading model:
2024-05-13 19:18:36,583-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:18:36,590-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:18:37,025-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:18:37,025-main.py:462-INFO- * Speed: 77.51465 ms/iter
2024-05-13 19:18:37,025-main.py:463-INFO- * MAPE: 9.28823
2024-05-13 19:18:37,026-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-13 19:18:37,026-main.py:465-INFO- * Kendall's Tau: 0.10540925533894598
2024-05-13 19:18:37,026-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:18:37,026-main.py:469-INFO- Average Latency : 75.96797943 ms
2024-05-13 19:20:07,557-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:20:07,557-main.py:76-INFO-Loading dataset:
2024-05-13 19:20:07,984-main.py:274-INFO-Train data = 2, Test data = 5
2024-05-13 19:20:08,742-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:20:08,743-main.py:109-INFO-Loading model:
2024-05-13 19:20:08,744-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:20:08,750-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:20:09,180-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:20:09,180-main.py:462-INFO- * Speed: 76.29771 ms/iter
2024-05-13 19:20:09,180-main.py:463-INFO- * MAPE: 8.79092
2024-05-13 19:20:09,180-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-13 19:20:09,180-main.py:465-INFO- * Kendall's Tau: -0.10540925533894598
2024-05-13 19:20:09,180-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:20:09,181-main.py:469-INFO- Average Latency : 74.50366020 ms
2024-05-13 19:24:23,679-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:24:23,679-main.py:76-INFO-Loading dataset:
2024-05-13 19:24:24,098-main.py:274-INFO-Train data = 2, Test data = 6
2024-05-13 19:24:24,865-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:24:24,865-main.py:109-INFO-Loading model:
2024-05-13 19:24:24,866-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:24:24,874-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:24:25,303-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:24:25,303-main.py:462-INFO- * Speed: 63.89010 ms/iter
2024-05-13 19:24:25,303-main.py:463-INFO- * MAPE: 7.44644
2024-05-13 19:24:25,303-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-13 19:24:25,303-main.py:465-INFO- * Kendall's Tau: -0.27602622373694163
2024-05-13 19:24:25,304-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:24:25,304-main.py:469-INFO- Average Latency : 62.06289927 ms
2024-05-13 19:37:43,920-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:37:43,920-main.py:76-INFO-Loading dataset:
2024-05-13 19:37:44,938-main.py:274-INFO-Train data = 2, Test data = 7
2024-05-13 19:37:45,720-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:37:45,721-main.py:109-INFO-Loading model:
2024-05-13 19:37:45,722-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:37:45,728-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:37:46,170-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:37:46,170-main.py:462-INFO- * Speed: 56.08903 ms/iter
2024-05-13 19:37:46,170-main.py:463-INFO- * MAPE: 6.39329
2024-05-13 19:37:46,171-main.py:464-INFO- * ErrorBound: [0.14285714 0.         0.        ]
2024-05-13 19:37:46,171-main.py:465-INFO- * Kendall's Tau: 0.09759000729485331
2024-05-13 19:37:46,171-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:37:46,171-main.py:469-INFO- Average Latency : 54.49996676 ms
2024-05-13 19:46:44,937-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:46:44,937-main.py:76-INFO-Loading dataset:
2024-05-13 19:46:46,641-main.py:274-INFO-Train data = 2, Test data = 8
2024-05-13 19:46:47,408-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:46:47,409-main.py:109-INFO-Loading model:
2024-05-13 19:46:47,410-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:46:47,417-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:46:47,852-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:46:47,852-main.py:462-INFO- * Speed: 48.54104 ms/iter
2024-05-13 19:46:47,852-main.py:463-INFO- * MAPE: 5.64016
2024-05-13 19:46:47,852-main.py:464-INFO- * ErrorBound: [0.125 0.    0.   ]
2024-05-13 19:46:47,852-main.py:465-INFO- * Kendall's Tau: 0.25458753860865774
2024-05-13 19:46:47,853-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:46:47,854-main.py:469-INFO- Average Latency : 47.17051983 ms
2024-05-13 19:55:06,350-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:55:06,350-main.py:76-INFO-Loading dataset:
2024-05-13 19:55:08,034-main.py:274-INFO-Train data = 2, Test data = 9
2024-05-13 19:55:08,798-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:55:08,799-main.py:109-INFO-Loading model:
2024-05-13 19:55:08,800-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:55:08,805-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:55:09,247-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:55:09,248-main.py:462-INFO- * Speed: 43.75010 ms/iter
2024-05-13 19:55:09,248-main.py:463-INFO- * MAPE: 5.05439
2024-05-13 19:55:09,248-main.py:464-INFO- * ErrorBound: [0.11111111 0.         0.        ]
2024-05-13 19:55:09,248-main.py:465-INFO- * Kendall's Tau: 0.34786262139146906
2024-05-13 19:55:09,248-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:55:09,248-main.py:469-INFO- Average Latency : 42.13452339 ms
2024-05-13 19:56:10,438-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-13 19:56:10,439-main.py:76-INFO-Loading dataset:
2024-05-13 19:56:12,841-main.py:274-INFO-Train data = 2, Test data = 9
2024-05-13 19:56:13,590-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-13 19:56:13,591-main.py:109-INFO-Loading model:
2024-05-13 19:56:13,592-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:56:13,600-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-13 19:56:14,044-main.py:461-INFO- ------------------------------------------------------------------
2024-05-13 19:56:14,044-main.py:462-INFO- * Speed: 44.25420 ms/iter
2024-05-13 19:56:14,045-main.py:463-INFO- * MAPE: 5.05270
2024-05-13 19:56:14,045-main.py:464-INFO- * ErrorBound: [0.11111111 0.         0.        ]
2024-05-13 19:56:14,045-main.py:465-INFO- * Kendall's Tau: 0.4225771273642583
2024-05-13 19:56:14,045-main.py:466-INFO- ------------------------------------------------------------------
2024-05-13 19:56:14,045-main.py:469-INFO- Average Latency : 42.70376099 ms
2024-05-14 10:40:12,526-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 10:40:12,526-main.py:76-INFO-Loading dataset:
2024-05-14 10:40:16,810-main.py:274-INFO-Train data = 2, Test data = 12
2024-05-14 10:40:18,152-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-14 10:40:18,153-main.py:109-INFO-Loading model:
2024-05-14 10:40:18,154-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-14 10:40:18,175-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-14 10:40:19,031-main.py:461-INFO- ------------------------------------------------------------------
2024-05-14 10:40:19,031-main.py:462-INFO- * Speed: 61.15637 ms/iter
2024-05-14 10:40:19,031-main.py:463-INFO- * MAPE: 3.86502
2024-05-14 10:40:19,032-main.py:464-INFO- * ErrorBound: [0.16666667 0.08333333 0.        ]
2024-05-14 10:40:19,032-main.py:465-INFO- * Kendall's Tau: 0.5649019553110248
2024-05-14 10:40:19,032-main.py:466-INFO- ------------------------------------------------------------------
2024-05-14 10:40:19,032-main.py:469-INFO- Average Latency : 58.82294973 ms
2024-05-14 11:09:07,755-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 11:09:07,755-main.py:76-INFO-Loading dataset:
2024-05-14 11:09:12,680-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-14 11:09:13,490-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-14 11:09:13,491-main.py:109-INFO-Loading model:
2024-05-14 11:09:13,492-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-14 11:09:13,498-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-14 11:09:13,967-main.py:461-INFO- ------------------------------------------------------------------
2024-05-14 11:09:13,967-main.py:462-INFO- * Speed: 28.14582 ms/iter
2024-05-14 11:09:13,967-main.py:463-INFO- * MAPE: 3.17238
2024-05-14 11:09:13,967-main.py:464-INFO- * ErrorBound: [0.2        0.06666667 0.        ]
2024-05-14 11:09:13,968-main.py:465-INFO- * Kendall's Tau: 0.5741692517632146
2024-05-14 11:09:13,968-main.py:466-INFO- ------------------------------------------------------------------
2024-05-14 11:09:13,968-main.py:469-INFO- Average Latency : 26.54581070 ms
2024-05-14 13:42:29,377-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:42:29,377-main.py:76-INFO-Loading dataset:
2024-05-14 13:43:51,361-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:43:51,361-main.py:76-INFO-Loading dataset:
2024-05-14 13:44:07,902-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:44:07,902-main.py:76-INFO-Loading dataset:
2024-05-14 13:44:33,093-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:44:33,093-main.py:76-INFO-Loading dataset:
2024-05-14 13:44:59,420-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:44:59,420-main.py:76-INFO-Loading dataset:
2024-05-14 13:45:27,094-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:45:27,094-main.py:76-INFO-Loading dataset:
2024-05-14 13:46:04,525-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:46:04,525-main.py:76-INFO-Loading dataset:
2024-05-14 13:46:09,428-main.py:274-INFO-Train data = 0, Test data = 17
2024-05-14 13:46:33,955-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 13:46:33,955-main.py:76-INFO-Loading dataset:
2024-05-14 13:46:38,853-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-14 13:46:39,639-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-14 13:46:39,639-main.py:109-INFO-Loading model:
2024-05-14 13:46:39,640-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-14 13:46:39,647-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-14 13:46:40,119-main.py:461-INFO- ------------------------------------------------------------------
2024-05-14 13:46:40,119-main.py:462-INFO- * Speed: 28.29008 ms/iter
2024-05-14 13:46:40,119-main.py:463-INFO- * MAPE: 3.38423
2024-05-14 13:46:40,120-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-14 13:46:40,120-main.py:465-INFO- * Kendall's Tau: 0.6124472018807623
2024-05-14 13:46:40,120-main.py:466-INFO- ------------------------------------------------------------------
2024-05-14 13:46:40,120-main.py:469-INFO- Average Latency : 26.75685883 ms
2024-05-14 15:29:13,676-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 15:29:13,676-main.py:76-INFO-Loading dataset:
2024-05-14 15:29:17,528-main.py:274-INFO-Train data = 2, Test data = 13
2024-05-14 15:29:18,299-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-14 15:29:18,300-main.py:109-INFO-Loading model:
2024-05-14 15:29:18,301-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-14 15:29:18,308-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-14 15:29:18,768-main.py:461-INFO- ------------------------------------------------------------------
2024-05-14 15:29:18,768-main.py:462-INFO- * Speed: 31.78912 ms/iter
2024-05-14 15:29:18,768-main.py:463-INFO- * MAPE: 3.65874
2024-05-14 15:29:18,769-main.py:464-INFO- * ErrorBound: [0.15384615 0.07692308 0.        ]
2024-05-14 15:29:18,769-main.py:465-INFO- * Kendall's Tau: 0.47742929103557086
2024-05-14 15:29:18,769-main.py:466-INFO- ------------------------------------------------------------------
2024-05-14 15:29:18,769-main.py:469-INFO- Average Latency : 30.25054932 ms
2024-05-14 15:31:24,931-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 15:31:24,931-main.py:76-INFO-Loading dataset:
2024-05-14 15:31:29,181-main.py:274-INFO-Train data = 2, Test data = 14
2024-05-14 15:31:29,959-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-14 15:31:29,959-main.py:109-INFO-Loading model:
2024-05-14 15:31:29,960-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-14 15:31:29,967-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-14 15:31:30,431-main.py:461-INFO- ------------------------------------------------------------------
2024-05-14 15:31:30,431-main.py:462-INFO- * Speed: 29.75774 ms/iter
2024-05-14 15:31:30,431-main.py:463-INFO- * MAPE: 3.43072
2024-05-14 15:31:30,432-main.py:464-INFO- * ErrorBound: [0.14285714 0.07142857 0.        ]
2024-05-14 15:31:30,432-main.py:465-INFO- * Kendall's Tau: 0.5082950505010435
2024-05-14 15:31:30,432-main.py:466-INFO- ------------------------------------------------------------------
2024-05-14 15:31:30,432-main.py:469-INFO- Average Latency : 28.32909993 ms
2024-05-14 15:36:16,352-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-14 15:36:16,352-main.py:76-INFO-Loading dataset:
2024-05-14 15:36:20,609-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-14 15:36:21,398-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-14 15:36:21,398-main.py:109-INFO-Loading model:
2024-05-14 15:36:21,399-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-14 15:36:21,406-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-14 15:36:21,880-main.py:461-INFO- ------------------------------------------------------------------
2024-05-14 15:36:21,880-main.py:462-INFO- * Speed: 28.10693 ms/iter
2024-05-14 15:36:21,880-main.py:463-INFO- * MAPE: 3.24467
2024-05-14 15:36:21,881-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-14 15:36:21,881-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-14 15:36:21,881-main.py:466-INFO- ------------------------------------------------------------------
2024-05-14 15:36:21,881-main.py:469-INFO- Average Latency : 26.63979530 ms
2024-05-16 12:20:04,775-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 12:20:04,775-main.py:76-INFO-Loading dataset:
2024-05-16 12:20:10,001-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 12:20:11,320-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 12:20:11,320-main.py:109-INFO-Loading model:
2024-05-16 12:20:11,321-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 12:20:11,342-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 12:20:12,201-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 12:20:12,202-main.py:462-INFO- * Speed: 49.12926 ms/iter
2024-05-16 12:20:12,202-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 12:20:12,202-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 12:20:12,202-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 12:20:12,202-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 12:20:12,203-main.py:469-INFO- Average Latency : 47.00299899 ms
2024-05-16 12:44:58,498-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 12:44:58,498-main.py:76-INFO-Loading dataset:
2024-05-16 12:45:03,181-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 12:45:03,970-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 12:45:03,971-main.py:109-INFO-Loading model:
2024-05-16 12:45:03,972-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 12:45:03,979-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 12:45:04,446-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 12:45:04,447-main.py:462-INFO- * Speed: 27.94747 ms/iter
2024-05-16 12:45:04,447-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 12:45:04,447-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 12:45:04,447-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 12:45:04,448-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 12:45:04,448-main.py:469-INFO- Average Latency : 26.48541133 ms
2024-05-16 14:23:41,551-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:23:41,551-main.py:76-INFO-Loading dataset:
2024-05-16 14:24:42,707-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:24:42,707-main.py:76-INFO-Loading dataset:
2024-05-16 14:25:37,069-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:25:37,069-main.py:76-INFO-Loading dataset:
2024-05-16 14:25:41,806-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:25:42,598-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:25:42,599-main.py:109-INFO-Loading model:
2024-05-16 14:25:42,599-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:25:42,605-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:25:43,077-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:25:43,078-main.py:462-INFO- * Speed: 28.29890 ms/iter
2024-05-16 14:25:43,079-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:25:43,079-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:25:43,079-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:25:43,079-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:25:43,079-main.py:469-INFO- Average Latency : 26.71885490 ms
2024-05-16 14:29:49,570-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:29:49,570-main.py:76-INFO-Loading dataset:
2024-05-16 14:29:54,366-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:29:55,135-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:29:55,135-main.py:109-INFO-Loading model:
2024-05-16 14:29:55,138-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:29:55,146-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:29:55,610-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:29:55,610-main.py:462-INFO- * Speed: 27.67189 ms/iter
2024-05-16 14:29:55,610-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:29:55,611-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:29:55,611-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:29:55,611-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:29:55,611-main.py:469-INFO- Average Latency : 26.40253703 ms
2024-05-16 14:37:44,690-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:37:44,690-main.py:76-INFO-Loading dataset:
2024-05-16 14:37:49,487-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:37:50,280-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:37:50,281-main.py:109-INFO-Loading model:
2024-05-16 14:37:50,287-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:37:50,295-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:37:50,763-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:37:50,763-main.py:462-INFO- * Speed: 28.07916 ms/iter
2024-05-16 14:37:50,763-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:37:50,763-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:37:50,763-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:37:50,764-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:37:50,764-main.py:469-INFO- Average Latency : 26.35132472 ms
2024-05-16 14:46:08,894-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:46:08,895-main.py:76-INFO-Loading dataset:
2024-05-16 14:46:13,634-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:46:14,435-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:46:14,436-main.py:109-INFO-Loading model:
2024-05-16 14:46:14,439-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:46:14,445-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:46:14,917-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:46:14,917-main.py:462-INFO- * Speed: 28.34628 ms/iter
2024-05-16 14:46:14,917-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:46:14,917-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:46:14,918-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:46:14,918-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:46:14,918-main.py:469-INFO- Average Latency : 26.61871910 ms
2024-05-16 14:48:03,868-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:48:03,868-main.py:76-INFO-Loading dataset:
2024-05-16 14:48:04,701-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:48:05,503-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:48:05,504-main.py:109-INFO-Loading model:
2024-05-16 14:48:05,506-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:48:05,514-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:48:05,991-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:48:05,991-main.py:462-INFO- * Speed: 28.24899 ms/iter
2024-05-16 14:48:05,991-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:48:05,992-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:48:05,992-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:48:05,992-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:48:05,992-main.py:469-INFO- Average Latency : 26.92055702 ms
2024-05-16 14:50:10,614-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:50:10,614-main.py:76-INFO-Loading dataset:
2024-05-16 14:50:11,434-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:50:12,198-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:50:12,199-main.py:109-INFO-Loading model:
2024-05-16 14:50:12,202-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:50:12,209-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:50:12,681-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:50:12,681-main.py:462-INFO- * Speed: 28.18139 ms/iter
2024-05-16 14:50:12,681-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:50:12,682-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:50:12,682-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:50:12,682-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:50:12,682-main.py:469-INFO- Average Latency : 26.58670743 ms
2024-05-16 14:52:25,074-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:52:25,074-main.py:76-INFO-Loading dataset:
2024-05-16 14:52:25,882-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:52:26,671-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:52:26,671-main.py:109-INFO-Loading model:
2024-05-16 14:52:26,675-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:52:26,682-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:52:27,166-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:52:27,166-main.py:462-INFO- * Speed: 29.01125 ms/iter
2024-05-16 14:52:27,166-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:52:27,166-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:52:27,166-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:52:27,167-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:52:27,167-main.py:469-INFO- Average Latency : 27.41643588 ms
2024-05-16 14:59:15,387-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-16 14:59:15,387-main.py:76-INFO-Loading dataset:
2024-05-16 14:59:16,203-main.py:274-INFO-Train data = 2, Test data = 15
2024-05-16 14:59:16,977-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-16 14:59:16,977-main.py:109-INFO-Loading model:
2024-05-16 14:59:16,979-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:59:16,987-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-16 14:59:17,465-main.py:461-INFO- ------------------------------------------------------------------
2024-05-16 14:59:17,465-main.py:462-INFO- * Speed: 28.57658 ms/iter
2024-05-16 14:59:17,465-main.py:463-INFO- * MAPE: 3.24467
2024-05-16 14:59:17,466-main.py:464-INFO- * ErrorBound: [0.13333333 0.06666667 0.        ]
2024-05-16 14:59:17,466-main.py:465-INFO- * Kendall's Tau: 0.4976133515281193
2024-05-16 14:59:17,466-main.py:466-INFO- ------------------------------------------------------------------
2024-05-16 14:59:17,466-main.py:469-INFO- Average Latency : 26.91547076 ms
2024-05-17 13:15:44,336-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:15:44,336-main.py:76-INFO-Loading dataset:
2024-05-17 13:15:49,749-main.py:274-INFO-Train data = 2, Test data = 14
2024-05-17 13:15:51,091-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:15:51,092-main.py:109-INFO-Loading model:
2024-05-17 13:15:51,093-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:15:51,117-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:15:52,004-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:15:52,004-main.py:462-INFO- * Speed: 54.28163 ms/iter
2024-05-17 13:15:52,004-main.py:463-INFO- * MAPE: 3.38023
2024-05-17 13:15:52,004-main.py:464-INFO- * ErrorBound: [0.14285714 0.07142857 0.        ]
2024-05-17 13:15:52,004-main.py:465-INFO- * Kendall's Tau: 0.5164835164835165
2024-05-17 13:15:52,005-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:15:52,005-main.py:469-INFO- Average Latency : 51.92438194 ms
2024-05-17 13:19:10,823-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:19:10,823-main.py:76-INFO-Loading dataset:
2024-05-17 13:19:11,691-main.py:274-INFO-Train data = 2, Test data = 14
2024-05-17 13:19:12,473-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:19:12,474-main.py:109-INFO-Loading model:
2024-05-17 13:19:12,476-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:19:12,485-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:19:12,977-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:19:12,977-main.py:462-INFO- * Speed: 31.69164 ms/iter
2024-05-17 13:19:12,977-main.py:463-INFO- * MAPE: 3.38023
2024-05-17 13:19:12,977-main.py:464-INFO- * ErrorBound: [0.14285714 0.07142857 0.        ]
2024-05-17 13:19:12,978-main.py:465-INFO- * Kendall's Tau: 0.5164835164835165
2024-05-17 13:19:12,978-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:19:12,978-main.py:469-INFO- Average Latency : 30.33433642 ms
2024-05-17 13:20:48,728-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:20:48,728-main.py:76-INFO-Loading dataset:
2024-05-17 13:20:49,606-main.py:274-INFO-Train data = 2, Test data = 14
2024-05-17 13:20:50,386-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:20:50,387-main.py:109-INFO-Loading model:
2024-05-17 13:20:50,389-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:20:50,397-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:20:50,883-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:20:50,883-main.py:462-INFO- * Speed: 31.32958 ms/iter
2024-05-17 13:20:50,883-main.py:463-INFO- * MAPE: 3.38023
2024-05-17 13:20:50,884-main.py:464-INFO- * ErrorBound: [0.14285714 0.07142857 0.        ]
2024-05-17 13:20:50,884-main.py:465-INFO- * Kendall's Tau: 0.5164835164835165
2024-05-17 13:20:50,884-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:20:50,884-main.py:469-INFO- Average Latency : 29.75816386 ms
2024-05-17 13:22:31,049-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:22:31,050-main.py:76-INFO-Loading dataset:
2024-05-17 13:22:31,931-main.py:274-INFO-Train data = 2, Test data = 14
2024-05-17 13:22:32,714-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:22:32,715-main.py:109-INFO-Loading model:
2024-05-17 13:22:32,717-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:22:32,725-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:22:33,212-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:22:33,212-main.py:462-INFO- * Speed: 31.47152 ms/iter
2024-05-17 13:22:33,212-main.py:463-INFO- * MAPE: 3.38023
2024-05-17 13:22:33,213-main.py:464-INFO- * ErrorBound: [0.14285714 0.07142857 0.        ]
2024-05-17 13:22:33,213-main.py:465-INFO- * Kendall's Tau: 0.5164835164835165
2024-05-17 13:22:33,213-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:22:33,213-main.py:469-INFO- Average Latency : 29.90003995 ms
2024-05-17 13:37:23,290-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:37:23,297-main.py:76-INFO-Loading dataset:
2024-05-17 13:37:26,349-main.py:274-INFO-Train data = 2, Test data = 16
2024-05-17 13:37:27,128-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:37:27,129-main.py:109-INFO-Loading model:
2024-05-17 13:37:27,130-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:37:27,137-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:37:27,615-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:37:27,615-main.py:462-INFO- * Speed: 26.93750 ms/iter
2024-05-17 13:37:27,616-main.py:463-INFO- * MAPE: 2.99344
2024-05-17 13:37:27,616-main.py:464-INFO- * ErrorBound: [0.1875 0.125  0.    ]
2024-05-17 13:37:27,616-main.py:465-INFO- * Kendall's Tau: 0.5833333333333334
2024-05-17 13:37:27,616-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:37:27,616-main.py:469-INFO- Average Latency : 25.62472224 ms
2024-05-17 13:44:20,655-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:44:20,655-main.py:76-INFO-Loading dataset:
2024-05-17 13:44:21,496-main.py:274-INFO-Train data = 2, Test data = 17
2024-05-17 13:44:22,276-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:44:22,277-main.py:109-INFO-Loading model:
2024-05-17 13:44:22,278-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:44:22,285-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:44:22,762-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:44:22,763-main.py:462-INFO- * Speed: 25.27050 ms/iter
2024-05-17 13:44:22,763-main.py:463-INFO- * MAPE: 2.86817
2024-05-17 13:44:22,763-main.py:464-INFO- * ErrorBound: [0.17647059 0.11764706 0.        ]
2024-05-17 13:44:22,763-main.py:465-INFO- * Kendall's Tau: 0.5441176470588235
2024-05-17 13:44:22,763-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:44:22,764-main.py:469-INFO- Average Latency : 23.91746465 ms
2024-05-17 13:48:10,369-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:48:10,369-main.py:76-INFO-Loading dataset:
2024-05-17 13:48:11,199-main.py:274-INFO-Train data = 2, Test data = 17
2024-05-17 13:48:11,967-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:48:11,968-main.py:109-INFO-Loading model:
2024-05-17 13:48:11,969-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:48:11,976-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:48:12,456-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:48:12,456-main.py:462-INFO- * Speed: 25.33102 ms/iter
2024-05-17 13:48:12,456-main.py:463-INFO- * MAPE: 2.86817
2024-05-17 13:48:12,456-main.py:464-INFO- * ErrorBound: [0.17647059 0.11764706 0.        ]
2024-05-17 13:48:12,456-main.py:465-INFO- * Kendall's Tau: 0.5441176470588235
2024-05-17 13:48:12,456-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:48:12,457-main.py:469-INFO- Average Latency : 23.86025821 ms
2024-05-17 13:49:20,730-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 13:49:20,730-main.py:76-INFO-Loading dataset:
2024-05-17 13:49:21,568-main.py:274-INFO-Train data = 2, Test data = 18
2024-05-17 13:49:22,344-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 13:49:22,345-main.py:109-INFO-Loading model:
2024-05-17 13:49:22,346-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:49:22,352-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 13:49:22,839-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 13:49:22,839-main.py:462-INFO- * Speed: 24.15453 ms/iter
2024-05-17 13:49:22,839-main.py:463-INFO- * MAPE: 2.75236
2024-05-17 13:49:22,840-main.py:464-INFO- * ErrorBound: [0.16666667 0.11111111 0.        ]
2024-05-17 13:49:22,840-main.py:465-INFO- * Kendall's Tau: 0.5294117647058824
2024-05-17 13:49:22,840-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 13:49:22,840-main.py:469-INFO- Average Latency : 22.54350980 ms
2024-05-17 14:00:57,793-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 14:00:57,793-main.py:76-INFO-Loading dataset:
2024-05-17 14:00:59,703-main.py:274-INFO-Train data = 2, Test data = 18
2024-05-17 14:01:00,489-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 14:01:00,490-main.py:109-INFO-Loading model:
2024-05-17 14:01:00,491-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:01:00,498-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:01:00,985-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 14:01:00,986-main.py:462-INFO- * Speed: 24.44610 ms/iter
2024-05-17 14:01:00,986-main.py:463-INFO- * MAPE: 2.75236
2024-05-17 14:01:00,986-main.py:464-INFO- * ErrorBound: [0.16666667 0.11111111 0.        ]
2024-05-17 14:01:00,986-main.py:465-INFO- * Kendall's Tau: 0.5294117647058824
2024-05-17 14:01:00,987-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 14:01:00,987-main.py:469-INFO- Average Latency : 22.94588089 ms
2024-05-17 14:05:41,187-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 14:05:41,187-main.py:76-INFO-Loading dataset:
2024-05-17 14:05:43,555-main.py:274-INFO-Train data = 2, Test data = 18
2024-05-17 14:05:44,321-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 14:05:44,322-main.py:109-INFO-Loading model:
2024-05-17 14:05:44,323-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:05:44,330-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:05:44,808-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 14:05:44,808-main.py:462-INFO- * Speed: 23.92822 ms/iter
2024-05-17 14:05:44,808-main.py:463-INFO- * MAPE: 2.75236
2024-05-17 14:05:44,809-main.py:464-INFO- * ErrorBound: [0.16666667 0.11111111 0.        ]
2024-05-17 14:05:44,809-main.py:465-INFO- * Kendall's Tau: 0.5294117647058824
2024-05-17 14:05:44,809-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 14:05:44,809-main.py:469-INFO- Average Latency : 22.54315217 ms
2024-05-17 14:09:46,935-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 14:09:46,936-main.py:76-INFO-Loading dataset:
2024-05-17 14:10:00,766-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 14:10:00,766-main.py:76-INFO-Loading dataset:
2024-05-17 14:10:04,859-main.py:274-INFO-Train data = 18000, Test data = 2000
2024-05-17 14:10:05,630-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 14:10:05,631-main.py:109-INFO-Loading model:
2024-05-17 14:10:05,632-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:10:05,639-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:10:06,395-main.py:454-INFO-[50/2000] MAPE: 0.08457 ErrBnd: [0.7254902  0.56862745 0.23529412], Tau: 0.92941
2024-05-17 14:10:06,767-main.py:454-INFO-[100/2000] MAPE: 0.12248 ErrBnd: [0.67326733 0.5049505  0.20792079], Tau: 0.86139
2024-05-17 14:10:07,114-main.py:454-INFO-[150/2000] MAPE: 0.12351 ErrBnd: [0.67549669 0.52317881 0.1986755 ], Tau: 0.85448
2024-05-17 14:10:07,484-main.py:454-INFO-[200/2000] MAPE: 0.11452 ErrBnd: [0.68656716 0.54228856 0.19402985], Tau: 0.86776
2024-05-17 14:10:07,830-main.py:454-INFO-[250/2000] MAPE: 0.11220 ErrBnd: [0.68525896 0.53784861 0.17928287], Tau: 0.87574
2024-05-17 14:10:08,202-main.py:454-INFO-[300/2000] MAPE: 0.11135 ErrBnd: [0.68438538 0.5448505  0.18604651], Tau: 0.87148
2024-05-17 14:10:08,581-main.py:454-INFO-[350/2000] MAPE: 0.10917 ErrBnd: [0.6951567  0.55270655 0.18233618], Tau: 0.87630
2024-05-17 14:10:08,953-main.py:454-INFO-[400/2000] MAPE: 0.11380 ErrBnd: [0.6882793  0.5436409  0.18952618], Tau: 0.87042
2024-05-17 14:10:09,336-main.py:454-INFO-[450/2000] MAPE: 0.11274 ErrBnd: [0.6962306  0.54988914 0.19290466], Tau: 0.87389
2024-05-17 14:10:09,675-main.py:454-INFO-[500/2000] MAPE: 0.11532 ErrBnd: [0.69461078 0.5489022  0.18762475], Tau: 0.86915
2024-05-17 14:10:10,063-main.py:454-INFO-[550/2000] MAPE: 0.11861 ErrBnd: [0.68239564 0.53357532 0.17604356], Tau: 0.86195
2024-05-17 14:10:10,435-main.py:454-INFO-[600/2000] MAPE: 0.11944 ErrBnd: [0.67387687 0.52911814 0.17304493], Tau: 0.86275
2024-05-17 14:10:10,828-main.py:454-INFO-[650/2000] MAPE: 0.11990 ErrBnd: [0.67895545 0.53149002 0.16743472], Tau: 0.86312
2024-05-17 14:10:11,212-main.py:454-INFO-[700/2000] MAPE: 0.12050 ErrBnd: [0.67047076 0.52496434 0.16405136], Tau: 0.86387
2024-05-17 14:10:11,541-main.py:454-INFO-[750/2000] MAPE: 0.12033 ErrBnd: [0.66977364 0.52463382 0.16245007], Tau: 0.86376
2024-05-17 14:10:11,952-main.py:454-INFO-[800/2000] MAPE: 0.11905 ErrBnd: [0.67166042 0.52933833 0.16354557], Tau: 0.86553
2024-05-17 14:10:12,335-main.py:454-INFO-[850/2000] MAPE: 0.11728 ErrBnd: [0.6733255  0.52643948 0.16098707], Tau: 0.86924
2024-05-17 14:10:12,728-main.py:454-INFO-[900/2000] MAPE: 0.11582 ErrBnd: [0.67702553 0.52719201 0.15871254], Tau: 0.86909
2024-05-17 14:10:13,095-main.py:454-INFO-[950/2000] MAPE: 0.11557 ErrBnd: [0.67718191 0.5278654  0.15667718], Tau: 0.87003
2024-05-17 14:10:13,520-main.py:454-INFO-[1000/2000] MAPE: 0.11534 ErrBnd: [0.67732268 0.52747253 0.15884116], Tau: 0.86985
2024-05-17 14:10:13,950-main.py:454-INFO-[1050/2000] MAPE: 0.11660 ErrBnd: [0.67459562 0.52521408 0.15984776], Tau: 0.86725
2024-05-17 14:10:14,385-main.py:454-INFO-[1100/2000] MAPE: 0.11622 ErrBnd: [0.67393279 0.52497729 0.16076294], Tau: 0.86939
2024-05-17 14:10:14,825-main.py:454-INFO-[1150/2000] MAPE: 0.11643 ErrBnd: [0.67332754 0.52128584 0.15899218], Tau: 0.87084
2024-05-17 14:10:15,279-main.py:454-INFO-[1200/2000] MAPE: 0.11830 ErrBnd: [0.66944213 0.51956703 0.1582015 ], Tau: 0.86716
2024-05-17 14:10:15,717-main.py:454-INFO-[1250/2000] MAPE: 0.11988 ErrBnd: [0.66666667 0.51558753 0.15667466], Tau: 0.86410
2024-05-17 14:10:16,171-main.py:454-INFO-[1300/2000] MAPE: 0.11995 ErrBnd: [0.66717909 0.51729439 0.15833974], Tau: 0.86396
2024-05-17 14:10:16,555-main.py:454-INFO-[1350/2000] MAPE: 0.12134 ErrBnd: [0.66469282 0.51665433 0.15914138], Tau: 0.86413
2024-05-17 14:10:17,013-main.py:454-INFO-[1400/2000] MAPE: 0.12063 ErrBnd: [0.66452534 0.51748751 0.16131335], Tau: 0.86481
2024-05-17 14:10:17,458-main.py:454-INFO-[1450/2000] MAPE: 0.12188 ErrBnd: [0.66023432 0.51619573 0.16195727], Tau: 0.86374
2024-05-17 14:10:17,973-main.py:454-INFO-[1500/2000] MAPE: 0.12180 ErrBnd: [0.65756163 0.51499001 0.15922718], Tau: 0.86466
2024-05-17 14:10:18,451-main.py:454-INFO-[1550/2000] MAPE: 0.12147 ErrBnd: [0.65699549 0.51450677 0.15731786], Tau: 0.86566
2024-05-17 14:10:18,921-main.py:454-INFO-[1600/2000] MAPE: 0.12210 ErrBnd: [0.65708932 0.51405372 0.15677701], Tau: 0.86414
2024-05-17 14:10:19,384-main.py:454-INFO-[1650/2000] MAPE: 0.12356 ErrBnd: [0.65475469 0.51181102 0.15445185], Tau: 0.86201
2024-05-17 14:10:19,864-main.py:454-INFO-[1700/2000] MAPE: 0.12316 ErrBnd: [0.65667255 0.51205173 0.15402704], Tau: 0.86305
2024-05-17 14:10:20,322-main.py:454-INFO-[1750/2000] MAPE: 0.12349 ErrBnd: [0.65790977 0.5117076  0.1536265 ], Tau: 0.86253
2024-05-17 14:10:20,738-main.py:454-INFO-[1800/2000] MAPE: 0.12346 ErrBnd: [0.65963354 0.5141588  0.15546918], Tau: 0.86069
2024-05-17 14:10:21,084-main.py:454-INFO-[1850/2000] MAPE: 0.12299 ErrBnd: [0.66072393 0.51377634 0.15667207], Tau: 0.86117
2024-05-17 14:10:21,509-main.py:454-INFO-[1900/2000] MAPE: 0.12311 ErrBnd: [0.66017885 0.51183588 0.15570752], Tau: 0.86096
2024-05-17 14:10:21,971-main.py:454-INFO-[1950/2000] MAPE: 0.12392 ErrBnd: [0.65709892 0.50896976 0.15427986], Tau: 0.86035
2024-05-17 14:10:22,429-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 14:10:22,429-main.py:462-INFO- * Speed: 8.36968 ms/iter
2024-05-17 14:10:22,430-main.py:463-INFO- * MAPE: 0.12323
2024-05-17 14:10:22,430-main.py:464-INFO- * ErrorBound: [0.66   0.509  0.1555]
2024-05-17 14:10:22,430-main.py:465-INFO- * Kendall's Tau: 0.862052897094688
2024-05-17 14:10:22,430-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 14:10:22,431-main.py:469-INFO- Average Latency : 4.59916282 ms
2024-05-17 14:12:41,563-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 14:12:41,563-main.py:76-INFO-Loading dataset:
2024-05-17 14:12:58,232-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset2/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 14:12:58,233-main.py:76-INFO-Loading dataset:
2024-05-17 14:13:00,630-main.py:274-INFO-Train data = 2, Test data = 18
2024-05-17 14:13:01,407-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 14:13:01,408-main.py:109-INFO-Loading model:
2024-05-17 14:13:01,410-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:13:01,416-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 14:13:01,899-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 14:13:01,899-main.py:462-INFO- * Speed: 24.16265 ms/iter
2024-05-17 14:13:01,899-main.py:463-INFO- * MAPE: 2.75236
2024-05-17 14:13:01,900-main.py:464-INFO- * ErrorBound: [0.16666667 0.11111111 0.        ]
2024-05-17 14:13:01,900-main.py:465-INFO- * Kendall's Tau: 0.5294117647058824
2024-05-17 14:13:01,900-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 14:13:01,900-main.py:469-INFO- Average Latency : 22.77423276 ms
2024-05-17 21:16:18,654-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:16:18,654-main.py:76-INFO-Loading dataset:
2024-05-17 21:21:33,884-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:21:33,884-main.py:76-INFO-Loading dataset:
2024-05-17 21:22:22,351-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:22:22,351-main.py:76-INFO-Loading dataset:
2024-05-17 21:22:22,677-main.py:274-INFO-Train data = 0, Test data = 0
2024-05-17 21:23:19,696-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:23:19,696-main.py:76-INFO-Loading dataset:
2024-05-17 21:23:20,034-main.py:274-INFO-Train data = 1, Test data = 1
2024-05-17 21:23:20,815-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 21:23:20,816-main.py:109-INFO-Loading model:
2024-05-17 21:23:20,818-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:23:20,824-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:23:21,255-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 21:23:21,255-main.py:462-INFO- * Speed: 384.31096 ms/iter
2024-05-17 21:23:21,255-main.py:463-INFO- * MAPE: 0.32026
2024-05-17 21:23:21,256-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-17 21:23:21,256-main.py:465-INFO- * Kendall's Tau: nan
2024-05-17 21:23:21,256-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 21:23:21,256-main.py:469-INFO- Average Latency : 381.31141663 ms
2024-05-17 21:29:38,623-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:29:38,624-main.py:76-INFO-Loading dataset:
2024-05-17 21:29:38,956-main.py:274-INFO-Train data = 1, Test data = 2
2024-05-17 21:29:39,711-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 21:29:39,712-main.py:109-INFO-Loading model:
2024-05-17 21:29:39,713-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:29:39,720-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:29:40,144-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 21:29:40,144-main.py:462-INFO- * Speed: 188.46011 ms/iter
2024-05-17 21:29:40,144-main.py:463-INFO- * MAPE: 0.51175
2024-05-17 21:29:40,144-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-17 21:29:40,144-main.py:465-INFO- * Kendall's Tau: 1.0
2024-05-17 21:29:40,145-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 21:29:40,145-main.py:469-INFO- Average Latency : 186.45989895 ms
2024-05-17 21:34:17,366-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:34:17,367-main.py:76-INFO-Loading dataset:
2024-05-17 21:34:17,714-main.py:274-INFO-Train data = 1, Test data = 3
2024-05-17 21:34:18,486-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 21:34:18,486-main.py:109-INFO-Loading model:
2024-05-17 21:34:18,488-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:34:18,494-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:34:18,925-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 21:34:18,925-main.py:462-INFO- * Speed: 127.68102 ms/iter
2024-05-17 21:34:18,925-main.py:463-INFO- * MAPE: 0.61372
2024-05-17 21:34:18,925-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-17 21:34:18,925-main.py:465-INFO- * Kendall's Tau: -1.0
2024-05-17 21:34:18,925-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 21:34:18,926-main.py:469-INFO- Average Latency : 126.01423264 ms
2024-05-17 21:46:45,245-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:46:45,246-main.py:76-INFO-Loading dataset:
2024-05-17 21:46:45,569-main.py:274-INFO-Train data = 1, Test data = 4
2024-05-17 21:46:46,327-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 21:46:46,328-main.py:109-INFO-Loading model:
2024-05-17 21:46:46,330-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:46:46,336-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:46:46,770-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 21:46:46,770-main.py:462-INFO- * Speed: 96.90017 ms/iter
2024-05-17 21:46:46,770-main.py:463-INFO- * MAPE: 0.65837
2024-05-17 21:46:46,771-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-17 21:46:46,771-main.py:465-INFO- * Kendall's Tau: -1.0
2024-05-17 21:46:46,771-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 21:46:46,771-main.py:469-INFO- Average Latency : 95.40003538 ms
2024-05-17 21:47:36,166-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 21:47:36,166-main.py:76-INFO-Loading dataset:
2024-05-17 21:47:36,506-main.py:274-INFO-Train data = 1, Test data = 4
2024-05-17 21:47:37,269-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 21:47:37,270-main.py:109-INFO-Loading model:
2024-05-17 21:47:37,272-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:47:37,278-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 21:47:37,712-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 21:47:37,712-main.py:462-INFO- * Speed: 96.44532 ms/iter
2024-05-17 21:47:37,712-main.py:463-INFO- * MAPE: 0.67581
2024-05-17 21:47:37,713-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-17 21:47:37,713-main.py:465-INFO- * Kendall's Tau: -0.3333333333333334
2024-05-17 21:47:37,713-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 21:47:37,713-main.py:469-INFO- Average Latency : 95.19541264 ms
2024-05-17 22:18:53,045-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-17 22:18:53,045-main.py:76-INFO-Loading dataset:
2024-05-17 22:18:53,382-main.py:274-INFO-Train data = 1, Test data = 5
2024-05-17 22:18:54,171-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-17 22:18:54,172-main.py:109-INFO-Loading model:
2024-05-17 22:18:54,174-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-17 22:18:54,183-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-17 22:18:54,622-main.py:461-INFO- ------------------------------------------------------------------
2024-05-17 22:18:54,622-main.py:462-INFO- * Speed: 78.44687 ms/iter
2024-05-17 22:18:54,622-main.py:463-INFO- * MAPE: 0.72134
2024-05-17 22:18:54,622-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-17 22:18:54,622-main.py:465-INFO- * Kendall's Tau: -0.19999999999999998
2024-05-17 22:18:54,623-main.py:466-INFO- ------------------------------------------------------------------
2024-05-17 22:18:54,623-main.py:469-INFO- Average Latency : 76.64651871 ms
2024-05-18 00:12:37,498-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset1/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-18 00:12:37,498-main.py:76-INFO-Loading dataset:
2024-05-18 00:12:38,414-main.py:274-INFO-Train data = 1, Test data = 5
2024-05-18 00:12:39,206-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-18 00:12:39,208-main.py:109-INFO-Loading model:
2024-05-18 00:12:39,208-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-18 00:12:39,219-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-18 00:12:39,685-main.py:461-INFO- ------------------------------------------------------------------
2024-05-18 00:12:39,685-main.py:462-INFO- * Speed: 83.62565 ms/iter
2024-05-18 00:12:39,685-main.py:463-INFO- * MAPE: 0.72134
2024-05-18 00:12:39,686-main.py:464-INFO- * ErrorBound: [0. 0. 0.]
2024-05-18 00:12:39,686-main.py:465-INFO- * Kendall's Tau: -0.19999999999999998
2024-05-18 00:12:39,686-main.py:466-INFO- ------------------------------------------------------------------
2024-05-18 00:12:39,686-main.py:469-INFO- Average Latency : 82.02528954 ms
2024-05-21 13:50:53,325-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 13:50:53,325-main.py:76-INFO-Loading dataset:
2024-05-21 13:50:57,675-main.py:274-INFO-Train data = 1, Test data = 5
2024-05-21 13:50:58,974-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 13:50:58,975-main.py:109-INFO-Loading model:
2024-05-21 13:50:58,976-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 13:50:58,996-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 13:50:59,799-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 13:50:59,799-main.py:462-INFO- * Speed: 136.33113 ms/iter
2024-05-21 13:50:59,800-main.py:463-INFO- * MAPE: 9.43985
2024-05-21 13:50:59,800-main.py:464-INFO- * ErrorBound: [0.2 0.2 0. ]
2024-05-21 13:50:59,800-main.py:465-INFO- * Kendall's Tau: 0.19999999999999998
2024-05-21 13:50:59,800-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 13:50:59,800-main.py:469-INFO- Average Latency : 132.94234276 ms
2024-05-21 14:35:22,600-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 14:35:22,600-main.py:76-INFO-Loading dataset:
2024-05-21 14:35:27,249-main.py:274-INFO-Train data = 1, Test data = 6
2024-05-21 14:35:28,032-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 14:35:28,032-main.py:109-INFO-Loading model:
2024-05-21 14:35:28,033-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 14:35:28,039-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 14:35:28,474-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 14:35:28,474-main.py:462-INFO- * Speed: 64.77869 ms/iter
2024-05-21 14:35:28,474-main.py:463-INFO- * MAPE: 7.87060
2024-05-21 14:35:28,475-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 14:35:28,475-main.py:465-INFO- * Kendall's Tau: 0.41403933560541256
2024-05-21 14:35:28,475-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 14:35:28,475-main.py:469-INFO- Average Latency : 63.28384082 ms
2024-05-21 14:42:35,825-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 14:42:35,826-main.py:76-INFO-Loading dataset:
2024-05-21 14:42:40,367-main.py:274-INFO-Train data = 1, Test data = 6
2024-05-21 14:42:41,158-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 14:42:41,158-main.py:109-INFO-Loading model:
2024-05-21 14:42:41,159-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 14:42:41,166-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 14:42:41,601-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 14:42:41,601-main.py:462-INFO- * Speed: 64.48746 ms/iter
2024-05-21 14:42:41,601-main.py:463-INFO- * MAPE: 7.87060
2024-05-21 14:42:41,601-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 14:42:41,601-main.py:465-INFO- * Kendall's Tau: 0.41403933560541256
2024-05-21 14:42:41,602-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 14:42:41,602-main.py:469-INFO- Average Latency : 62.82595793 ms
2024-05-21 15:01:47,880-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:01:47,881-main.py:76-INFO-Loading dataset:
2024-05-21 15:01:48,438-main.py:274-INFO-Train data = 1, Test data = 6
2024-05-21 15:01:49,204-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:01:49,205-main.py:109-INFO-Loading model:
2024-05-21 15:01:49,206-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:01:49,213-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:01:49,641-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:01:49,641-main.py:462-INFO- * Speed: 63.51741 ms/iter
2024-05-21 15:01:49,641-main.py:463-INFO- * MAPE: 7.87060
2024-05-21 15:01:49,641-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 15:01:49,641-main.py:465-INFO- * Kendall's Tau: 0.41403933560541256
2024-05-21 15:01:49,641-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:01:49,642-main.py:469-INFO- Average Latency : 62.35460440 ms
2024-05-21 15:04:37,139-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:04:37,140-main.py:76-INFO-Loading dataset:
2024-05-21 15:04:42,979-main.py:274-INFO-Train data = 1, Test data = 6
2024-05-21 15:04:43,769-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:04:43,770-main.py:109-INFO-Loading model:
2024-05-21 15:04:43,771-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:04:43,777-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:04:44,218-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:04:44,218-main.py:462-INFO- * Speed: 65.32741 ms/iter
2024-05-21 15:04:44,218-main.py:463-INFO- * MAPE: 7.87060
2024-05-21 15:04:44,219-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 15:04:44,219-main.py:465-INFO- * Kendall's Tau: 0.41403933560541256
2024-05-21 15:04:44,219-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:04:44,219-main.py:469-INFO- Average Latency : 63.99714947 ms
2024-05-21 15:06:13,958-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:06:13,959-main.py:76-INFO-Loading dataset:
2024-05-21 15:06:18,642-main.py:274-INFO-Train data = 1, Test data = 6
2024-05-21 15:06:19,421-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:06:19,423-main.py:109-INFO-Loading model:
2024-05-21 15:06:19,424-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:06:19,430-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:06:19,868-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:06:19,868-main.py:462-INFO- * Speed: 65.03876 ms/iter
2024-05-21 15:06:19,868-main.py:463-INFO- * MAPE: 7.87060
2024-05-21 15:06:19,869-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 15:06:19,869-main.py:465-INFO- * Kendall's Tau: 0.41403933560541256
2024-05-21 15:06:19,869-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:06:19,869-main.py:469-INFO- Average Latency : 63.37769826 ms
2024-05-21 15:08:20,215-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:08:20,215-main.py:76-INFO-Loading dataset:
2024-05-21 15:08:24,942-main.py:274-INFO-Train data = 1, Test data = 6
2024-05-21 15:08:25,724-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:08:25,739-main.py:109-INFO-Loading model:
2024-05-21 15:08:25,740-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:08:25,746-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:08:26,184-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:08:26,185-main.py:462-INFO- * Speed: 64.77813 ms/iter
2024-05-21 15:08:26,185-main.py:463-INFO- * MAPE: 7.87060
2024-05-21 15:08:26,185-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 15:08:26,185-main.py:465-INFO- * Kendall's Tau: 0.41403933560541256
2024-05-21 15:08:26,185-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:08:26,185-main.py:469-INFO- Average Latency : 63.61544132 ms
2024-05-21 15:15:21,422-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:15:21,422-main.py:76-INFO-Loading dataset:
2024-05-21 15:15:22,171-main.py:274-INFO-Train data = 1, Test data = 6
2024-05-21 15:15:22,946-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:15:22,946-main.py:109-INFO-Loading model:
2024-05-21 15:15:22,948-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:15:22,954-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:15:23,392-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:15:23,392-main.py:462-INFO- * Speed: 64.83444 ms/iter
2024-05-21 15:15:23,392-main.py:463-INFO- * MAPE: 7.87060
2024-05-21 15:15:23,392-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 15:15:23,392-main.py:465-INFO- * Kendall's Tau: 0.41403933560541256
2024-05-21 15:15:23,392-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:15:23,393-main.py:469-INFO- Average Latency : 63.67154916 ms
2024-05-21 15:18:42,842-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:18:42,842-main.py:76-INFO-Loading dataset:
2024-05-21 15:18:47,848-main.py:274-INFO-Train data = 1, Test data = 7
2024-05-21 15:18:48,632-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:18:48,632-main.py:109-INFO-Loading model:
2024-05-21 15:18:48,633-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:18:48,639-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:18:49,082-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:18:49,083-main.py:462-INFO- * Speed: 56.18361 ms/iter
2024-05-21 15:18:49,083-main.py:463-INFO- * MAPE: 6.75311
2024-05-21 15:18:49,083-main.py:464-INFO- * ErrorBound: [0.42857143 0.42857143 0.        ]
2024-05-21 15:18:49,083-main.py:465-INFO- * Kendall's Tau: 0.5855400437691199
2024-05-21 15:18:49,083-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:18:49,083-main.py:469-INFO- Average Latency : 54.47503499 ms
2024-05-21 15:24:53,288-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:24:53,288-main.py:76-INFO-Loading dataset:
2024-05-21 15:24:58,437-main.py:274-INFO-Train data = 1, Test data = 7
2024-05-21 15:24:59,227-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:24:59,227-main.py:109-INFO-Loading model:
2024-05-21 15:24:59,228-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:24:59,235-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:24:59,675-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:24:59,675-main.py:462-INFO- * Speed: 56.00827 ms/iter
2024-05-21 15:24:59,676-main.py:463-INFO- * MAPE: 6.75311
2024-05-21 15:24:59,676-main.py:464-INFO- * ErrorBound: [0.42857143 0.42857143 0.        ]
2024-05-21 15:24:59,676-main.py:465-INFO- * Kendall's Tau: 0.5855400437691199
2024-05-21 15:24:59,676-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:24:59,676-main.py:469-INFO- Average Latency : 54.58446911 ms
2024-05-21 15:26:42,138-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:26:42,138-main.py:76-INFO-Loading dataset:
2024-05-21 15:26:43,371-main.py:274-INFO-Train data = 1, Test data = 8
2024-05-21 15:26:44,153-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:26:44,153-main.py:109-INFO-Loading model:
2024-05-21 15:26:44,154-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:26:44,161-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:26:44,605-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:26:44,605-main.py:462-INFO- * Speed: 49.50118 ms/iter
2024-05-21 15:26:44,605-main.py:463-INFO- * MAPE: 5.93791
2024-05-21 15:26:44,605-main.py:464-INFO- * ErrorBound: [0.375 0.375 0.   ]
2024-05-21 15:26:44,605-main.py:465-INFO- * Kendall's Tau: 0.5455447255899809
2024-05-21 15:26:44,605-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:26:44,606-main.py:469-INFO- Average Latency : 48.04238677 ms
2024-05-21 15:31:15,339-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:31:15,340-main.py:76-INFO-Loading dataset:
2024-05-21 15:31:15,946-main.py:274-INFO-Train data = 1, Test data = 8
2024-05-21 15:31:16,725-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:31:16,726-main.py:109-INFO-Loading model:
2024-05-21 15:31:16,727-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:31:16,733-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:31:17,175-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:31:17,175-main.py:462-INFO- * Speed: 49.46038 ms/iter
2024-05-21 15:31:17,175-main.py:463-INFO- * MAPE: 5.93791
2024-05-21 15:31:17,176-main.py:464-INFO- * ErrorBound: [0.375 0.375 0.   ]
2024-05-21 15:31:17,176-main.py:465-INFO- * Kendall's Tau: 0.5455447255899809
2024-05-21 15:31:17,176-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:31:17,176-main.py:469-INFO- Average Latency : 48.09007049 ms
2024-05-21 15:33:05,673-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:33:05,673-main.py:76-INFO-Loading dataset:
2024-05-21 15:33:06,689-main.py:274-INFO-Train data = 1, Test data = 9
2024-05-21 15:33:07,461-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:33:07,462-main.py:109-INFO-Loading model:
2024-05-21 15:33:07,463-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:33:07,470-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:33:07,919-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:33:07,919-main.py:462-INFO- * Speed: 44.57392 ms/iter
2024-05-21 15:33:07,919-main.py:463-INFO- * MAPE: 5.32620
2024-05-21 15:33:07,919-main.py:464-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-05-21 15:33:07,920-main.py:465-INFO- * Kendall's Tau: 0.5916079783099616
2024-05-21 15:33:07,920-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:33:07,920-main.py:469-INFO- Average Latency : 43.13431846 ms
2024-05-21 15:42:01,630-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:42:01,630-main.py:76-INFO-Loading dataset:
2024-05-21 15:42:02,116-main.py:274-INFO-Train data = 1, Test data = 10
2024-05-21 15:42:02,897-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:42:02,898-main.py:109-INFO-Loading model:
2024-05-21 15:42:02,899-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:42:02,905-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:42:03,360-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:42:03,360-main.py:462-INFO- * Speed: 40.76319 ms/iter
2024-05-21 15:42:03,360-main.py:463-INFO- * MAPE: 4.86158
2024-05-21 15:42:03,360-main.py:464-INFO- * ErrorBound: [0.3 0.3 0. ]
2024-05-21 15:42:03,360-main.py:465-INFO- * Kendall's Tau: 0.3595732599803958
2024-05-21 15:42:03,360-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:42:03,361-main.py:469-INFO- Average Latency : 39.36784267 ms
2024-05-21 15:44:54,602-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:44:54,602-main.py:76-INFO-Loading dataset:
2024-05-21 15:45:01,299-main.py:274-INFO-Train data = 1, Test data = 10
2024-05-21 15:45:02,087-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:45:02,087-main.py:109-INFO-Loading model:
2024-05-21 15:45:02,088-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:45:02,094-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:45:02,550-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:45:02,550-main.py:462-INFO- * Speed: 40.72535 ms/iter
2024-05-21 15:45:02,550-main.py:463-INFO- * MAPE: 4.86164
2024-05-21 15:45:02,550-main.py:464-INFO- * ErrorBound: [0.3 0.3 0. ]
2024-05-21 15:45:02,550-main.py:465-INFO- * Kendall's Tau: 0.3595732599803958
2024-05-21 15:45:02,551-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:45:02,551-main.py:469-INFO- Average Latency : 39.23094273 ms
2024-05-21 15:49:42,912-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:49:42,912-main.py:76-INFO-Loading dataset:
2024-05-21 15:49:49,636-main.py:274-INFO-Train data = 1, Test data = 10
2024-05-21 15:49:50,422-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:49:50,423-main.py:109-INFO-Loading model:
2024-05-21 15:49:50,424-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:49:50,430-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:49:50,883-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:49:50,883-main.py:462-INFO- * Speed: 40.56466 ms/iter
2024-05-21 15:49:50,883-main.py:463-INFO- * MAPE: 4.86151
2024-05-21 15:49:50,883-main.py:464-INFO- * ErrorBound: [0.3 0.3 0. ]
2024-05-21 15:49:50,884-main.py:465-INFO- * Kendall's Tau: 0.3595732599803958
2024-05-21 15:49:50,884-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:49:50,884-main.py:469-INFO- Average Latency : 39.20967579 ms
2024-05-21 15:57:09,951-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:57:09,951-main.py:76-INFO-Loading dataset:
2024-05-21 15:57:10,774-main.py:274-INFO-Train data = 1, Test data = 10
2024-05-21 15:57:11,548-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:57:11,549-main.py:109-INFO-Loading model:
2024-05-21 15:57:11,550-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:57:11,558-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:57:12,010-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:57:12,010-main.py:462-INFO- * Speed: 40.47189 ms/iter
2024-05-21 15:57:12,010-main.py:463-INFO- * MAPE: 4.86151
2024-05-21 15:57:12,010-main.py:464-INFO- * ErrorBound: [0.3 0.3 0. ]
2024-05-21 15:57:12,010-main.py:465-INFO- * Kendall's Tau: 0.3595732599803958
2024-05-21 15:57:12,011-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:57:12,011-main.py:469-INFO- Average Latency : 39.07659054 ms
2024-05-21 15:58:47,186-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 15:58:47,186-main.py:76-INFO-Loading dataset:
2024-05-21 15:58:48,777-main.py:274-INFO-Train data = 1, Test data = 11
2024-05-21 15:58:49,558-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 15:58:49,559-main.py:109-INFO-Loading model:
2024-05-21 15:58:49,560-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:58:49,567-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 15:58:50,027-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 15:58:50,027-main.py:462-INFO- * Speed: 37.29153 ms/iter
2024-05-21 15:58:50,027-main.py:463-INFO- * MAPE: 4.43795
2024-05-21 15:58:50,028-main.py:464-INFO- * ErrorBound: [0.27272727 0.27272727 0.        ]
2024-05-21 15:58:50,028-main.py:465-INFO- * Kendall's Tau: 0.4770842982214229
2024-05-21 15:58:50,028-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 15:58:50,028-main.py:469-INFO- Average Latency : 35.66267274 ms
2024-05-21 16:01:27,505-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:01:27,505-main.py:76-INFO-Loading dataset:
2024-05-21 16:01:28,327-main.py:274-INFO-Train data = 1, Test data = 12
2024-05-21 16:01:29,106-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:01:29,106-main.py:109-INFO-Loading model:
2024-05-21 16:01:29,107-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:01:29,114-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:01:29,571-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:01:29,571-main.py:462-INFO- * Speed: 34.24082 ms/iter
2024-05-21 16:01:29,571-main.py:463-INFO- * MAPE: 4.14127
2024-05-21 16:01:29,572-main.py:464-INFO- * ErrorBound: [0.25 0.25 0.  ]
2024-05-21 16:01:29,572-main.py:465-INFO- * Kendall's Tau: 0.2595495470347952
2024-05-21 16:01:29,572-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:01:29,572-main.py:469-INFO- Average Latency : 32.74583817 ms
2024-05-21 16:09:38,211-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:09:38,212-main.py:76-INFO-Loading dataset:
2024-05-21 16:09:38,977-main.py:274-INFO-Train data = 1, Test data = 13
2024-05-21 16:09:39,760-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:09:39,761-main.py:109-INFO-Loading model:
2024-05-21 16:09:39,762-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:09:39,768-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:09:40,232-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:09:40,232-main.py:462-INFO- * Speed: 31.97543 ms/iter
2024-05-21 16:09:40,232-main.py:463-INFO- * MAPE: 3.88593
2024-05-21 16:09:40,232-main.py:464-INFO- * ErrorBound: [0.23076923 0.23076923 0.        ]
2024-05-21 16:09:40,232-main.py:465-INFO- * Kendall's Tau: 0.16774542658006547
2024-05-21 16:09:40,232-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:09:40,232-main.py:469-INFO- Average Latency : 30.57677929 ms
2024-05-21 16:12:01,474-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:12:01,474-main.py:76-INFO-Loading dataset:
2024-05-21 16:12:01,799-main.py:274-INFO-Train data = 1, Test data = 13
2024-05-21 16:12:02,566-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:12:02,566-main.py:109-INFO-Loading model:
2024-05-21 16:12:02,568-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:12:02,575-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:12:03,029-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:12:03,029-main.py:462-INFO- * Speed: 31.42623 ms/iter
2024-05-21 16:12:03,030-main.py:463-INFO- * MAPE: 3.88593
2024-05-21 16:12:03,030-main.py:464-INFO- * ErrorBound: [0.23076923 0.23076923 0.        ]
2024-05-21 16:12:03,030-main.py:465-INFO- * Kendall's Tau: 0.16774542658006547
2024-05-21 16:12:03,030-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:12:03,030-main.py:469-INFO- Average Latency : 30.04631629 ms
2024-05-21 16:15:17,118-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:15:17,118-main.py:76-INFO-Loading dataset:
2024-05-21 16:15:17,442-main.py:274-INFO-Train data = 1, Test data = 13
2024-05-21 16:15:18,197-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:15:18,198-main.py:109-INFO-Loading model:
2024-05-21 16:15:18,199-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:15:18,206-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:15:18,662-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:15:18,662-main.py:462-INFO- * Speed: 31.51243 ms/iter
2024-05-21 16:15:18,662-main.py:463-INFO- * MAPE: 3.88593
2024-05-21 16:15:18,662-main.py:464-INFO- * ErrorBound: [0.23076923 0.23076923 0.        ]
2024-05-21 16:15:18,662-main.py:465-INFO- * Kendall's Tau: 0.16774542658006547
2024-05-21 16:15:18,662-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:15:18,663-main.py:469-INFO- Average Latency : 30.00083336 ms
2024-05-21 16:16:26,349-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:16:26,349-main.py:76-INFO-Loading dataset:
2024-05-21 16:16:36,004-main.py:274-INFO-Train data = 1, Test data = 13
2024-05-21 16:16:36,778-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:16:36,778-main.py:109-INFO-Loading model:
2024-05-21 16:16:36,779-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:16:36,785-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:16:37,238-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:16:37,238-main.py:462-INFO- * Speed: 31.26957 ms/iter
2024-05-21 16:16:37,239-main.py:463-INFO- * MAPE: 3.87977
2024-05-21 16:16:37,239-main.py:464-INFO- * ErrorBound: [0.23076923 0.23076923 0.        ]
2024-05-21 16:16:37,239-main.py:465-INFO- * Kendall's Tau: 0.29678037010319275
2024-05-21 16:16:37,240-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:16:37,240-main.py:469-INFO- Average Latency : 29.88952857 ms
2024-05-21 16:17:20,879-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:17:20,880-main.py:76-INFO-Loading dataset:
2024-05-21 16:17:21,327-main.py:274-INFO-Train data = 1, Test data = 13
2024-05-21 16:17:22,082-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:17:22,083-main.py:109-INFO-Loading model:
2024-05-21 16:17:22,084-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:17:22,090-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:17:22,543-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:17:22,543-main.py:462-INFO- * Speed: 31.26546 ms/iter
2024-05-21 16:17:22,544-main.py:463-INFO- * MAPE: 3.87977
2024-05-21 16:17:22,544-main.py:464-INFO- * ErrorBound: [0.23076923 0.23076923 0.        ]
2024-05-21 16:17:22,544-main.py:465-INFO- * Kendall's Tau: 0.29678037010319275
2024-05-21 16:17:22,544-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:17:22,544-main.py:469-INFO- Average Latency : 29.72074655 ms
2024-05-21 16:17:54,950-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:17:54,950-main.py:76-INFO-Loading dataset:
2024-05-21 16:18:05,155-main.py:274-INFO-Train data = 1, Test data = 14
2024-05-21 16:18:05,905-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:18:05,905-main.py:109-INFO-Loading model:
2024-05-21 16:18:05,906-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:18:05,913-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:18:06,372-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:18:06,372-main.py:462-INFO- * Speed: 29.43964 ms/iter
2024-05-21 16:18:06,372-main.py:463-INFO- * MAPE: 3.66227
2024-05-21 16:18:06,372-main.py:464-INFO- * ErrorBound: [0.21428571 0.21428571 0.        ]
2024-05-21 16:18:06,372-main.py:465-INFO- * Kendall's Tau: 0.19889806323953876
2024-05-21 16:18:06,373-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:18:06,373-main.py:469-INFO- Average Latency : 27.97981671 ms
2024-05-21 16:40:14,248-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:40:14,248-main.py:76-INFO-Loading dataset:
2024-05-21 16:40:15,581-main.py:274-INFO-Train data = 1, Test data = 15
2024-05-21 16:40:16,345-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:40:16,345-main.py:109-INFO-Loading model:
2024-05-21 16:40:16,347-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:40:16,354-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:40:16,814-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:40:16,814-main.py:462-INFO- * Speed: 27.59611 ms/iter
2024-05-21 16:40:16,814-main.py:463-INFO- * MAPE: 3.45775
2024-05-21 16:40:16,814-main.py:464-INFO- * ErrorBound: [0.2 0.2 0. ]
2024-05-21 16:40:16,814-main.py:465-INFO- * Kendall's Tau: 0.2870846258816073
2024-05-21 16:40:16,815-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:40:16,815-main.py:469-INFO- Average Latency : 26.00159645 ms
2024-05-21 16:58:48,482-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-21 16:58:48,483-main.py:76-INFO-Loading dataset:
2024-05-21 16:58:58,586-main.py:274-INFO-Train data = 1, Test data = 13
2024-05-21 16:58:59,372-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-21 16:58:59,373-main.py:109-INFO-Loading model:
2024-05-21 16:58:59,374-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:58:59,381-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-21 16:58:59,840-main.py:461-INFO- ------------------------------------------------------------------
2024-05-21 16:58:59,840-main.py:462-INFO- * Speed: 31.51268 ms/iter
2024-05-21 16:58:59,840-main.py:463-INFO- * MAPE: 0.53831
2024-05-21 16:58:59,840-main.py:464-INFO- * ErrorBound: [0.23076923 0.23076923 0.        ]
2024-05-21 16:58:59,840-main.py:465-INFO- * Kendall's Tau: 0.16774542658006547
2024-05-21 16:58:59,841-main.py:466-INFO- ------------------------------------------------------------------
2024-05-21 16:58:59,841-main.py:469-INFO- Average Latency : 30.03534904 ms
2024-05-22 22:10:06,784-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:10:06,784-main.py:76-INFO-Loading dataset:
2024-05-22 22:10:07,712-main.py:274-INFO-Train data = 1, Test data = 13
2024-05-22 22:10:09,008-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:10:09,009-main.py:109-INFO-Loading model:
2024-05-22 22:10:09,009-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:10:09,028-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:10:09,867-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:10:09,867-main.py:462-INFO- * Speed: 55.14343 ms/iter
2024-05-22 22:10:09,867-main.py:463-INFO- * MAPE: 0.53831
2024-05-22 22:10:09,868-main.py:464-INFO- * ErrorBound: [0.23076923 0.23076923 0.        ]
2024-05-22 22:10:09,868-main.py:465-INFO- * Kendall's Tau: 0.16774542658006547
2024-05-22 22:10:09,868-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:10:09,868-main.py:469-INFO- Average Latency : 52.78774408 ms
2024-05-22 22:12:21,240-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:12:21,240-main.py:76-INFO-Loading dataset:
2024-05-22 22:12:25,230-main.py:274-INFO-Train data = 1, Test data = 15
2024-05-22 22:12:26,009-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:12:26,010-main.py:109-INFO-Loading model:
2024-05-22 22:12:26,011-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:12:26,017-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:12:26,479-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:12:26,479-main.py:462-INFO- * Speed: 27.71168 ms/iter
2024-05-22 22:12:26,479-main.py:463-INFO- * MAPE: 0.54964
2024-05-22 22:12:26,480-main.py:464-INFO- * ErrorBound: [0.2 0.2 0. ]
2024-05-22 22:12:26,480-main.py:465-INFO- * Kendall's Tau: 0.09569487529386911
2024-05-22 22:12:26,480-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:12:26,480-main.py:469-INFO- Average Latency : 26.38484637 ms
2024-05-22 22:26:20,334-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:26:20,334-main.py:76-INFO-Loading dataset:
2024-05-22 22:26:26,543-main.py:274-INFO-Train data = 1, Test data = 19
2024-05-22 22:26:27,340-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:26:27,342-main.py:109-INFO-Loading model:
2024-05-22 22:26:27,343-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:26:27,349-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:26:27,834-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:26:27,834-main.py:462-INFO- * Speed: 22.94542 ms/iter
2024-05-22 22:26:27,834-main.py:463-INFO- * MAPE: 0.53291
2024-05-22 22:26:27,834-main.py:464-INFO- * ErrorBound: [0.15789474 0.15789474 0.        ]
2024-05-22 22:26:27,834-main.py:465-INFO- * Kendall's Tau: 0.08211179002574179
2024-05-22 22:26:27,834-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:26:27,835-main.py:469-INFO- Average Latency : 21.63396384 ms
2024-05-22 22:28:40,164-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:28:40,164-main.py:76-INFO-Loading dataset:
2024-05-22 22:29:01,991-main.py:274-INFO-Train data = 1, Test data = 19
2024-05-22 22:29:02,778-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:29:02,780-main.py:109-INFO-Loading model:
2024-05-22 22:29:02,781-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:29:02,788-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:29:03,297-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:29:03,297-main.py:462-INFO- * Speed: 24.34841 ms/iter
2024-05-22 22:29:03,297-main.py:463-INFO- * MAPE: 0.53697
2024-05-22 22:29:03,297-main.py:464-INFO- * ErrorBound: [0.15789474 0.15789474 0.        ]
2024-05-22 22:29:03,297-main.py:465-INFO- * Kendall's Tau: 0.0938420457437049
2024-05-22 22:29:03,298-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:29:03,298-main.py:469-INFO- Average Latency : 21.80393119 ms
2024-05-22 22:36:34,571-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:36:34,571-main.py:76-INFO-Loading dataset:
2024-05-22 22:36:54,978-main.py:274-INFO-Train data = 1, Test data = 20
2024-05-22 22:36:55,763-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:36:55,763-main.py:109-INFO-Loading model:
2024-05-22 22:36:55,765-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:36:55,771-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:36:56,253-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:36:56,253-main.py:462-INFO- * Speed: 21.77731 ms/iter
2024-05-22 22:36:56,253-main.py:463-INFO- * MAPE: 0.51374
2024-05-22 22:36:56,254-main.py:464-INFO- * ErrorBound: [0.15 0.15 0.  ]
2024-05-22 22:36:56,254-main.py:465-INFO- * Kendall's Tau: 0.07915594835766294
2024-05-22 22:36:56,254-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:36:56,254-main.py:469-INFO- Average Latency : 20.53145170 ms
2024-05-22 22:50:37,889-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:50:37,890-main.py:76-INFO-Loading dataset:
2024-05-22 22:50:58,745-main.py:274-INFO-Train data = 1, Test data = 20
2024-05-22 22:50:59,515-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:50:59,516-main.py:109-INFO-Loading model:
2024-05-22 22:50:59,517-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:50:59,523-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:51:00,006-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:51:00,006-main.py:462-INFO- * Speed: 21.82803 ms/iter
2024-05-22 22:51:00,006-main.py:463-INFO- * MAPE: 0.51374
2024-05-22 22:51:00,006-main.py:464-INFO- * ErrorBound: [0.15 0.15 0.  ]
2024-05-22 22:51:00,006-main.py:465-INFO- * Kendall's Tau: 0.07915594835766294
2024-05-22 22:51:00,006-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:51:00,007-main.py:469-INFO- Average Latency : 20.59727907 ms
2024-05-22 22:51:46,018-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:51:46,019-main.py:76-INFO-Loading dataset:
2024-05-22 22:51:47,406-main.py:274-INFO-Train data = 1, Test data = 20
2024-05-22 22:51:48,190-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:51:48,191-main.py:109-INFO-Loading model:
2024-05-22 22:51:48,192-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:51:48,199-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:51:48,689-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:51:48,689-main.py:462-INFO- * Speed: 22.16698 ms/iter
2024-05-22 22:51:48,689-main.py:463-INFO- * MAPE: 0.51374
2024-05-22 22:51:48,690-main.py:464-INFO- * ErrorBound: [0.15 0.15 0.  ]
2024-05-22 22:51:48,690-main.py:465-INFO- * Kendall's Tau: 0.07915594835766294
2024-05-22 22:51:48,690-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:51:48,690-main.py:469-INFO- Average Latency : 20.82136869 ms
2024-05-22 22:53:55,758-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 22:53:55,759-main.py:76-INFO-Loading dataset:
2024-05-22 22:53:56,860-main.py:274-INFO-Train data = 1, Test data = 21
2024-05-22 22:53:57,627-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 22:53:57,628-main.py:109-INFO-Loading model:
2024-05-22 22:53:57,629-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:53:57,636-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 22:53:58,142-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 22:53:58,142-main.py:462-INFO- * Speed: 21.71950 ms/iter
2024-05-22 22:53:58,143-main.py:463-INFO- * MAPE: 0.49326
2024-05-22 22:53:58,143-main.py:464-INFO- * ErrorBound: [0.19047619 0.14285714 0.        ]
2024-05-22 22:53:58,143-main.py:465-INFO- * Kendall's Tau: 0.0906923823984585
2024-05-22 22:53:58,143-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 22:53:58,143-main.py:469-INFO- Average Latency : 20.48559416 ms
2024-05-22 23:06:49,125-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-22 23:06:49,125-main.py:76-INFO-Loading dataset:
2024-05-22 23:06:50,662-main.py:274-INFO-Train data = 1, Test data = 22
2024-05-22 23:06:51,496-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-22 23:06:51,496-main.py:109-INFO-Loading model:
2024-05-22 23:06:51,497-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-22 23:06:51,507-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-22 23:06:52,029-main.py:461-INFO- ------------------------------------------------------------------
2024-05-22 23:06:52,029-main.py:462-INFO- * Speed: 21.34814 ms/iter
2024-05-22 23:06:52,029-main.py:463-INFO- * MAPE: 0.47188
2024-05-22 23:06:52,030-main.py:464-INFO- * ErrorBound: [0.22727273 0.18181818 0.        ]
2024-05-22 23:06:52,030-main.py:465-INFO- * Kendall's Tau: 0.12147534002635721
2024-05-22 23:06:52,030-main.py:466-INFO- ------------------------------------------------------------------
2024-05-22 23:06:52,030-main.py:469-INFO- Average Latency : 19.53597502 ms
2024-05-23 11:35:47,761-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-23 11:35:47,761-main.py:76-INFO-Loading dataset:
2024-05-23 11:35:48,108-main.py:274-INFO-Train data = 1, Test data = 22
2024-05-23 11:35:49,396-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-23 11:35:49,397-main.py:109-INFO-Loading model:
2024-05-23 11:35:49,398-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-23 11:35:49,418-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-23 11:35:50,317-main.py:461-INFO- ------------------------------------------------------------------
2024-05-23 11:35:50,317-main.py:462-INFO- * Speed: 35.07897 ms/iter
2024-05-23 11:35:50,317-main.py:463-INFO- * MAPE: 0.47188
2024-05-23 11:35:50,318-main.py:464-INFO- * ErrorBound: [0.22727273 0.18181818 0.        ]
2024-05-23 11:35:50,318-main.py:465-INFO- * Kendall's Tau: 0.12147534002635721
2024-05-23 11:35:50,318-main.py:466-INFO- ------------------------------------------------------------------
2024-05-23 11:35:50,318-main.py:469-INFO- Average Latency : 32.63300115 ms
2024-05-27 16:38:43,030-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 16:38:43,031-main.py:76-INFO-Loading dataset:
2024-05-27 16:38:43,370-main.py:274-INFO-Train data = 1, Test data = 22
2024-05-27 16:38:44,665-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 16:38:44,665-main.py:109-INFO-Loading model:
2024-05-27 16:38:44,667-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 16:38:44,689-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 16:38:45,579-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 16:38:45,579-main.py:462-INFO- * Speed: 34.69895 ms/iter
2024-05-27 16:38:45,580-main.py:463-INFO- * MAPE: 0.47188
2024-05-27 16:38:45,580-main.py:464-INFO- * ErrorBound: [0.22727273 0.18181818 0.        ]
2024-05-27 16:38:45,580-main.py:465-INFO- * Kendall's Tau: 0.12147534002635721
2024-05-27 16:38:45,580-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 16:38:45,580-main.py:469-INFO- Average Latency : 32.37416527 ms
2024-05-27 16:40:57,229-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 16:40:57,229-main.py:76-INFO-Loading dataset:
2024-05-27 16:40:58,619-main.py:274-INFO-Train data = 1, Test data = 23
2024-05-27 16:40:59,391-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 16:40:59,392-main.py:109-INFO-Loading model:
2024-05-27 16:40:59,393-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 16:40:59,399-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 16:40:59,907-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 16:40:59,907-main.py:462-INFO- * Speed: 20.03237 ms/iter
2024-05-27 16:40:59,907-main.py:463-INFO- * MAPE: 0.46581
2024-05-27 16:40:59,907-main.py:464-INFO- * ErrorBound: [0.2173913  0.17391304 0.        ]
2024-05-27 16:40:59,907-main.py:465-INFO- * Kendall's Tau: 0.15841615217391916
2024-05-27 16:40:59,908-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 16:40:59,908-main.py:469-INFO- Average Latency : 18.51056970 ms
2024-05-27 17:01:23,130-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 17:01:23,131-main.py:76-INFO-Loading dataset:
2024-05-27 17:01:51,851-main.py:274-INFO-Train data = 1, Test data = 23
2024-05-27 17:01:52,633-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 17:01:52,634-main.py:109-INFO-Loading model:
2024-05-27 17:01:52,635-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:01:52,642-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:01:53,151-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 17:01:53,151-main.py:462-INFO- * Speed: 19.97108 ms/iter
2024-05-27 17:01:53,151-main.py:463-INFO- * MAPE: 0.46444
2024-05-27 17:01:53,152-main.py:464-INFO- * ErrorBound: [0.2173913  0.17391304 0.        ]
2024-05-27 17:01:53,152-main.py:465-INFO- * Kendall's Tau: 0.11881211413043936
2024-05-27 17:01:53,152-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 17:01:53,152-main.py:469-INFO- Average Latency : 18.40578991 ms
2024-05-27 17:18:39,462-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 17:18:39,462-main.py:76-INFO-Loading dataset:
2024-05-27 17:18:41,109-main.py:274-INFO-Train data = 1, Test data = 24
2024-05-27 17:18:41,868-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 17:18:41,869-main.py:109-INFO-Loading model:
2024-05-27 17:18:41,870-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:18:41,878-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:18:42,377-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 17:18:42,377-main.py:462-INFO- * Speed: 18.80590 ms/iter
2024-05-27 17:18:42,377-main.py:463-INFO- * MAPE: 0.45450
2024-05-27 17:18:42,377-main.py:464-INFO- * ErrorBound: [0.20833333 0.16666667 0.        ]
2024-05-27 17:18:42,377-main.py:465-INFO- * Kendall's Tau: 0.11252287133929728
2024-05-27 17:18:42,377-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 17:18:42,378-main.py:469-INFO- Average Latency : 17.30589072 ms
2024-05-27 17:20:24,129-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 17:20:24,129-main.py:76-INFO-Loading dataset:
2024-05-27 17:20:25,557-main.py:274-INFO-Train data = 1, Test data = 25
2024-05-27 17:20:26,329-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 17:20:26,329-main.py:109-INFO-Loading model:
2024-05-27 17:20:26,331-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:20:26,337-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:20:26,839-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 17:20:26,839-main.py:462-INFO- * Speed: 18.20919 ms/iter
2024-05-27 17:20:26,839-main.py:463-INFO- * MAPE: 0.44866
2024-05-27 17:20:26,840-main.py:464-INFO- * ErrorBound: [0.2  0.16 0.  ]
2024-05-27 17:20:26,840-main.py:465-INFO- * Kendall's Tau: 0.1168615985764811
2024-05-27 17:20:26,840-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 17:20:26,840-main.py:469-INFO- Average Latency : 16.60534859 ms
2024-05-27 17:22:14,827-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 17:22:14,827-main.py:76-INFO-Loading dataset:
2024-05-27 17:22:15,587-main.py:274-INFO-Train data = 1, Test data = 26
2024-05-27 17:22:16,330-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 17:22:16,331-main.py:109-INFO-Loading model:
2024-05-27 17:22:16,332-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:22:16,339-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:22:16,849-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 17:22:16,849-main.py:462-INFO- * Speed: 17.79271 ms/iter
2024-05-27 17:22:16,849-main.py:463-INFO- * MAPE: 0.45939
2024-05-27 17:22:16,849-main.py:464-INFO- * ErrorBound: [0.19230769 0.15384615 0.        ]
2024-05-27 17:22:16,849-main.py:465-INFO- * Kendall's Tau: 0.08628669719059119
2024-05-27 17:22:16,849-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 17:22:16,850-main.py:469-INFO- Average Latency : 16.29277376 ms
2024-05-27 17:24:36,654-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 17:24:36,654-main.py:76-INFO-Loading dataset:
2024-05-27 17:24:38,627-main.py:274-INFO-Train data = 1, Test data = 27
2024-05-27 17:24:39,407-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 17:24:39,407-main.py:109-INFO-Loading model:
2024-05-27 17:24:39,409-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:24:39,415-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 17:24:39,930-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 17:24:39,931-main.py:462-INFO- * Speed: 17.30583 ms/iter
2024-05-27 17:24:39,931-main.py:463-INFO- * MAPE: 0.45420
2024-05-27 17:24:39,931-main.py:464-INFO- * ErrorBound: [0.18518519 0.14814815 0.        ]
2024-05-27 17:24:39,931-main.py:465-INFO- * Kendall's Tau: 0.1141227980029101
2024-05-27 17:24:39,931-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 17:24:39,931-main.py:469-INFO- Average Latency : 15.93545631 ms
2024-05-27 18:09:03,604-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-05-27 18:09:03,604-main.py:76-INFO-Loading dataset:
2024-05-27 18:09:05,568-main.py:274-INFO-Train data = 1, Test data = 28
2024-05-27 18:09:06,343-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-05-27 18:09:06,344-main.py:109-INFO-Loading model:
2024-05-27 18:09:06,345-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-05-27 18:09:06,351-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-05-27 18:09:06,869-main.py:461-INFO- ------------------------------------------------------------------
2024-05-27 18:09:06,869-main.py:462-INFO- * Speed: 16.80923 ms/iter
2024-05-27 18:09:06,869-main.py:463-INFO- * MAPE: 0.45324
2024-05-27 18:09:06,869-main.py:464-INFO- * ErrorBound: [0.17857143 0.14285714 0.        ]
2024-05-27 18:09:06,869-main.py:465-INFO- * Kendall's Tau: 0.1350994562514938
2024-05-27 18:09:06,870-main.py:466-INFO- ------------------------------------------------------------------
2024-05-27 18:09:06,870-main.py:469-INFO- Average Latency : 15.07140909 ms
2024-06-11 13:59:12,793-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-11 13:59:12,793-main.py:76-INFO-Loading dataset:
2024-06-11 13:59:21,619-main.py:274-INFO-Train data = 1, Test data = 8
2024-06-11 13:59:22,911-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-11 13:59:22,912-main.py:109-INFO-Loading model:
2024-06-11 13:59:22,913-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-11 13:59:22,933-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-11 13:59:23,749-main.py:463-INFO- ------------------------------------------------------------------
2024-06-11 13:59:23,749-main.py:464-INFO- * Speed: 87.39978 ms/iter
2024-06-11 13:59:23,749-main.py:465-INFO- * MAPE: 0.38898
2024-06-11 13:59:23,750-main.py:466-INFO- * ErrorBound: [0.125 0.    0.   ]
2024-06-11 13:59:23,750-main.py:467-INFO- * Kendall's Tau: -0.21428571428571427
2024-06-11 13:59:23,750-main.py:468-INFO- ------------------------------------------------------------------
2024-06-11 13:59:23,750-main.py:471-INFO- Average Latency : 81.14984632 ms
2024-06-11 14:04:48,173-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset3/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-11 14:04:48,174-main.py:76-INFO-Loading dataset:
2024-06-11 14:04:57,839-main.py:274-INFO-Train data = 1, Test data = 9
2024-06-11 14:04:58,606-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-11 14:04:58,606-main.py:109-INFO-Loading model:
2024-06-11 14:04:58,607-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-11 14:04:58,615-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-11 14:04:59,082-main.py:463-INFO- ------------------------------------------------------------------
2024-06-11 14:04:59,083-main.py:464-INFO- * Speed: 46.41493 ms/iter
2024-06-11 14:04:59,083-main.py:465-INFO- * MAPE: 0.42771
2024-06-11 14:04:59,083-main.py:466-INFO- * ErrorBound: [0. 0. 0.]
2024-06-11 14:04:59,083-main.py:467-INFO- * Kendall's Tau: -0.2222222222222222
2024-06-11 14:04:59,083-main.py:468-INFO- ------------------------------------------------------------------
2024-06-11 14:04:59,084-main.py:471-INFO- Average Latency : 43.97039943 ms
2024-06-11 15:07:42,956-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-11 15:07:42,957-main.py:76-INFO-Loading dataset:
2024-06-11 15:07:53,372-main.py:274-INFO-Train data = 1, Test data = 9
2024-06-11 15:07:54,165-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-11 15:07:54,166-main.py:109-INFO-Loading model:
2024-06-11 15:07:54,167-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-11 15:07:54,173-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-11 15:07:54,635-main.py:463-INFO- ------------------------------------------------------------------
2024-06-11 15:07:54,635-main.py:464-INFO- * Speed: 45.44632 ms/iter
2024-06-11 15:07:54,635-main.py:465-INFO- * MAPE: 0.58175
2024-06-11 15:07:54,635-main.py:466-INFO- * ErrorBound: [0.44444444 0.33333333 0.11111111]
2024-06-11 15:07:54,635-main.py:467-INFO- * Kendall's Tau: -0.5
2024-06-11 15:07:54,636-main.py:468-INFO- ------------------------------------------------------------------
2024-06-11 15:07:54,636-main.py:471-INFO- Average Latency : 42.77957810 ms
2024-06-11 17:03:11,076-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/gt_stage.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-11 17:03:11,076-main.py:76-INFO-Loading dataset:
2024-06-11 17:03:24,770-main.py:274-INFO-Train data = 1, Test data = 9
2024-06-11 17:03:25,562-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-11 17:03:25,563-main.py:109-INFO-Loading model:
2024-06-11 17:03:25,564-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-11 17:03:25,570-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-11 17:03:26,034-main.py:463-INFO- ------------------------------------------------------------------
2024-06-11 17:03:26,034-main.py:464-INFO- * Speed: 46.15312 ms/iter
2024-06-11 17:03:26,034-main.py:465-INFO- * MAPE: 0.58979
2024-06-11 17:03:26,034-main.py:466-INFO- * ErrorBound: [0.22222222 0.11111111 0.        ]
2024-06-11 17:03:26,035-main.py:467-INFO- * Kendall's Tau: 0.05555555555555555
2024-06-11 17:03:26,035-main.py:468-INFO- ------------------------------------------------------------------
2024-06-11 17:03:26,035-main.py:471-INFO- Average Latency : 43.51562924 ms
2024-06-24 14:07:18,993-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:08:03,358-main.py:76-INFO-Loading dataset:
2024-06-24 14:08:14,170-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 14:08:15,467-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:08:15,468-main.py:109-INFO-Loading model:
2024-06-24 14:08:15,469-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:08:15,490-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:08:16,345-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:08:16,345-main.py:463-INFO- * Speed: 37.20344 ms/iter
2024-06-24 14:08:16,345-main.py:464-INFO- * MAPE: 0.51777
2024-06-24 14:08:16,345-main.py:465-INFO- * ErrorBound: [0.1  0.05 0.  ]
2024-06-24 14:08:16,345-main.py:466-INFO- * Kendall's Tau: 0.2631578947368421
2024-06-24 14:08:16,346-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:08:16,346-main.py:470-INFO- Average Latency : 34.86130238 ms
2024-06-24 14:10:05,484-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mnasnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:10:05,484-main.py:76-INFO-Loading dataset:
2024-06-24 14:10:05,499-main.py:274-INFO-Train data = 1, Test data = 0
2024-06-24 14:10:06,247-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:10:06,248-main.py:109-INFO-Loading model:
2024-06-24 14:10:06,249-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:10:06,256-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:12:12,971-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mnasnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:12:12,971-main.py:76-INFO-Loading dataset:
2024-06-24 14:12:47,434-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 14:12:48,190-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:12:48,191-main.py:109-INFO-Loading model:
2024-06-24 14:12:48,192-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:12:48,198-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:12:48,702-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:12:48,702-main.py:463-INFO- * Speed: 22.81004 ms/iter
2024-06-24 14:12:48,702-main.py:464-INFO- * MAPE: 0.61662
2024-06-24 14:12:48,702-main.py:465-INFO- * ErrorBound: [0.1 0.  0. ]
2024-06-24 14:12:48,702-main.py:466-INFO- * Kendall's Tau: -0.09473684210526316
2024-06-24 14:12:48,702-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:12:48,703-main.py:470-INFO- Average Latency : 21.31484747 ms
2024-06-24 14:16:37,957-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:16:37,957-main.py:76-INFO-Loading dataset:
2024-06-24 14:16:55,382-main.py:274-INFO-Train data = 1, Test data = 17
2024-06-24 14:16:56,152-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:16:56,153-main.py:109-INFO-Loading model:
2024-06-24 14:16:56,154-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:16:56,164-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:16:56,659-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:16:56,659-main.py:463-INFO- * Speed: 26.15554 ms/iter
2024-06-24 14:16:56,659-main.py:464-INFO- * MAPE: 0.59514
2024-06-24 14:16:56,660-main.py:465-INFO- * ErrorBound: [0.11764706 0.05882353 0.        ]
2024-06-24 14:16:56,660-main.py:466-INFO- * Kendall's Tau: 0.0588235294117647
2024-06-24 14:16:56,660-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:16:56,660-main.py:470-INFO- Average Latency : 24.57245658 ms
2024-06-24 14:18:47,711-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:18:47,711-main.py:76-INFO-Loading dataset:
2024-06-24 14:18:50,721-main.py:274-INFO-Train data = 0, Test data = 19
2024-06-24 14:19:18,137-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:19:18,137-main.py:76-INFO-Loading dataset:
2024-06-24 14:19:18,144-main.py:274-INFO-Train data = 1, Test data = 18
2024-06-24 14:19:18,919-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:19:18,919-main.py:109-INFO-Loading model:
2024-06-24 14:19:18,920-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:19:18,927-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:19:19,442-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:19:19,442-main.py:463-INFO- * Speed: 25.65372 ms/iter
2024-06-24 14:19:19,442-main.py:464-INFO- * MAPE: 0.93451
2024-06-24 14:19:19,442-main.py:465-INFO- * ErrorBound: [0.05555556 0.         0.        ]
2024-06-24 14:19:19,443-main.py:466-INFO- * Kendall's Tau: -0.006535947712418302
2024-06-24 14:19:19,443-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:19:19,443-main.py:470-INFO- Average Latency : 24.04798402 ms
2024-06-24 14:19:54,954-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:19:54,955-main.py:76-INFO-Loading dataset:
2024-06-24 14:20:19,477-main.py:274-INFO-Train data = 1, Test data = 18
2024-06-24 14:20:20,246-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:20:20,246-main.py:109-INFO-Loading model:
2024-06-24 14:20:20,247-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:20:20,254-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:20:20,761-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:20:20,762-main.py:463-INFO- * Speed: 25.28648 ms/iter
2024-06-24 14:20:20,762-main.py:464-INFO- * MAPE: 0.83203
2024-06-24 14:20:20,762-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:20:20,762-main.py:466-INFO- * Kendall's Tau: 0.11111111111111112
2024-06-24 14:20:20,762-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:20:20,763-main.py:470-INFO- Average Latency : 23.68109756 ms
2024-06-24 14:24:37,944-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:24:37,944-main.py:76-INFO-Loading dataset:
2024-06-24 14:24:37,958-main.py:274-INFO-Train data = 0, Test data = 0
2024-06-24 14:26:25,886-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:26:25,887-main.py:76-INFO-Loading dataset:
2024-06-24 14:26:27,271-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-24 14:26:28,033-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:26:28,034-main.py:109-INFO-Loading model:
2024-06-24 14:26:28,034-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:26:28,040-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:26:28,544-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:26:28,545-main.py:463-INFO- * Speed: 24.01543 ms/iter
2024-06-24 14:26:28,545-main.py:464-INFO- * MAPE: 0.82092
2024-06-24 14:26:28,545-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:26:28,545-main.py:466-INFO- * Kendall's Tau: -0.14619883040935672
2024-06-24 14:26:28,546-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:26:28,546-main.py:470-INFO- Average Latency : 22.44156285 ms
2024-06-24 14:27:57,919-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/vgg16.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:27:57,919-main.py:76-INFO-Loading dataset:
2024-06-24 14:27:57,926-main.py:274-INFO-Train data = 0, Test data = 0
2024-06-24 14:28:51,874-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/vgg16.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:28:51,874-main.py:76-INFO-Loading dataset:
2024-06-24 14:29:28,686-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-24 14:29:29,459-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:29:29,459-main.py:109-INFO-Loading model:
2024-06-24 14:29:29,460-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:29:29,467-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:29:29,976-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:29:29,976-main.py:463-INFO- * Speed: 24.31273 ms/iter
2024-06-24 14:29:29,977-main.py:464-INFO- * MAPE: 0.78757
2024-06-24 14:29:29,977-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:29:29,977-main.py:466-INFO- * Kendall's Tau: 0.28654970760233917
2024-06-24 14:29:29,977-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:29:29,978-main.py:470-INFO- Average Latency : 22.73897121 ms
2024-06-24 14:31:29,761-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/vgg16.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:31:29,761-main.py:76-INFO-Loading dataset:
2024-06-24 14:31:29,768-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-24 14:31:30,519-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:31:30,520-main.py:109-INFO-Loading model:
2024-06-24 14:31:30,521-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:31:30,527-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:31:31,037-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:31:31,037-main.py:463-INFO- * Speed: 24.36497 ms/iter
2024-06-24 14:31:31,037-main.py:464-INFO- * MAPE: 0.78757
2024-06-24 14:31:31,038-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:31:31,038-main.py:466-INFO- * Kendall's Tau: 0.28654970760233917
2024-06-24 14:31:31,038-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:31:31,038-main.py:470-INFO- Average Latency : 22.73925982 ms
2024-06-24 14:33:58,651-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:33:58,651-main.py:76-INFO-Loading dataset:
2024-06-24 14:33:58,667-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 14:33:59,418-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:33:59,419-main.py:109-INFO-Loading model:
2024-06-24 14:33:59,420-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:33:59,427-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:33:59,951-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:33:59,951-main.py:463-INFO- * Speed: 23.78533 ms/iter
2024-06-24 14:33:59,951-main.py:464-INFO- * MAPE: 0.77732
2024-06-24 14:33:59,951-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:33:59,952-main.py:466-INFO- * Kendall's Tau: 0.2736842105263158
2024-06-24 14:33:59,952-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:33:59,952-main.py:470-INFO- Average Latency : 22.14074135 ms
2024-06-24 14:37:44,509-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:37:44,509-main.py:76-INFO-Loading dataset:
2024-06-24 14:38:04,654-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 14:38:05,431-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:38:05,431-main.py:109-INFO-Loading model:
2024-06-24 14:38:05,432-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:38:05,438-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:38:05,944-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:38:05,944-main.py:463-INFO- * Speed: 22.89344 ms/iter
2024-06-24 14:38:05,944-main.py:464-INFO- * MAPE: 0.64057
2024-06-24 14:38:05,945-main.py:465-INFO- * ErrorBound: [0.1  0.1  0.05]
2024-06-24 14:38:05,945-main.py:466-INFO- * Kendall's Tau: 0.010526315789473684
2024-06-24 14:38:05,945-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:38:05,945-main.py:470-INFO- Average Latency : 21.79690599 ms
2024-06-24 14:38:29,748-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mnasnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:38:29,749-main.py:76-INFO-Loading dataset:
2024-06-24 14:39:14,326-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 14:39:15,432-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:39:15,433-main.py:109-INFO-Loading model:
2024-06-24 14:39:15,434-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:39:15,445-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:39:16,217-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:39:16,217-main.py:463-INFO- * Speed: 35.10364 ms/iter
2024-06-24 14:39:16,217-main.py:464-INFO- * MAPE: 0.61662
2024-06-24 14:39:16,217-main.py:465-INFO- * ErrorBound: [0.1 0.  0. ]
2024-06-24 14:39:16,217-main.py:466-INFO- * Kendall's Tau: -0.09473684210526316
2024-06-24 14:39:16,218-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:39:16,218-main.py:470-INFO- Average Latency : 32.78098106 ms
2024-06-24 14:39:58,605-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:39:58,605-main.py:76-INFO-Loading dataset:
2024-06-24 14:40:17,168-main.py:274-INFO-Train data = 1, Test data = 17
2024-06-24 14:40:17,938-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:40:17,940-main.py:109-INFO-Loading model:
2024-06-24 14:40:17,941-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:40:17,947-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:40:18,462-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:40:18,462-main.py:463-INFO- * Speed: 27.51889 ms/iter
2024-06-24 14:40:18,463-main.py:464-INFO- * MAPE: 0.59514
2024-06-24 14:40:18,463-main.py:465-INFO- * ErrorBound: [0.11764706 0.05882353 0.        ]
2024-06-24 14:40:18,463-main.py:466-INFO- * Kendall's Tau: 0.0588235294117647
2024-06-24 14:40:18,463-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:40:18,463-main.py:470-INFO- Average Latency : 25.93626696 ms
2024-06-24 14:41:36,640-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:41:36,640-main.py:76-INFO-Loading dataset:
2024-06-24 14:42:02,362-main.py:274-INFO-Train data = 1, Test data = 18
2024-06-24 14:42:03,134-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:42:03,135-main.py:109-INFO-Loading model:
2024-06-24 14:42:03,136-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:42:03,143-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:42:03,642-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:42:03,642-main.py:463-INFO- * Speed: 25.10031 ms/iter
2024-06-24 14:42:03,642-main.py:464-INFO- * MAPE: 0.83203
2024-06-24 14:42:03,642-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:42:03,642-main.py:466-INFO- * Kendall's Tau: 0.11111111111111112
2024-06-24 14:42:03,642-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:42:03,643-main.py:470-INFO- Average Latency : 23.66994487 ms
2024-06-24 14:44:06,143-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:44:06,143-main.py:76-INFO-Loading dataset:
2024-06-24 14:44:07,528-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-24 14:44:08,301-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:44:08,302-main.py:109-INFO-Loading model:
2024-06-24 14:44:08,302-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:44:08,309-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:44:08,829-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:44:08,829-main.py:463-INFO- * Speed: 24.86385 ms/iter
2024-06-24 14:44:08,829-main.py:464-INFO- * MAPE: 0.82092
2024-06-24 14:44:08,829-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:44:08,830-main.py:466-INFO- * Kendall's Tau: -0.14619883040935672
2024-06-24 14:44:08,830-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:44:08,830-main.py:470-INFO- Average Latency : 23.29025770 ms
2024-06-24 14:45:53,843-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/vgg16.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 14:45:53,843-main.py:76-INFO-Loading dataset:
2024-06-24 14:46:31,128-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-24 14:46:31,909-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 14:46:31,910-main.py:109-INFO-Loading model:
2024-06-24 14:46:31,910-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:46:31,917-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 14:46:32,437-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 14:46:32,437-main.py:463-INFO- * Speed: 24.67010 ms/iter
2024-06-24 14:46:32,438-main.py:464-INFO- * MAPE: 0.78757
2024-06-24 14:46:32,438-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-24 14:46:32,438-main.py:466-INFO- * Kendall's Tau: 0.28654970760233917
2024-06-24 14:46:32,438-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 14:46:32,438-main.py:470-INFO- Average Latency : 23.14883784 ms
2024-06-24 19:12:03,177-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 19:12:03,177-main.py:76-INFO-Loading dataset:
2024-06-24 19:12:04,666-main.py:274-INFO-Train data = 1, Test data = 16
2024-06-24 19:12:05,468-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 19:12:05,470-main.py:109-INFO-Loading model:
2024-06-24 19:12:05,471-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 19:12:05,479-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 19:12:06,027-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 19:12:06,027-main.py:463-INFO- * Speed: 31.19199 ms/iter
2024-06-24 19:12:06,027-main.py:464-INFO- * MAPE: 0.42069
2024-06-24 19:12:06,028-main.py:465-INFO- * ErrorBound: [0.0625 0.0625 0.    ]
2024-06-24 19:12:06,028-main.py:466-INFO- * Kendall's Tau: 0.19999999999999998
2024-06-24 19:12:06,028-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 19:12:06,028-main.py:470-INFO- Average Latency : 29.75909412 ms
2024-06-24 19:18:56,301-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 19:18:56,301-main.py:76-INFO-Loading dataset:
2024-06-24 19:18:56,308-main.py:274-INFO-Train data = 1, Test data = 16
2024-06-24 19:18:57,059-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 19:18:57,060-main.py:109-INFO-Loading model:
2024-06-24 19:18:57,061-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 19:18:57,068-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 19:18:57,549-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 19:18:57,550-main.py:463-INFO- * Speed: 27.12041 ms/iter
2024-06-24 19:18:57,550-main.py:464-INFO- * MAPE: 0.42069
2024-06-24 19:18:57,551-main.py:465-INFO- * ErrorBound: [0.0625 0.0625 0.    ]
2024-06-24 19:18:57,551-main.py:466-INFO- * Kendall's Tau: 0.19999999999999998
2024-06-24 19:18:57,551-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 19:18:57,551-main.py:470-INFO- Average Latency : 25.56300163 ms
2024-06-24 20:11:00,548-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 20:11:00,548-main.py:76-INFO-Loading dataset:
2024-06-24 20:11:01,931-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-24 20:11:02,683-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 20:11:02,684-main.py:109-INFO-Loading model:
2024-06-24 20:11:02,685-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 20:11:02,692-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 20:11:03,220-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 20:11:03,220-main.py:463-INFO- * Speed: 24.54063 ms/iter
2024-06-24 20:11:03,220-main.py:464-INFO- * MAPE: 0.33965
2024-06-24 20:11:03,221-main.py:465-INFO- * ErrorBound: [0.05263158 0.05263158 0.        ]
2024-06-24 20:11:03,221-main.py:466-INFO- * Kendall's Tau: 0.23976608187134502
2024-06-24 20:11:03,221-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 20:11:03,221-main.py:470-INFO- Average Latency : 23.07184119 ms
2024-06-24 20:26:55,476-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 20:26:55,476-main.py:76-INFO-Loading dataset:
2024-06-24 20:26:56,844-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-24 20:26:57,595-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 20:26:57,595-main.py:109-INFO-Loading model:
2024-06-24 20:26:57,596-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 20:26:57,603-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 20:26:58,104-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 20:26:58,105-main.py:463-INFO- * Speed: 23.95201 ms/iter
2024-06-24 20:26:58,105-main.py:464-INFO- * MAPE: 0.33965
2024-06-24 20:26:58,105-main.py:465-INFO- * ErrorBound: [0.05263158 0.05263158 0.        ]
2024-06-24 20:26:58,105-main.py:466-INFO- * Kendall's Tau: 0.23976608187134502
2024-06-24 20:26:58,105-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 20:26:58,105-main.py:470-INFO- Average Latency : 22.27342756 ms
2024-06-24 20:29:09,042-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 20:29:09,042-main.py:76-INFO-Loading dataset:
2024-06-24 20:29:09,098-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 20:29:09,845-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 20:29:09,846-main.py:109-INFO-Loading model:
2024-06-24 20:29:09,846-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 20:29:09,853-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 20:29:10,354-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 20:29:10,354-main.py:463-INFO- * Speed: 22.69442 ms/iter
2024-06-24 20:29:10,354-main.py:464-INFO- * MAPE: 0.36535
2024-06-24 20:29:10,354-main.py:465-INFO- * ErrorBound: [0.05 0.05 0.  ]
2024-06-24 20:29:10,354-main.py:466-INFO- * Kendall's Tau: 0.2105263157894737
2024-06-24 20:29:10,355-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 20:29:10,355-main.py:470-INFO- Average Latency : 21.00009918 ms
2024-06-24 21:07:04,364-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 21:07:04,364-main.py:76-INFO-Loading dataset:
2024-06-24 21:07:04,371-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 21:07:05,115-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 21:07:05,115-main.py:109-INFO-Loading model:
2024-06-24 21:07:05,116-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 21:07:05,122-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 21:07:05,640-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 21:07:05,640-main.py:463-INFO- * Speed: 23.54995 ms/iter
2024-06-24 21:07:05,641-main.py:464-INFO- * MAPE: 0.36535
2024-06-24 21:07:05,641-main.py:465-INFO- * ErrorBound: [0.05 0.05 0.  ]
2024-06-24 21:07:05,641-main.py:466-INFO- * Kendall's Tau: 0.2105263157894737
2024-06-24 21:07:05,641-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 21:07:05,641-main.py:470-INFO- Average Latency : 22.00520039 ms
2024-06-24 21:07:48,900-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 21:07:48,900-main.py:76-INFO-Loading dataset:
2024-06-24 21:07:48,963-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-24 21:07:49,713-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 21:07:49,714-main.py:109-INFO-Loading model:
2024-06-24 21:07:49,715-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 21:07:49,721-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 21:07:50,229-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 21:07:50,229-main.py:463-INFO- * Speed: 23.01100 ms/iter
2024-06-24 21:07:50,229-main.py:464-INFO- * MAPE: 0.36427
2024-06-24 21:07:50,229-main.py:465-INFO- * ErrorBound: [0.05 0.05 0.  ]
2024-06-24 21:07:50,229-main.py:466-INFO- * Kendall's Tau: 0.2105263157894737
2024-06-24 21:07:50,230-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 21:07:50,230-main.py:470-INFO- Average Latency : 21.36672735 ms
2024-06-24 21:26:09,394-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-24 21:26:09,394-main.py:76-INFO-Loading dataset:
2024-06-24 21:26:09,434-main.py:274-INFO-Train data = 1, Test data = 21
2024-06-24 21:26:10,177-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-24 21:26:10,178-main.py:109-INFO-Loading model:
2024-06-24 21:26:10,179-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-24 21:26:10,186-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-24 21:26:10,710-main.py:462-INFO- ------------------------------------------------------------------
2024-06-24 21:26:10,710-main.py:463-INFO- * Speed: 22.70535 ms/iter
2024-06-24 21:26:10,710-main.py:464-INFO- * MAPE: 0.36336
2024-06-24 21:26:10,710-main.py:465-INFO- * ErrorBound: [0.04761905 0.04761905 0.        ]
2024-06-24 21:26:10,711-main.py:466-INFO- * Kendall's Tau: 0.24761904761904766
2024-06-24 21:26:10,711-main.py:467-INFO- ------------------------------------------------------------------
2024-06-24 21:26:10,711-main.py:470-INFO- Average Latency : 21.09166554 ms
2024-06-25 12:01:31,711-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 12:01:31,712-main.py:76-INFO-Loading dataset:
2024-06-25 12:01:47,600-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-25 12:01:48,939-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 12:01:48,940-main.py:109-INFO-Loading model:
2024-06-25 12:01:48,941-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 12:01:48,960-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 12:01:49,840-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 12:01:49,840-main.py:463-INFO- * Speed: 38.24564 ms/iter
2024-06-25 12:01:49,840-main.py:464-INFO- * MAPE: 0.62526
2024-06-25 12:01:49,841-main.py:465-INFO- * ErrorBound: [0.1  0.05 0.  ]
2024-06-25 12:01:49,841-main.py:466-INFO- * Kendall's Tau: -0.031578947368421054
2024-06-25 12:01:49,841-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 12:01:49,841-main.py:470-INFO- Average Latency : 36.40190363 ms
2024-06-25 12:35:56,917-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 12:35:56,918-main.py:76-INFO-Loading dataset:
2024-06-25 12:36:12,883-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-25 12:36:13,658-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 12:36:13,659-main.py:109-INFO-Loading model:
2024-06-25 12:36:13,660-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 12:36:13,667-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 12:36:14,170-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 12:36:14,170-main.py:463-INFO- * Speed: 22.79156 ms/iter
2024-06-25 12:36:14,170-main.py:464-INFO- * MAPE: 0.62526
2024-06-25 12:36:14,171-main.py:465-INFO- * ErrorBound: [0.1  0.05 0.  ]
2024-06-25 12:36:14,171-main.py:466-INFO- * Kendall's Tau: -0.031578947368421054
2024-06-25 12:36:14,171-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 12:36:14,171-main.py:470-INFO- Average Latency : 21.54579163 ms
2024-06-25 12:36:34,300-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 12:36:34,301-main.py:76-INFO-Loading dataset:
2024-06-25 12:36:34,632-main.py:274-INFO-Train data = 1, Test data = 5
2024-06-25 12:36:35,400-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 12:36:35,401-main.py:109-INFO-Loading model:
2024-06-25 12:36:35,402-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 12:36:35,408-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 12:36:35,849-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 12:36:35,849-main.py:463-INFO- * Speed: 78.76711 ms/iter
2024-06-25 12:36:35,849-main.py:464-INFO- * MAPE: 0.60136
2024-06-25 12:36:35,849-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-25 12:36:35,849-main.py:466-INFO- * Kendall's Tau: -0.39999999999999997
2024-06-25 12:36:35,849-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 12:36:35,850-main.py:470-INFO- Average Latency : 77.16879845 ms
2024-06-25 13:09:24,514-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 13:09:24,514-main.py:76-INFO-Loading dataset:
2024-06-25 13:09:46,646-main.py:274-INFO-Train data = 1, Test data = 28
2024-06-25 13:09:47,429-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 13:09:47,430-main.py:109-INFO-Loading model:
2024-06-25 13:09:47,432-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 13:09:47,440-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 13:09:47,967-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 13:09:47,967-main.py:463-INFO- * Speed: 17.17131 ms/iter
2024-06-25 13:09:47,967-main.py:464-INFO- * MAPE: 0.72989
2024-06-25 13:09:47,968-main.py:465-INFO- * ErrorBound: [0.07142857 0.03571429 0.        ]
2024-06-25 13:09:47,968-main.py:466-INFO- * Kendall's Tau: -0.037037037037037035
2024-06-25 13:09:47,968-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 13:09:47,968-main.py:470-INFO- Average Latency : 15.78291825 ms
2024-06-25 13:10:49,650-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 13:10:49,651-main.py:76-INFO-Loading dataset:
2024-06-25 13:10:49,658-main.py:274-INFO-Train data = 1, Test data = 28
2024-06-25 13:10:50,424-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 13:10:50,425-main.py:109-INFO-Loading model:
2024-06-25 13:10:50,426-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 13:10:50,432-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 13:10:50,959-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 13:10:50,959-main.py:463-INFO- * Speed: 17.17821 ms/iter
2024-06-25 13:10:50,959-main.py:464-INFO- * MAPE: 0.72989
2024-06-25 13:10:50,960-main.py:465-INFO- * ErrorBound: [0.07142857 0.03571429 0.        ]
2024-06-25 13:10:50,960-main.py:466-INFO- * Kendall's Tau: -0.037037037037037035
2024-06-25 13:10:50,960-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 13:10:50,960-main.py:470-INFO- Average Latency : 15.64755610 ms
2024-06-25 13:48:58,429-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 13:48:58,429-main.py:76-INFO-Loading dataset:
2024-06-25 13:49:22,260-main.py:274-INFO-Train data = 1, Test data = 32
2024-06-25 13:49:23,036-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 13:49:23,037-main.py:109-INFO-Loading model:
2024-06-25 13:49:23,038-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 13:49:23,044-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 13:49:23,585-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 13:49:23,586-main.py:463-INFO- * Speed: 15.43430 ms/iter
2024-06-25 13:49:23,586-main.py:464-INFO- * MAPE: 0.73420
2024-06-25 13:49:23,586-main.py:465-INFO- * ErrorBound: [0.0625  0.03125 0.     ]
2024-06-25 13:49:23,586-main.py:466-INFO- * Kendall's Tau: 0.040322580645161296
2024-06-25 13:49:23,586-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 13:49:23,586-main.py:470-INFO- Average Latency : 14.25063610 ms
2024-06-25 14:25:40,434-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 14:25:40,435-main.py:76-INFO-Loading dataset:
2024-06-25 14:25:41,273-main.py:274-INFO-Train data = 1, Test data = 11
2024-06-25 14:25:42,014-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 14:25:42,015-main.py:109-INFO-Loading model:
2024-06-25 14:25:42,017-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 14:25:42,024-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 14:25:42,484-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 14:25:42,484-main.py:463-INFO- * Speed: 37.45172 ms/iter
2024-06-25 14:25:42,484-main.py:464-INFO- * MAPE: 0.60040
2024-06-25 14:25:42,484-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-25 14:25:42,485-main.py:466-INFO- * Kendall's Tau: -0.41818181818181815
2024-06-25 14:25:42,485-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 14:25:42,485-main.py:470-INFO- Average Latency : 36.00192070 ms
2024-06-25 14:47:27,939-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 14:47:27,939-main.py:76-INFO-Loading dataset:
2024-06-25 14:48:15,526-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 14:48:15,526-main.py:76-INFO-Loading dataset:
2024-06-25 14:48:37,286-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 14:48:37,287-main.py:76-INFO-Loading dataset:
2024-06-25 14:49:35,869-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 14:49:35,869-main.py:76-INFO-Loading dataset:
2024-06-25 14:49:36,695-main.py:274-INFO-Train data = 1, Test data = 11
2024-06-25 14:49:37,440-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 14:49:37,441-main.py:109-INFO-Loading model:
2024-06-25 14:49:37,442-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 14:49:37,448-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 14:49:37,940-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 14:49:37,940-main.py:463-INFO- * Speed: 40.53460 ms/iter
2024-06-25 14:49:37,941-main.py:464-INFO- * MAPE: 0.60040
2024-06-25 14:49:37,941-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-25 14:49:37,941-main.py:466-INFO- * Kendall's Tau: -0.41818181818181815
2024-06-25 14:49:37,941-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 14:49:37,941-main.py:470-INFO- Average Latency : 39.08497637 ms
2024-06-25 14:50:17,227-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 14:50:17,228-main.py:76-INFO-Loading dataset:
2024-06-25 14:50:20,528-main.py:274-INFO-Train data = 1, Test data = 3
2024-06-25 14:50:21,309-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 14:50:21,309-main.py:109-INFO-Loading model:
2024-06-25 14:50:21,310-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 14:50:21,317-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 14:50:21,743-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 14:50:21,743-main.py:463-INFO- * Speed: 126.11000 ms/iter
2024-06-25 14:50:21,743-main.py:464-INFO- * MAPE: 19.01178
2024-06-25 14:50:21,744-main.py:465-INFO- * ErrorBound: [0.33333333 0.33333333 0.        ]
2024-06-25 14:50:21,744-main.py:466-INFO- * Kendall's Tau: -1.0
2024-06-25 14:50:21,744-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 14:50:21,744-main.py:470-INFO- Average Latency : 124.44885572 ms
2024-06-25 16:43:55,800-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 16:43:55,801-main.py:76-INFO-Loading dataset:
2024-06-25 16:43:56,894-main.py:274-INFO-Train data = 1, Test data = 15
2024-06-25 16:43:57,655-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 16:43:57,655-main.py:109-INFO-Loading model:
2024-06-25 16:43:57,656-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 16:43:57,662-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 16:43:58,134-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 16:43:58,134-main.py:463-INFO- * Speed: 28.34489 ms/iter
2024-06-25 16:43:58,134-main.py:464-INFO- * MAPE: 0.56470
2024-06-25 16:43:58,134-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-25 16:43:58,134-main.py:466-INFO- * Kendall's Tau: -0.33333333333333337
2024-06-25 16:43:58,134-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 16:43:58,135-main.py:470-INFO- Average Latency : 27.01590856 ms
2024-06-25 16:53:37,509-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 16:53:37,510-main.py:76-INFO-Loading dataset:
2024-06-25 16:53:37,580-main.py:274-INFO-Train data = 1, Test data = 16
2024-06-25 16:53:38,332-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 16:53:38,333-main.py:109-INFO-Loading model:
2024-06-25 16:53:38,334-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 16:53:38,340-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 16:53:38,820-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 16:53:38,820-main.py:463-INFO- * Speed: 27.01227 ms/iter
2024-06-25 16:53:38,820-main.py:464-INFO- * MAPE: 0.54010
2024-06-25 16:53:38,820-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-25 16:53:38,820-main.py:466-INFO- * Kendall's Tau: -0.3
2024-06-25 16:53:38,821-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 16:53:38,821-main.py:470-INFO- Average Latency : 25.55303276 ms
2024-06-25 18:34:47,229-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 18:34:47,229-main.py:76-INFO-Loading dataset:
2024-06-25 18:34:48,505-main.py:274-INFO-Train data = 1, Test data = 16
2024-06-25 18:34:49,235-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 18:34:49,235-main.py:109-INFO-Loading model:
2024-06-25 18:34:49,236-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 18:34:49,243-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 18:34:49,727-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 18:34:49,727-main.py:463-INFO- * Speed: 27.28376 ms/iter
2024-06-25 18:34:49,728-main.py:464-INFO- * MAPE: 0.48690
2024-06-25 18:34:49,728-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-25 18:34:49,728-main.py:466-INFO- * Kendall's Tau: -0.33333333333333337
2024-06-25 18:34:49,728-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 18:34:49,728-main.py:470-INFO- Average Latency : 25.78867972 ms
2024-06-25 18:37:07,353-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-25 18:37:07,353-main.py:76-INFO-Loading dataset:
2024-06-25 18:37:07,484-main.py:274-INFO-Train data = 1, Test data = 17
2024-06-25 18:37:08,225-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-25 18:37:08,226-main.py:109-INFO-Loading model:
2024-06-25 18:37:08,227-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-25 18:37:08,233-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-25 18:37:08,723-main.py:462-INFO- ------------------------------------------------------------------
2024-06-25 18:37:08,723-main.py:463-INFO- * Speed: 26.06585 ms/iter
2024-06-25 18:37:08,723-main.py:464-INFO- * MAPE: 0.49543
2024-06-25 18:37:08,723-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-25 18:37:08,723-main.py:466-INFO- * Kendall's Tau: -0.338235294117647
2024-06-25 18:37:08,724-main.py:467-INFO- ------------------------------------------------------------------
2024-06-25 18:37:08,724-main.py:470-INFO- Average Latency : 24.54160242 ms
2024-06-28 15:01:05,340-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-28 15:01:05,341-main.py:76-INFO-Loading dataset:
2024-06-28 15:01:06,935-main.py:274-INFO-Train data = 1, Test data = 2
2024-06-28 15:01:08,223-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-28 15:01:08,224-main.py:109-INFO-Loading model:
2024-06-28 15:01:08,225-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-28 15:01:08,242-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-28 15:01:08,997-main.py:462-INFO- ------------------------------------------------------------------
2024-06-28 15:01:08,997-main.py:463-INFO- * Speed: 319.94247 ms/iter
2024-06-28 15:01:08,997-main.py:464-INFO- * MAPE: 0.83223
2024-06-28 15:01:08,997-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-28 15:01:08,997-main.py:466-INFO- * Kendall's Tau: 1.0
2024-06-28 15:01:08,998-main.py:467-INFO- ------------------------------------------------------------------
2024-06-28 15:01:08,998-main.py:470-INFO- Average Latency : 314.44191933 ms
2024-06-28 15:03:01,864-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-28 15:03:01,864-main.py:76-INFO-Loading dataset:
2024-06-28 15:03:04,718-main.py:274-INFO-Train data = 1, Test data = 2
2024-06-28 15:03:05,475-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-28 15:03:05,476-main.py:109-INFO-Loading model:
2024-06-28 15:03:05,476-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-28 15:03:05,484-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-28 15:03:05,899-main.py:462-INFO- ------------------------------------------------------------------
2024-06-28 15:03:05,900-main.py:463-INFO- * Speed: 184.42476 ms/iter
2024-06-28 15:03:05,900-main.py:464-INFO- * MAPE: 0.74222
2024-06-28 15:03:05,900-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-28 15:03:05,900-main.py:466-INFO- * Kendall's Tau: 1.0
2024-06-28 15:03:05,900-main.py:467-INFO- ------------------------------------------------------------------
2024-06-28 15:03:05,900-main.py:470-INFO- Average Latency : 182.42454529 ms
2024-06-28 15:06:15,659-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-28 15:06:15,659-main.py:76-INFO-Loading dataset:
2024-06-28 15:06:17,761-main.py:274-INFO-Train data = 1, Test data = 2
2024-06-28 15:06:18,528-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-28 15:06:18,529-main.py:109-INFO-Loading model:
2024-06-28 15:06:18,530-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-28 15:06:18,536-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-28 15:06:18,955-main.py:462-INFO- ------------------------------------------------------------------
2024-06-28 15:06:18,955-main.py:463-INFO- * Speed: 186.83934 ms/iter
2024-06-28 15:06:18,956-main.py:464-INFO- * MAPE: 0.43493
2024-06-28 15:06:18,956-main.py:465-INFO- * ErrorBound: [0. 0. 0.]
2024-06-28 15:06:18,956-main.py:466-INFO- * Kendall's Tau: 1.0
2024-06-28 15:06:18,956-main.py:467-INFO- ------------------------------------------------------------------
2024-06-28 15:06:18,956-main.py:470-INFO- Average Latency : 184.83912945 ms
2024-06-28 20:17:36,369-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-28 20:17:36,369-main.py:76-INFO-Loading dataset:
2024-06-28 20:17:56,672-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-28 20:17:57,455-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-28 20:17:57,456-main.py:109-INFO-Loading model:
2024-06-28 20:17:57,457-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-28 20:17:57,474-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-28 20:17:58,208-main.py:462-INFO- ------------------------------------------------------------------
2024-06-28 20:17:58,208-main.py:463-INFO- * Speed: 30.74170 ms/iter
2024-06-28 20:17:58,208-main.py:464-INFO- * MAPE: 0.27206
2024-06-28 20:17:58,209-main.py:465-INFO- * ErrorBound: [0.2 0.1 0. ]
2024-06-28 20:17:58,209-main.py:466-INFO- * Kendall's Tau: 0.49473684210526314
2024-06-28 20:17:58,209-main.py:467-INFO- ------------------------------------------------------------------
2024-06-28 20:17:58,209-main.py:470-INFO- Average Latency : 29.29161787 ms
2024-06-28 20:21:06,136-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/a.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-28 20:21:06,137-main.py:76-INFO-Loading dataset:
2024-06-28 20:21:24,585-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-28 20:21:25,362-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-28 20:21:25,363-main.py:109-INFO-Loading model:
2024-06-28 20:21:25,364-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-28 20:21:25,370-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-28 20:21:25,871-main.py:462-INFO- ------------------------------------------------------------------
2024-06-28 20:21:25,871-main.py:463-INFO- * Speed: 23.87876 ms/iter
2024-06-28 20:21:25,872-main.py:464-INFO- * MAPE: 0.27603
2024-06-28 20:21:25,872-main.py:465-INFO- * ErrorBound: [0.21052632 0.10526316 0.        ]
2024-06-28 20:21:25,872-main.py:466-INFO- * Kendall's Tau: 0.47368421052631576
2024-06-28 20:21:25,872-main.py:467-INFO- ------------------------------------------------------------------
2024-06-28 20:21:25,872-main.py:470-INFO- Average Latency : 22.51027760 ms
2024-06-30 22:19:29,717-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/a.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 22:19:29,717-main.py:76-INFO-Loading dataset:
2024-06-30 22:19:50,414-main.py:274-INFO-Train data = 1, Test data = 19
2024-06-30 22:19:51,720-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 22:19:51,721-main.py:109-INFO-Loading model:
2024-06-30 22:19:51,723-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:19:51,745-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:19:52,608-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 22:19:52,609-main.py:465-INFO- * Speed: 39.72465 ms/iter
2024-06-30 22:19:52,609-main.py:466-INFO- * MAPE: 0.27603
2024-06-30 22:19:52,609-main.py:467-INFO- * ErrorBound: [0.21052632 0.10526316 0.        ]
2024-06-30 22:19:52,609-main.py:468-INFO- * Kendall's Tau: 0.47368421052631576
2024-06-30 22:19:52,609-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 22:19:52,609-main.py:472-INFO- Average Latency : 37.93565851 ms
2024-06-30 22:21:57,886-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mnasnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 22:21:57,886-main.py:76-INFO-Loading dataset:
2024-06-30 22:22:36,875-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-30 22:22:37,642-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 22:22:37,643-main.py:109-INFO-Loading model:
2024-06-30 22:22:37,644-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:22:37,650-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:22:38,160-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 22:22:38,160-main.py:465-INFO- * Speed: 23.09563 ms/iter
2024-06-30 22:22:38,160-main.py:466-INFO- * MAPE: 0.25139
2024-06-30 22:22:38,160-main.py:467-INFO- * ErrorBound: [0.25 0.15 0.  ]
2024-06-30 22:22:38,160-main.py:468-INFO- * Kendall's Tau: 0.22105263157894736
2024-06-30 22:22:38,160-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 22:22:38,161-main.py:472-INFO- Average Latency : 21.68711424 ms
2024-06-30 22:24:13,627-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 22:24:13,628-main.py:76-INFO-Loading dataset:
2024-06-30 22:24:35,402-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-30 22:24:36,170-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 22:24:36,170-main.py:109-INFO-Loading model:
2024-06-30 22:24:36,172-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:24:36,183-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:24:36,712-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 22:24:36,712-main.py:465-INFO- * Speed: 24.01357 ms/iter
2024-06-30 22:24:36,712-main.py:466-INFO- * MAPE: 0.18308
2024-06-30 22:24:36,712-main.py:467-INFO- * ErrorBound: [0.2 0.1 0. ]
2024-06-30 22:24:36,713-main.py:468-INFO- * Kendall's Tau: 0.5578947368421052
2024-06-30 22:24:36,713-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 22:24:36,713-main.py:472-INFO- Average Latency : 22.51905203 ms
2024-06-30 22:25:58,504-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 22:25:58,504-main.py:76-INFO-Loading dataset:
2024-06-30 22:26:16,814-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-30 22:26:17,582-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 22:26:17,583-main.py:109-INFO-Loading model:
2024-06-30 22:26:17,584-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:26:17,591-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:26:18,099-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 22:26:18,099-main.py:465-INFO- * Speed: 23.11047 ms/iter
2024-06-30 22:26:18,099-main.py:466-INFO- * MAPE: 0.47401
2024-06-30 22:26:18,100-main.py:467-INFO- * ErrorBound: [0.15 0.1  0.  ]
2024-06-30 22:26:18,100-main.py:468-INFO- * Kendall's Tau: 0.2105263157894737
2024-06-30 22:26:18,100-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 22:26:18,100-main.py:472-INFO- Average Latency : 21.71415091 ms
2024-06-30 22:28:10,423-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 22:28:10,423-main.py:76-INFO-Loading dataset:
2024-06-30 22:28:14,715-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-30 22:28:15,515-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 22:28:15,515-main.py:109-INFO-Loading model:
2024-06-30 22:28:15,516-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:28:15,523-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:28:16,062-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 22:28:16,062-main.py:465-INFO- * Speed: 24.65479 ms/iter
2024-06-30 22:28:16,063-main.py:466-INFO- * MAPE: 0.38932
2024-06-30 22:28:16,063-main.py:467-INFO- * ErrorBound: [0.2 0.1 0. ]
2024-06-30 22:28:16,063-main.py:468-INFO- * Kendall's Tau: 0.10526315789473685
2024-06-30 22:28:16,063-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 22:28:16,063-main.py:472-INFO- Average Latency : 23.25943708 ms
2024-06-30 22:30:07,008-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 22:30:07,009-main.py:76-INFO-Loading dataset:
2024-06-30 22:30:08,747-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-30 22:30:09,521-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 22:30:09,522-main.py:109-INFO-Loading model:
2024-06-30 22:30:09,523-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:30:09,530-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:30:10,061-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 22:30:10,061-main.py:465-INFO- * Speed: 24.04590 ms/iter
2024-06-30 22:30:10,061-main.py:466-INFO- * MAPE: 0.29883
2024-06-30 22:30:10,061-main.py:467-INFO- * ErrorBound: [0.15 0.1  0.05]
2024-06-30 22:30:10,061-main.py:468-INFO- * Kendall's Tau: 0.3368421052631579
2024-06-30 22:30:10,062-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 22:30:10,062-main.py:472-INFO- Average Latency : 22.66088724 ms
2024-06-30 22:33:38,042-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 22:33:38,042-main.py:76-INFO-Loading dataset:
2024-06-30 22:34:07,341-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-30 22:34:08,126-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 22:34:08,127-main.py:109-INFO-Loading model:
2024-06-30 22:34:08,128-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:34:08,140-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 22:34:08,643-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 22:34:08,643-main.py:465-INFO- * Speed: 22.74779 ms/iter
2024-06-30 22:34:08,644-main.py:466-INFO- * MAPE: 0.67326
2024-06-30 22:34:08,644-main.py:467-INFO- * ErrorBound: [0. 0. 0.]
2024-06-30 22:34:08,644-main.py:468-INFO- * Kendall's Tau: -0.1368421052631579
2024-06-30 22:34:08,644-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 22:34:08,644-main.py:472-INFO- Average Latency : 21.50214911 ms
2024-06-30 23:01:34,229-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-06-30 23:01:34,229-main.py:76-INFO-Loading dataset:
2024-06-30 23:01:40,362-main.py:274-INFO-Train data = 1, Test data = 20
2024-06-30 23:01:41,184-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-06-30 23:01:41,185-main.py:109-INFO-Loading model:
2024-06-30 23:01:41,186-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-06-30 23:01:41,193-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-06-30 23:01:41,725-main.py:464-INFO- ------------------------------------------------------------------
2024-06-30 23:01:41,725-main.py:465-INFO- * Speed: 24.16904 ms/iter
2024-06-30 23:01:41,725-main.py:466-INFO- * MAPE: 0.57386
2024-06-30 23:01:41,725-main.py:467-INFO- * ErrorBound: [0. 0. 0.]
2024-06-30 23:01:41,725-main.py:468-INFO- * Kendall's Tau: 0.0
2024-06-30 23:01:41,725-main.py:469-INFO- ------------------------------------------------------------------
2024-06-30 23:01:41,725-main.py:472-INFO- Average Latency : 22.77357578 ms
2024-07-01 11:55:35,346-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/a.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 11:55:35,346-main.py:76-INFO-Loading dataset:
2024-07-01 11:55:54,633-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-01 11:55:55,946-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 11:55:55,947-main.py:109-INFO-Loading model:
2024-07-01 11:55:55,948-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 11:55:55,967-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 11:55:56,842-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 11:55:56,842-main.py:465-INFO- * Speed: 38.00944 ms/iter
2024-07-01 11:55:56,842-main.py:466-INFO- * MAPE: 0.28016
2024-07-01 11:55:56,842-main.py:467-INFO- * ErrorBound: [0.2 0.1 0. ]
2024-07-01 11:55:56,842-main.py:468-INFO- * Kendall's Tau: 0.49473684210526314
2024-07-01 11:55:56,842-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 11:55:56,843-main.py:472-INFO- Average Latency : 36.16533279 ms
2024-07-01 12:27:04,740-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 12:27:04,740-main.py:76-INFO-Loading dataset:
2024-07-01 12:27:21,239-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-01 12:27:22,001-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 12:27:22,002-main.py:109-INFO-Loading model:
2024-07-01 12:27:22,003-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 12:27:22,009-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 12:27:22,514-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 12:27:22,514-main.py:465-INFO- * Speed: 22.83998 ms/iter
2024-07-01 12:27:22,514-main.py:466-INFO- * MAPE: 0.47401
2024-07-01 12:27:22,515-main.py:467-INFO- * ErrorBound: [0.15 0.1  0.  ]
2024-07-01 12:27:22,515-main.py:468-INFO- * Kendall's Tau: 0.2105263157894737
2024-07-01 12:27:22,515-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 12:27:22,515-main.py:472-INFO- Average Latency : 21.21553421 ms
2024-07-01 19:52:30,969-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 19:52:30,969-main.py:76-INFO-Loading dataset:
2024-07-01 19:52:30,976-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-01 19:52:31,740-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 19:52:31,741-main.py:109-INFO-Loading model:
2024-07-01 19:52:31,742-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 19:52:31,749-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 19:52:32,202-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 19:52:32,202-main.py:465-INFO- * Speed: 40.64376 ms/iter
2024-07-01 19:52:32,202-main.py:466-INFO- * MAPE: 0.63065
2024-07-01 19:52:32,203-main.py:467-INFO- * ErrorBound: [0. 0. 0.]
2024-07-01 19:52:32,203-main.py:468-INFO- * Kendall's Tau: 0.06666666666666667
2024-07-01 19:52:32,203-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 19:52:32,203-main.py:472-INFO- Average Latency : 38.94937038 ms
2024-07-01 20:30:09,377-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 20:30:09,377-main.py:76-INFO-Loading dataset:
2024-07-01 20:30:18,173-main.py:274-INFO-Train data = 1, Test data = 11
2024-07-01 20:30:18,946-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 20:30:18,947-main.py:109-INFO-Loading model:
2024-07-01 20:30:18,948-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 20:30:18,954-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 20:30:19,415-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 20:30:19,415-main.py:465-INFO- * Speed: 37.58743 ms/iter
2024-07-01 20:30:19,416-main.py:466-INFO- * MAPE: 0.60686
2024-07-01 20:30:19,416-main.py:467-INFO- * ErrorBound: [0.18181818 0.18181818 0.        ]
2024-07-01 20:30:19,416-main.py:468-INFO- * Kendall's Tau: 0.2727272727272727
2024-07-01 20:30:19,416-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 20:30:19,416-main.py:472-INFO- Average Latency : 36.04717688 ms
2024-07-01 20:39:21,258-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 20:39:21,259-main.py:76-INFO-Loading dataset:
2024-07-01 20:39:30,038-main.py:274-INFO-Train data = 1, Test data = 11
2024-07-01 20:39:30,808-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 20:39:30,809-main.py:109-INFO-Loading model:
2024-07-01 20:39:30,810-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 20:39:30,816-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 20:39:31,270-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 20:39:31,270-main.py:465-INFO- * Speed: 37.05792 ms/iter
2024-07-01 20:39:31,270-main.py:466-INFO- * MAPE: 0.60412
2024-07-01 20:39:31,271-main.py:467-INFO- * ErrorBound: [0.18181818 0.18181818 0.        ]
2024-07-01 20:39:31,271-main.py:468-INFO- * Kendall's Tau: 0.2727272727272727
2024-07-01 20:39:31,271-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 20:39:31,271-main.py:472-INFO- Average Latency : 35.42709351 ms
2024-07-01 23:36:34,863-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 23:36:34,864-main.py:76-INFO-Loading dataset:
2024-07-01 23:36:52,054-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-01 23:36:52,829-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 23:36:52,829-main.py:109-INFO-Loading model:
2024-07-01 23:36:52,830-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:36:52,846-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:36:53,310-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 23:36:53,311-main.py:465-INFO- * Speed: 41.73079 ms/iter
2024-07-01 23:36:53,311-main.py:466-INFO- * MAPE: 0.42745
2024-07-01 23:36:53,311-main.py:467-INFO- * ErrorBound: [0.1 0.  0. ]
2024-07-01 23:36:53,311-main.py:468-INFO- * Kendall's Tau: -0.3333333333333333
2024-07-01 23:36:53,311-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 23:36:53,311-main.py:472-INFO- Average Latency : 40.43569565 ms
2024-07-01 23:38:13,131-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 23:38:13,131-main.py:76-INFO-Loading dataset:
2024-07-01 23:38:26,574-main.py:274-INFO-Train data = 1, Test data = 8
2024-07-01 23:38:27,338-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 23:38:27,339-main.py:109-INFO-Loading model:
2024-07-01 23:38:27,340-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:38:27,346-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:38:27,805-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 23:38:27,805-main.py:465-INFO- * Speed: 51.58901 ms/iter
2024-07-01 23:38:27,805-main.py:466-INFO- * MAPE: 0.36692
2024-07-01 23:38:27,805-main.py:467-INFO- * ErrorBound: [0.125 0.    0.   ]
2024-07-01 23:38:27,805-main.py:468-INFO- * Kendall's Tau: -0.3571428571428571
2024-07-01 23:38:27,806-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 23:38:27,806-main.py:472-INFO- Average Latency : 49.84483123 ms
2024-07-01 23:40:47,102-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 23:40:47,102-main.py:76-INFO-Loading dataset:
2024-07-01 23:40:47,109-main.py:274-INFO-Train data = 1, Test data = 8
2024-07-01 23:40:47,873-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 23:40:47,873-main.py:109-INFO-Loading model:
2024-07-01 23:40:47,874-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:40:47,881-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:40:48,332-main.py:464-INFO- ------------------------------------------------------------------
2024-07-01 23:40:48,332-main.py:465-INFO- * Speed: 50.20756 ms/iter
2024-07-01 23:40:48,332-main.py:466-INFO- * MAPE: 0.36692
2024-07-01 23:40:48,332-main.py:467-INFO- * ErrorBound: [0.125 0.    0.   ]
2024-07-01 23:40:48,332-main.py:468-INFO- * Kendall's Tau: -0.3571428571428571
2024-07-01 23:40:48,333-main.py:469-INFO- ------------------------------------------------------------------
2024-07-01 23:40:48,333-main.py:472-INFO- Average Latency : 48.71258140 ms
2024-07-01 23:42:07,778-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-01 23:42:07,778-main.py:76-INFO-Loading dataset:
2024-07-01 23:42:07,785-main.py:274-INFO-Train data = 1, Test data = 8
2024-07-01 23:42:08,543-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-01 23:42:08,544-main.py:109-INFO-Loading model:
2024-07-01 23:42:08,545-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:42:08,551-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-01 23:42:09,012-main.py:466-INFO- ------------------------------------------------------------------
2024-07-01 23:42:09,012-main.py:467-INFO- * Speed: 51.75090 ms/iter
2024-07-01 23:42:09,013-main.py:468-INFO- * MAPE: 0.33174
2024-07-01 23:42:09,013-main.py:469-INFO- * ErrorBound: [0.125 0.    0.   ]
2024-07-01 23:42:09,013-main.py:470-INFO- * Kendall's Tau: -0.3571428571428571
2024-07-01 23:42:09,013-main.py:471-INFO- ------------------------------------------------------------------
2024-07-01 23:42:09,015-main.py:474-INFO- Average Latency : 50.36291480 ms
2024-07-02 12:54:03,291-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-02 12:54:03,292-main.py:76-INFO-Loading dataset:
2024-07-02 12:54:08,885-main.py:274-INFO-Train data = 1, Test data = 6
2024-07-02 12:54:10,165-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-02 12:54:10,166-main.py:109-INFO-Loading model:
2024-07-02 12:54:10,167-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-02 12:54:10,186-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-02 12:54:10,997-main.py:466-INFO- ------------------------------------------------------------------
2024-07-02 12:54:10,997-main.py:467-INFO- * Speed: 115.62093 ms/iter
2024-07-02 12:54:10,997-main.py:468-INFO- * MAPE: 0.44035
2024-07-02 12:54:10,998-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-02 12:54:10,998-main.py:470-INFO- * Kendall's Tau: 0.2
2024-07-02 12:54:10,998-main.py:471-INFO- ------------------------------------------------------------------
2024-07-02 12:54:10,999-main.py:474-INFO- Average Latency : 112.63899008 ms
2024-07-02 13:17:42,980-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-02 13:17:42,980-main.py:76-INFO-Loading dataset:
2024-07-02 13:18:00,564-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-02 13:18:01,354-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-02 13:18:01,354-main.py:109-INFO-Loading model:
2024-07-02 13:18:01,355-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-02 13:18:01,372-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-02 13:18:01,846-main.py:466-INFO- ------------------------------------------------------------------
2024-07-02 13:18:01,846-main.py:467-INFO- * Speed: 42.46407 ms/iter
2024-07-02 13:18:01,846-main.py:468-INFO- * MAPE: 0.48569
2024-07-02 13:18:01,847-main.py:469-INFO- * ErrorBound: [0.1 0.  0. ]
2024-07-02 13:18:01,847-main.py:470-INFO- * Kendall's Tau: -0.3333333333333333
2024-07-02 13:18:01,847-main.py:471-INFO- ------------------------------------------------------------------
2024-07-02 13:18:01,848-main.py:474-INFO- Average Latency : 40.86406231 ms
2024-07-02 15:32:01,712-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-02 15:32:01,712-main.py:76-INFO-Loading dataset:
2024-07-02 15:32:22,588-main.py:274-INFO-Train data = 1, Test data = 21
2024-07-02 15:32:23,374-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-02 15:32:23,375-main.py:109-INFO-Loading model:
2024-07-02 15:32:23,377-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-02 15:32:23,385-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-02 15:32:23,924-main.py:466-INFO- ------------------------------------------------------------------
2024-07-02 15:32:23,925-main.py:467-INFO- * Speed: 23.34578 ms/iter
2024-07-02 15:32:23,925-main.py:468-INFO- * MAPE: 0.23017
2024-07-02 15:32:23,925-main.py:469-INFO- * ErrorBound: [0.23809524 0.0952381  0.        ]
2024-07-02 15:32:23,925-main.py:470-INFO- * Kendall's Tau: 0.6
2024-07-02 15:32:23,925-main.py:471-INFO- ------------------------------------------------------------------
2024-07-02 15:32:23,926-main.py:474-INFO- Average Latency : 21.67907215 ms
2024-07-02 19:40:37,771-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-02 19:40:37,771-main.py:76-INFO-Loading dataset:
2024-07-02 19:40:37,777-main.py:274-INFO-Train data = 1, Test data = 4
2024-07-02 19:40:38,537-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-02 19:40:38,538-main.py:109-INFO-Loading model:
2024-07-02 19:40:38,539-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-02 19:40:38,547-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-02 19:40:38,972-main.py:466-INFO- ------------------------------------------------------------------
2024-07-02 19:40:38,972-main.py:467-INFO- * Speed: 94.58637 ms/iter
2024-07-02 19:40:38,972-main.py:468-INFO- * MAPE: 0.48918
2024-07-02 19:40:38,972-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-02 19:40:38,972-main.py:470-INFO- * Kendall's Tau: 0.3333333333333334
2024-07-02 19:40:38,972-main.py:471-INFO- ------------------------------------------------------------------
2024-07-02 19:40:38,973-main.py:474-INFO- Average Latency : 92.58651733 ms
2024-07-02 19:41:19,403-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-02 19:41:19,404-main.py:76-INFO-Loading dataset:
2024-07-02 19:41:24,389-main.py:274-INFO-Train data = 1, Test data = 4
2024-07-02 19:41:25,153-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-02 19:41:25,154-main.py:109-INFO-Loading model:
2024-07-02 19:41:25,155-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-02 19:41:25,161-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-02 19:41:25,589-main.py:466-INFO- ------------------------------------------------------------------
2024-07-02 19:41:25,589-main.py:467-INFO- * Speed: 95.09212 ms/iter
2024-07-02 19:41:25,589-main.py:468-INFO- * MAPE: 0.48330
2024-07-02 19:41:25,589-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-02 19:41:25,589-main.py:470-INFO- * Kendall's Tau: -1.0
2024-07-02 19:41:25,589-main.py:471-INFO- ------------------------------------------------------------------
2024-07-02 19:41:25,590-main.py:474-INFO- Average Latency : 93.34224463 ms
2024-07-03 21:51:05,333-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/a.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-03 21:51:05,334-main.py:76-INFO-Loading dataset:
2024-07-03 21:51:45,046-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-03 21:51:45,046-main.py:76-INFO-Loading dataset:
2024-07-03 21:51:50,748-main.py:274-INFO-Train data = 1, Test data = 6
2024-07-03 21:51:52,014-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-03 21:51:52,015-main.py:109-INFO-Loading model:
2024-07-03 21:51:52,015-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-03 21:51:52,035-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-03 21:51:52,826-main.py:466-INFO- ------------------------------------------------------------------
2024-07-03 21:51:52,826-main.py:467-INFO- * Speed: 112.57676 ms/iter
2024-07-03 21:51:52,826-main.py:468-INFO- * MAPE: 0.41982
2024-07-03 21:51:52,826-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-03 21:51:52,826-main.py:470-INFO- * Kendall's Tau: -1.0
2024-07-03 21:51:52,827-main.py:471-INFO- ------------------------------------------------------------------
2024-07-03 21:51:52,827-main.py:474-INFO- Average Latency : 109.91497835 ms
2024-07-03 21:52:36,534-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-03 21:52:36,535-main.py:76-INFO-Loading dataset:
2024-07-03 21:52:38,312-main.py:274-INFO-Train data = 1, Test data = 6
2024-07-03 21:52:39,080-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-03 21:52:39,081-main.py:109-INFO-Loading model:
2024-07-03 21:52:39,082-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-03 21:52:39,089-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-03 21:52:39,521-main.py:466-INFO- ------------------------------------------------------------------
2024-07-03 21:52:39,521-main.py:467-INFO- * Speed: 64.23346 ms/iter
2024-07-03 21:52:39,521-main.py:468-INFO- * MAPE: 0.46237
2024-07-03 21:52:39,521-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-03 21:52:39,521-main.py:470-INFO- * Kendall's Tau: -0.7333333333333333
2024-07-03 21:52:39,521-main.py:471-INFO- ------------------------------------------------------------------
2024-07-03 21:52:39,521-main.py:474-INFO- Average Latency : 62.73269653 ms
2024-07-04 12:22:16,673-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/esnet18-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 12:22:16,673-main.py:76-INFO-Loading dataset:
2024-07-04 12:22:30,308-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 12:22:30,308-main.py:76-INFO-Loading dataset:
2024-07-04 12:22:32,239-main.py:274-INFO-Train data = 1, Test data = 14
2024-07-04 12:22:33,527-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-04 12:22:33,527-main.py:109-INFO-Loading model:
2024-07-04 12:22:33,528-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-04 12:22:33,546-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-04 12:22:34,388-main.py:466-INFO- ------------------------------------------------------------------
2024-07-04 12:22:34,389-main.py:467-INFO- * Speed: 52.03923 ms/iter
2024-07-04 12:22:34,389-main.py:468-INFO- * MAPE: 0.96972
2024-07-04 12:22:34,389-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-04 12:22:34,389-main.py:470-INFO- * Kendall's Tau: 0.3406593406593407
2024-07-04 12:22:34,389-main.py:471-INFO- ------------------------------------------------------------------
2024-07-04 12:22:34,389-main.py:474-INFO- Average Latency : 50.03922326 ms
2024-07-04 13:06:40,425-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 13:06:40,426-main.py:76-INFO-Loading dataset:
2024-07-04 13:06:41,124-main.py:274-INFO-Train data = 1, Test data = 12
2024-07-04 13:06:41,896-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-04 13:06:41,897-main.py:109-INFO-Loading model:
2024-07-04 13:06:41,898-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-04 13:06:41,905-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-04 13:06:42,384-main.py:466-INFO- ------------------------------------------------------------------
2024-07-04 13:06:42,384-main.py:467-INFO- * Speed: 36.03266 ms/iter
2024-07-04 13:06:42,384-main.py:468-INFO- * MAPE: 0.90493
2024-07-04 13:06:42,385-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-04 13:06:42,385-main.py:470-INFO- * Kendall's Tau: 0.2727272727272727
2024-07-04 13:06:42,385-main.py:471-INFO- ------------------------------------------------------------------
2024-07-04 13:06:42,385-main.py:474-INFO- Average Latency : 34.14899111 ms
2024-07-04 14:19:20,297-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 14:19:20,298-main.py:76-INFO-Loading dataset:
2024-07-04 14:20:53,655-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 14:20:53,656-main.py:76-INFO-Loading dataset:
2024-07-04 14:20:54,339-main.py:274-INFO-Train data = 1, Test data = 12
2024-07-04 14:20:55,092-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-04 14:20:55,093-main.py:109-INFO-Loading model:
2024-07-04 14:20:55,094-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-04 14:20:55,100-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-04 14:20:55,561-main.py:466-INFO- ------------------------------------------------------------------
2024-07-04 14:20:55,561-main.py:467-INFO- * Speed: 34.63984 ms/iter
2024-07-04 14:20:55,562-main.py:468-INFO- * MAPE: 0.90493
2024-07-04 14:20:55,562-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-04 14:20:55,562-main.py:470-INFO- * Kendall's Tau: 0.2727272727272727
2024-07-04 14:20:55,562-main.py:471-INFO- ------------------------------------------------------------------
2024-07-04 14:20:55,562-main.py:474-INFO- Average Latency : 32.87549814 ms
2024-07-04 14:21:11,074-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 14:21:11,074-main.py:76-INFO-Loading dataset:
2024-07-04 14:22:44,429-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 14:22:44,429-main.py:76-INFO-Loading dataset:
2024-07-04 14:22:44,437-main.py:274-INFO-Train data = 1, Test data = 9
2024-07-04 14:22:45,172-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-04 14:22:45,172-main.py:109-INFO-Loading model:
2024-07-04 14:22:45,173-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-04 14:22:45,180-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-04 14:22:45,627-main.py:466-INFO- ------------------------------------------------------------------
2024-07-04 14:22:45,627-main.py:467-INFO- * Speed: 44.56602 ms/iter
2024-07-04 14:22:45,627-main.py:468-INFO- * MAPE: 0.84702
2024-07-04 14:22:45,627-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-04 14:22:45,628-main.py:470-INFO- * Kendall's Tau: 0.1111111111111111
2024-07-04 14:22:45,628-main.py:471-INFO- ------------------------------------------------------------------
2024-07-04 14:22:45,628-main.py:474-INFO- Average Latency : 43.01060571 ms
2024-07-04 14:23:08,192-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-04 14:23:08,193-main.py:76-INFO-Loading dataset:
2024-07-04 14:23:14,925-main.py:274-INFO-Train data = 1, Test data = 9
2024-07-04 14:23:15,673-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-04 14:23:15,674-main.py:109-INFO-Loading model:
2024-07-04 14:23:15,675-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-04 14:23:15,681-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-04 14:23:16,132-main.py:466-INFO- ------------------------------------------------------------------
2024-07-04 14:23:16,132-main.py:467-INFO- * Speed: 44.86752 ms/iter
2024-07-04 14:23:16,132-main.py:468-INFO- * MAPE: 0.46488
2024-07-04 14:23:16,133-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-04 14:23:16,133-main.py:470-INFO- * Kendall's Tau: 0.16666666666666666
2024-07-04 14:23:16,133-main.py:471-INFO- ------------------------------------------------------------------
2024-07-04 14:23:16,133-main.py:474-INFO- Average Latency : 42.86750158 ms
2024-07-05 20:18:46,684-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/a.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-05 20:18:46,685-main.py:76-INFO-Loading dataset:
2024-07-05 20:19:05,467-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-05 20:19:06,765-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-05 20:19:06,766-main.py:109-INFO-Loading model:
2024-07-05 20:19:06,767-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-05 20:19:06,786-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-05 20:19:07,628-main.py:466-INFO- ------------------------------------------------------------------
2024-07-05 20:19:07,628-main.py:467-INFO- * Speed: 36.69875 ms/iter
2024-07-05 20:19:07,628-main.py:468-INFO- * MAPE: 0.29998
2024-07-05 20:19:07,628-main.py:469-INFO- * ErrorBound: [0.2 0.1 0. ]
2024-07-05 20:19:07,628-main.py:470-INFO- * Kendall's Tau: 0.49473684210526314
2024-07-05 20:19:07,628-main.py:471-INFO- ------------------------------------------------------------------
2024-07-05 20:19:07,629-main.py:474-INFO- Average Latency : 34.75515842 ms
2024-07-10 15:06:41,743-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-10 15:06:41,743-main.py:76-INFO-Loading dataset:
2024-07-10 15:07:03,556-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-10 15:07:04,842-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-10 15:07:04,842-main.py:109-INFO-Loading model:
2024-07-10 15:07:04,844-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-10 15:07:04,864-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-10 15:07:05,694-main.py:466-INFO- ------------------------------------------------------------------
2024-07-10 15:07:05,695-main.py:467-INFO- * Speed: 71.65198 ms/iter
2024-07-10 15:07:05,695-main.py:468-INFO- * MAPE: 0.48569
2024-07-10 15:07:05,695-main.py:469-INFO- * ErrorBound: [0.1 0.  0. ]
2024-07-10 15:07:05,695-main.py:470-INFO- * Kendall's Tau: -0.3333333333333333
2024-07-10 15:07:05,695-main.py:471-INFO- ------------------------------------------------------------------
2024-07-10 15:07:05,695-main.py:474-INFO- Average Latency : 68.44682693 ms
2024-07-10 15:33:49,689-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-10 15:33:49,689-main.py:76-INFO-Loading dataset:
2024-07-10 15:34:06,541-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-10 15:34:07,322-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-10 15:34:07,323-main.py:109-INFO-Loading model:
2024-07-10 15:34:07,325-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-10 15:34:07,331-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-10 15:34:07,796-main.py:466-INFO- ------------------------------------------------------------------
2024-07-10 15:34:07,796-main.py:467-INFO- * Speed: 41.72001 ms/iter
2024-07-10 15:34:07,796-main.py:468-INFO- * MAPE: 0.37191
2024-07-10 15:34:07,797-main.py:469-INFO- * ErrorBound: [0.2 0.2 0. ]
2024-07-10 15:34:07,797-main.py:470-INFO- * Kendall's Tau: -0.37777777777777777
2024-07-10 15:34:07,797-main.py:471-INFO- ------------------------------------------------------------------
2024-07-10 15:34:07,797-main.py:474-INFO- Average Latency : 40.11993408 ms
2024-07-10 19:55:50,163-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/vgg16-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-10 19:55:50,163-main.py:76-INFO-Loading dataset:
2024-07-10 19:56:06,605-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-10 19:56:07,694-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-10 19:56:07,695-main.py:109-INFO-Loading model:
2024-07-10 19:56:07,697-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-10 19:56:07,708-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-10 19:56:08,397-main.py:466-INFO- ------------------------------------------------------------------
2024-07-10 19:56:08,397-main.py:467-INFO- * Speed: 61.68063 ms/iter
2024-07-10 19:56:08,397-main.py:468-INFO- * MAPE: 0.37191
2024-07-10 19:56:08,398-main.py:469-INFO- * ErrorBound: [0.2 0.2 0. ]
2024-07-10 19:56:08,398-main.py:470-INFO- * Kendall's Tau: -0.37777777777777777
2024-07-10 19:56:08,398-main.py:471-INFO- ------------------------------------------------------------------
2024-07-10 19:56:08,398-main.py:474-INFO- Average Latency : 58.68072510 ms
2024-07-11 11:16:56,924-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:16:56,924-main.py:76-INFO-Loading dataset:
2024-07-11 11:18:05,866-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:18:05,866-main.py:76-INFO-Loading dataset:
2024-07-11 11:18:28,289-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:18:28,290-main.py:76-INFO-Loading dataset:
2024-07-11 11:19:39,929-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:19:39,930-main.py:76-INFO-Loading dataset:
2024-07-11 11:22:00,095-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:22:00,095-main.py:76-INFO-Loading dataset:
2024-07-11 11:24:00,547-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:24:00,547-main.py:76-INFO-Loading dataset:
2024-07-11 11:24:52,905-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/go.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:24:52,906-main.py:76-INFO-Loading dataset:
2024-07-11 11:24:54,977-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-11 11:24:56,258-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-11 11:24:56,258-main.py:109-INFO-Loading model:
2024-07-11 11:24:56,260-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-11 11:24:56,281-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-11 11:24:57,080-main.py:466-INFO- ------------------------------------------------------------------
2024-07-11 11:24:57,080-main.py:467-INFO- * Speed: 68.62006 ms/iter
2024-07-11 11:24:57,080-main.py:468-INFO- * MAPE: 0.76532
2024-07-11 11:24:57,081-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-11 11:24:57,081-main.py:470-INFO- * Kendall's Tau: 0.4222222222222222
2024-07-11 11:24:57,081-main.py:471-INFO- ------------------------------------------------------------------
2024-07-11 11:24:57,081-main.py:474-INFO- Average Latency : 66.52021408 ms
2024-07-11 11:28:51,087-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/go.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:28:51,087-main.py:76-INFO-Loading dataset:
2024-07-11 11:28:53,046-main.py:274-INFO-Train data = 1, Test data = 10
2024-07-11 11:28:53,825-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-11 11:28:53,825-main.py:109-INFO-Loading model:
2024-07-11 11:28:53,826-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-11 11:28:53,832-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-11 11:28:54,291-main.py:466-INFO- ------------------------------------------------------------------
2024-07-11 11:28:54,291-main.py:467-INFO- * Speed: 41.04183 ms/iter
2024-07-11 11:28:54,292-main.py:468-INFO- * MAPE: 0.76532
2024-07-11 11:28:54,292-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-11 11:28:54,292-main.py:470-INFO- * Kendall's Tau: 0.4222222222222222
2024-07-11 11:28:54,292-main.py:471-INFO- ------------------------------------------------------------------
2024-07-11 11:28:54,292-main.py:474-INFO- Average Latency : 39.11640644 ms
2024-07-11 11:29:13,009-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/go2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-11 11:29:13,010-main.py:76-INFO-Loading dataset:
2024-07-11 11:29:16,832-main.py:274-INFO-Train data = 1, Test data = 19
2024-07-11 11:29:17,622-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-11 11:29:17,623-main.py:109-INFO-Loading model:
2024-07-11 11:29:17,624-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-11 11:29:17,630-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-11 11:29:18,126-main.py:466-INFO- ------------------------------------------------------------------
2024-07-11 11:29:18,127-main.py:467-INFO- * Speed: 23.68657 ms/iter
2024-07-11 11:29:18,127-main.py:468-INFO- * MAPE: 0.76039
2024-07-11 11:29:18,127-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-11 11:29:18,127-main.py:470-INFO- * Kendall's Tau: 0.08771929824561403
2024-07-11 11:29:18,127-main.py:471-INFO- ------------------------------------------------------------------
2024-07-11 11:29:18,128-main.py:474-INFO- Average Latency : 21.89476866 ms
2024-07-12 11:50:47,310-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/ale.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-12 11:50:47,310-main.py:76-INFO-Loading dataset:
2024-07-12 11:50:48,045-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-12 11:50:49,325-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-12 11:50:49,325-main.py:109-INFO-Loading model:
2024-07-12 11:50:49,325-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-12 11:50:49,344-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-12 11:50:50,203-main.py:466-INFO- ------------------------------------------------------------------
2024-07-12 11:50:50,203-main.py:467-INFO- * Speed: 37.32084 ms/iter
2024-07-12 11:50:50,203-main.py:468-INFO- * MAPE: 3.13127
2024-07-12 11:50:50,204-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-12 11:50:50,204-main.py:470-INFO- * Kendall's Tau: 0.39999999999999997
2024-07-12 11:50:50,204-main.py:471-INFO- ------------------------------------------------------------------
2024-07-12 11:50:50,204-main.py:474-INFO- Average Latency : 35.67637205 ms
2024-07-12 12:11:54,181-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mn.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-12 12:11:54,181-main.py:76-INFO-Loading dataset:
2024-07-12 12:11:54,285-main.py:274-INFO-Train data = 1, Test data = 18
2024-07-12 12:11:55,047-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-12 12:11:55,047-main.py:109-INFO-Loading model:
2024-07-12 12:11:55,049-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-12 12:11:55,056-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-12 12:11:55,548-main.py:466-INFO- ------------------------------------------------------------------
2024-07-12 12:11:55,548-main.py:467-INFO- * Speed: 24.71424 ms/iter
2024-07-12 12:11:55,548-main.py:468-INFO- * MAPE: 11.72585
2024-07-12 12:11:55,548-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-12 12:11:55,548-main.py:470-INFO- * Kendall's Tau: -0.12418300653594773
2024-07-12 12:11:55,549-main.py:471-INFO- ------------------------------------------------------------------
2024-07-12 12:11:55,549-main.py:474-INFO- Average Latency : 23.12359545 ms
2024-07-12 12:12:24,030-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/mn.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-12 12:12:24,030-main.py:76-INFO-Loading dataset:
2024-07-12 12:12:24,131-main.py:274-INFO-Train data = 1, Test data = 18
2024-07-12 12:12:24,888-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-12 12:12:24,889-main.py:109-INFO-Loading model:
2024-07-12 12:12:24,891-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-12 12:12:24,898-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-12 12:12:25,382-main.py:466-INFO- ------------------------------------------------------------------
2024-07-12 12:12:25,382-main.py:467-INFO- * Speed: 24.25223 ms/iter
2024-07-12 12:12:25,383-main.py:468-INFO- * MAPE: 11.72585
2024-07-12 12:12:25,383-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-12 12:12:25,383-main.py:470-INFO- * Kendall's Tau: -0.12418300653594773
2024-07-12 12:12:25,383-main.py:471-INFO- ------------------------------------------------------------------
2024-07-12 12:12:25,383-main.py:474-INFO- Average Latency : 22.92340332 ms
2024-07-12 18:12:35,622-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/go.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-12 18:12:35,622-main.py:76-INFO-Loading dataset:
2024-07-12 18:12:40,647-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-12 18:12:41,415-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-12 18:12:41,416-main.py:109-INFO-Loading model:
2024-07-12 18:12:41,416-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-12 18:12:41,423-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-12 18:12:41,935-main.py:466-INFO- ------------------------------------------------------------------
2024-07-12 18:12:41,935-main.py:467-INFO- * Speed: 23.21788 ms/iter
2024-07-12 18:12:41,935-main.py:468-INFO- * MAPE: 1.11854
2024-07-12 18:12:41,935-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-07-12 18:12:41,935-main.py:470-INFO- * Kendall's Tau: 0.0736842105263158
2024-07-12 18:12:41,935-main.py:471-INFO- ------------------------------------------------------------------
2024-07-12 18:12:41,936-main.py:474-INFO- Average Latency : 21.67298794 ms
2024-07-16 10:41:14,056-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/7Bmn.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset4/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-16 10:41:14,057-main.py:76-INFO-Loading dataset:
2024-07-16 10:41:14,065-main.py:274-INFO-Train data = 0, Test data = 0
2024-07-16 10:41:23,890-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/7Bmn.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-16 10:41:23,891-main.py:76-INFO-Loading dataset:
2024-07-16 10:41:52,014-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-16 10:41:53,296-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-16 10:41:53,296-main.py:109-INFO-Loading model:
2024-07-16 10:41:53,297-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-16 10:41:53,317-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-16 10:41:54,265-main.py:466-INFO- ------------------------------------------------------------------
2024-07-16 10:41:54,265-main.py:467-INFO- * Speed: 41.75819 ms/iter
2024-07-16 10:41:54,266-main.py:468-INFO- * MAPE: 0.49719
2024-07-16 10:41:54,266-main.py:469-INFO- * ErrorBound: [0.05 0.05 0.05]
2024-07-16 10:41:54,266-main.py:470-INFO- * Kendall's Tau: 0.16842105263157894
2024-07-16 10:41:54,267-main.py:471-INFO- ------------------------------------------------------------------
2024-07-16 10:41:54,267-main.py:474-INFO- Average Latency : 39.45823908 ms
2024-07-16 19:34:08,135-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/1.8Bmn.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-16 19:34:08,135-main.py:76-INFO-Loading dataset:
2024-07-16 19:34:38,863-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-16 19:34:39,638-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-16 19:34:39,639-main.py:109-INFO-Loading model:
2024-07-16 19:34:39,640-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-16 19:34:39,656-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-16 19:34:40,246-main.py:466-INFO- ------------------------------------------------------------------
2024-07-16 19:34:40,246-main.py:467-INFO- * Speed: 24.07123 ms/iter
2024-07-16 19:34:40,247-main.py:468-INFO- * MAPE: 0.36646
2024-07-16 19:34:40,247-main.py:469-INFO- * ErrorBound: [0.15 0.05 0.  ]
2024-07-16 19:34:40,247-main.py:470-INFO- * Kendall's Tau: 0.09473684210526316
2024-07-16 19:34:40,248-main.py:471-INFO- ------------------------------------------------------------------
2024-07-16 19:34:40,248-main.py:474-INFO- Average Latency : 22.12162018 ms
2024-07-17 12:15:43,310-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/1.8BV2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-17 12:15:43,310-main.py:76-INFO-Loading dataset:
2024-07-17 12:16:01,491-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-17 12:16:02,783-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-17 12:16:02,784-main.py:109-INFO-Loading model:
2024-07-17 12:16:02,785-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-17 12:16:02,804-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-17 12:16:03,692-main.py:466-INFO- ------------------------------------------------------------------
2024-07-17 12:16:03,692-main.py:467-INFO- * Speed: 38.75476 ms/iter
2024-07-17 12:16:03,693-main.py:468-INFO- * MAPE: 0.27016
2024-07-17 12:16:03,693-main.py:469-INFO- * ErrorBound: [0.15 0.05 0.  ]
2024-07-17 12:16:03,693-main.py:470-INFO- * Kendall's Tau: 0.0736842105263158
2024-07-17 12:16:03,693-main.py:471-INFO- ------------------------------------------------------------------
2024-07-17 12:16:03,693-main.py:474-INFO- Average Latency : 36.56208515 ms
2024-07-17 12:34:56,978-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/1.8BV2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-17 12:34:56,978-main.py:76-INFO-Loading dataset:
2024-07-17 12:35:19,722-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-17 12:35:20,505-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-17 12:35:20,506-main.py:109-INFO-Loading model:
2024-07-17 12:35:20,507-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-17 12:35:20,528-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-17 12:35:21,313-main.py:466-INFO- ------------------------------------------------------------------
2024-07-17 12:35:21,313-main.py:467-INFO- * Speed: 32.38764 ms/iter
2024-07-17 12:35:21,313-main.py:468-INFO- * MAPE: 0.29620
2024-07-17 12:35:21,314-main.py:469-INFO- * ErrorBound: [0.15 0.1  0.05]
2024-07-17 12:35:21,314-main.py:470-INFO- * Kendall's Tau: 0.0736842105263158
2024-07-17 12:35:21,314-main.py:471-INFO- ------------------------------------------------------------------
2024-07-17 12:35:21,314-main.py:474-INFO- Average Latency : 30.84299564 ms
2024-07-17 13:29:47,563-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/1.8BV2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-17 13:29:47,563-main.py:76-INFO-Loading dataset:
2024-07-17 13:30:17,077-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-17 13:30:17,868-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-17 13:30:17,869-main.py:109-INFO-Loading model:
2024-07-17 13:30:17,871-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-17 13:30:17,889-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-17 13:30:18,500-main.py:466-INFO- ------------------------------------------------------------------
2024-07-17 13:30:18,500-main.py:467-INFO- * Speed: 24.45058 ms/iter
2024-07-17 13:30:18,500-main.py:468-INFO- * MAPE: 0.29620
2024-07-17 13:30:18,501-main.py:469-INFO- * ErrorBound: [0.15 0.1  0.05]
2024-07-17 13:30:18,501-main.py:470-INFO- * Kendall's Tau: 0.0736842105263158
2024-07-17 13:30:18,501-main.py:471-INFO- ------------------------------------------------------------------
2024-07-17 13:30:18,501-main.py:474-INFO- Average Latency : 22.65740633 ms
2024-07-17 13:30:43,979-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/1.8Bale.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-17 13:30:43,980-main.py:76-INFO-Loading dataset:
2024-07-17 13:31:05,486-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-17 13:31:06,267-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-17 13:31:06,268-main.py:109-INFO-Loading model:
2024-07-17 13:31:06,269-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-17 13:31:06,276-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-17 13:31:06,807-main.py:466-INFO- ------------------------------------------------------------------
2024-07-17 13:31:06,807-main.py:467-INFO- * Speed: 24.18493 ms/iter
2024-07-17 13:31:06,807-main.py:468-INFO- * MAPE: 0.49727
2024-07-17 13:31:06,807-main.py:469-INFO- * ErrorBound: [0.1  0.05 0.  ]
2024-07-17 13:31:06,807-main.py:470-INFO- * Kendall's Tau: -0.09473684210526316
2024-07-17 13:31:06,807-main.py:471-INFO- ------------------------------------------------------------------
2024-07-17 13:31:06,808-main.py:474-INFO- Average Latency : 22.64002562 ms
2024-07-17 14:28:19,130-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/7Bale.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-17 14:28:19,130-main.py:76-INFO-Loading dataset:
2024-07-17 14:28:35,588-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-17 14:28:36,373-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-17 14:28:36,373-main.py:109-INFO-Loading model:
2024-07-17 14:28:36,375-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-17 14:28:36,381-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-17 14:28:36,889-main.py:466-INFO- ------------------------------------------------------------------
2024-07-17 14:28:36,890-main.py:467-INFO- * Speed: 23.08322 ms/iter
2024-07-17 14:28:36,890-main.py:468-INFO- * MAPE: 0.45363
2024-07-17 14:28:36,890-main.py:469-INFO- * ErrorBound: [0.15 0.15 0.  ]
2024-07-17 14:28:36,890-main.py:470-INFO- * Kendall's Tau: 0.19999999999999998
2024-07-17 14:28:36,890-main.py:471-INFO- ------------------------------------------------------------------
2024-07-17 14:28:36,891-main.py:474-INFO- Average Latency : 21.43915892 ms
2024-07-26 22:17:18,572-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-26 22:17:18,574-main.py:76-INFO-Loading dataset:
2024-07-26 22:17:38,619-main.py:274-INFO-Train data = 0, Test data = 21
2024-07-26 22:17:56,227-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-26 22:17:56,228-main.py:76-INFO-Loading dataset:
2024-07-26 22:17:56,235-main.py:274-INFO-Train data = 1, Test data = 20
2024-07-26 22:17:57,556-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-26 22:17:57,558-main.py:109-INFO-Loading model:
2024-07-26 22:17:57,560-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-26 22:17:57,579-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-26 22:17:58,594-main.py:466-INFO- ------------------------------------------------------------------
2024-07-26 22:17:58,595-main.py:467-INFO- * Speed: 43.91063 ms/iter
2024-07-26 22:17:58,595-main.py:468-INFO- * MAPE: 0.42984
2024-07-26 22:17:58,595-main.py:469-INFO- * ErrorBound: [0.25 0.1  0.1 ]
2024-07-26 22:17:58,595-main.py:470-INFO- * Kendall's Tau: 0.16842105263157894
2024-07-26 22:17:58,596-main.py:471-INFO- ------------------------------------------------------------------
2024-07-26 22:17:58,596-main.py:474-INFO- Average Latency : 41.61812067 ms
2024-07-27 00:24:36,291-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-27 00:24:36,291-main.py:76-INFO-Loading dataset:
2024-07-27 00:24:43,781-main.py:274-INFO-Train data = 1, Test data = 19
2024-07-27 00:24:44,537-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-27 00:24:44,538-main.py:109-INFO-Loading model:
2024-07-27 00:24:44,539-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-27 00:24:44,546-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-27 00:24:45,056-main.py:466-INFO- ------------------------------------------------------------------
2024-07-27 00:24:45,057-main.py:467-INFO- * Speed: 24.32703 ms/iter
2024-07-27 00:24:45,057-main.py:468-INFO- * MAPE: 0.65740
2024-07-27 00:24:45,057-main.py:469-INFO- * ErrorBound: [0.10526316 0.10526316 0.05263158]
2024-07-27 00:24:45,058-main.py:470-INFO- * Kendall's Tau: 0.017543859649122806
2024-07-27 00:24:45,058-main.py:471-INFO- ------------------------------------------------------------------
2024-07-27 00:24:45,058-main.py:474-INFO- Average Latency : 22.49101589 ms
2024-07-27 10:57:52,814-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-27 10:57:52,814-main.py:76-INFO-Loading dataset:
2024-07-27 10:57:56,123-main.py:274-INFO-Train data = 1, Test data = 15
2024-07-27 10:57:57,385-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-27 10:57:57,387-main.py:109-INFO-Loading model:
2024-07-27 10:57:57,387-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-27 10:57:57,407-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-27 10:57:58,318-main.py:466-INFO- ------------------------------------------------------------------
2024-07-27 10:57:58,318-main.py:467-INFO- * Speed: 51.84466 ms/iter
2024-07-27 10:57:58,318-main.py:468-INFO- * MAPE: 0.21198
2024-07-27 10:57:58,318-main.py:469-INFO- * ErrorBound: [0.26666667 0.2        0.13333333]
2024-07-27 10:57:58,318-main.py:470-INFO- * Kendall's Tau: 0.2761904761904762
2024-07-27 10:57:58,318-main.py:471-INFO- ------------------------------------------------------------------
2024-07-27 10:57:58,318-main.py:474-INFO- Average Latency : 49.97777939 ms
2024-07-27 10:58:26,567-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-27 10:58:26,567-main.py:76-INFO-Loading dataset:
2024-07-27 10:58:26,573-main.py:274-INFO-Train data = 1, Test data = 15
2024-07-27 10:58:27,312-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-27 10:58:27,315-main.py:109-INFO-Loading model:
2024-07-27 10:58:27,315-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-27 10:58:27,321-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-27 10:58:27,790-main.py:466-INFO- ------------------------------------------------------------------
2024-07-27 10:58:27,790-main.py:467-INFO- * Speed: 28.19060 ms/iter
2024-07-27 10:58:27,790-main.py:468-INFO- * MAPE: 0.21198
2024-07-27 10:58:27,790-main.py:469-INFO- * ErrorBound: [0.26666667 0.2        0.13333333]
2024-07-27 10:58:27,790-main.py:470-INFO- * Kendall's Tau: 0.2761904761904762
2024-07-27 10:58:27,790-main.py:471-INFO- ------------------------------------------------------------------
2024-07-27 10:58:27,791-main.py:474-INFO- Average Latency : 26.85720126 ms
2024-07-27 10:59:04,725-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-07-27 10:59:04,726-main.py:76-INFO-Loading dataset:
2024-07-27 10:59:04,731-main.py:274-INFO-Train data = 1, Test data = 15
2024-07-27 10:59:05,468-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-07-27 10:59:05,470-main.py:109-INFO-Loading model:
2024-07-27 10:59:05,470-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-07-27 10:59:05,476-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-07-27 10:59:05,947-main.py:466-INFO- ------------------------------------------------------------------
2024-07-27 10:59:05,947-main.py:467-INFO- * Speed: 28.25592 ms/iter
2024-07-27 10:59:05,947-main.py:468-INFO- * MAPE: 0.21198
2024-07-27 10:59:05,948-main.py:469-INFO- * ErrorBound: [0.26666667 0.2        0.13333333]
2024-07-27 10:59:05,948-main.py:470-INFO- * Kendall's Tau: 0.2761904761904762
2024-07-27 10:59:05,948-main.py:471-INFO- ------------------------------------------------------------------
2024-07-27 10:59:05,948-main.py:474-INFO- Average Latency : 26.78917249 ms
2024-08-02 11:27:49,033-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-02 11:27:49,033-main.py:76-INFO-Loading dataset:
2024-08-02 11:27:49,040-main.py:274-INFO-Train data = 0, Test data = 0
2024-08-02 11:28:45,875-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-02 11:28:45,875-main.py:76-INFO-Loading dataset:
2024-08-02 11:28:58,168-main.py:274-INFO-Train data = 1, Test data = 19
2024-08-02 11:28:59,426-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-02 11:28:59,427-main.py:109-INFO-Loading model:
2024-08-02 11:28:59,428-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-02 11:28:59,445-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-02 11:29:00,352-main.py:466-INFO- ------------------------------------------------------------------
2024-08-02 11:29:00,352-main.py:467-INFO- * Speed: 40.80726 ms/iter
2024-08-02 11:29:00,352-main.py:468-INFO- * MAPE: 0.80475
2024-08-02 11:29:00,352-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-02 11:29:00,352-main.py:470-INFO- * Kendall's Tau: -0.1695906432748538
2024-08-02 11:29:00,353-main.py:471-INFO- ------------------------------------------------------------------
2024-08-02 11:29:00,353-main.py:474-INFO- Average Latency : 39.23328299 ms
2024-08-02 21:46:01,059-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-02 21:46:01,060-main.py:76-INFO-Loading dataset:
2024-08-02 21:46:01,065-main.py:274-INFO-Train data = 0, Test data = 0
2024-08-02 21:46:20,091-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-02 21:46:20,091-main.py:76-INFO-Loading dataset:
2024-08-02 21:46:22,849-main.py:274-INFO-Train data = 1, Test data = 19
2024-08-02 21:46:23,637-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-02 21:46:23,638-main.py:109-INFO-Loading model:
2024-08-02 21:46:23,639-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-02 21:46:23,645-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-02 21:46:24,155-main.py:466-INFO- ------------------------------------------------------------------
2024-08-02 21:46:24,155-main.py:467-INFO- * Speed: 24.33884 ms/iter
2024-08-02 21:46:24,155-main.py:468-INFO- * MAPE: 0.69676
2024-08-02 21:46:24,155-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-02 21:46:24,155-main.py:470-INFO- * Kendall's Tau: 0.06432748538011696
2024-08-02 21:46:24,155-main.py:471-INFO- ------------------------------------------------------------------
2024-08-02 21:46:24,155-main.py:474-INFO- Average Latency : 23.02619031 ms
2024-08-03 10:49:02,698-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mnasnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-03 10:49:02,698-main.py:76-INFO-Loading dataset:
2024-08-03 10:49:45,959-main.py:274-INFO-Train data = 1, Test data = 26
2024-08-03 10:49:47,269-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-03 10:49:47,271-main.py:109-INFO-Loading model:
2024-08-03 10:49:47,271-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-03 10:49:47,292-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-03 10:49:48,308-main.py:466-INFO- ------------------------------------------------------------------
2024-08-03 10:49:48,308-main.py:467-INFO- * Speed: 33.69368 ms/iter
2024-08-03 10:49:48,308-main.py:468-INFO- * MAPE: 0.87788
2024-08-03 10:49:48,309-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-03 10:49:48,309-main.py:470-INFO- * Kendall's Tau: 0.15076923076923077
2024-08-03 10:49:48,309-main.py:471-INFO- ------------------------------------------------------------------
2024-08-03 10:49:48,309-main.py:474-INFO- Average Latency : 31.79495151 ms
2024-08-03 11:33:05,921-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-03 11:33:05,922-main.py:76-INFO-Loading dataset:
2024-08-03 11:33:46,087-main.py:274-INFO-Train data = 1, Test data = 29
2024-08-03 11:33:47,189-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-03 11:33:47,192-main.py:109-INFO-Loading model:
2024-08-03 11:33:47,192-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-03 11:33:47,214-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-03 11:33:48,438-main.py:466-INFO- ------------------------------------------------------------------
2024-08-03 11:33:48,438-main.py:467-INFO- * Speed: 39.78371 ms/iter
2024-08-03 11:33:48,439-main.py:468-INFO- * MAPE: 0.93616
2024-08-03 11:33:48,439-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-03 11:33:48,439-main.py:470-INFO- * Kendall's Tau: 0.019704433497536943
2024-08-03 11:33:48,439-main.py:471-INFO- ------------------------------------------------------------------
2024-08-03 11:33:48,440-main.py:474-INFO- Average Latency : 37.17167624 ms
2024-08-11 10:26:50,988-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-11 10:26:50,989-main.py:76-INFO-Loading dataset:
2024-08-11 10:26:52,767-main.py:274-INFO-Train data = 0, Test data = 12
2024-08-11 10:27:51,945-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-11 10:27:51,945-main.py:76-INFO-Loading dataset:
2024-08-11 10:27:51,951-main.py:274-INFO-Train data = 1, Test data = 11
2024-08-11 10:27:53,220-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-11 10:27:53,221-main.py:109-INFO-Loading model:
2024-08-11 10:27:53,222-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-11 10:27:53,242-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-11 10:27:54,139-main.py:466-INFO- ------------------------------------------------------------------
2024-08-11 10:27:54,139-main.py:467-INFO- * Speed: 69.48259 ms/iter
2024-08-11 10:27:54,139-main.py:468-INFO- * MAPE: 0.33290
2024-08-11 10:27:54,140-main.py:469-INFO- * ErrorBound: [0.18181818 0.09090909 0.        ]
2024-08-11 10:27:54,140-main.py:470-INFO- * Kendall's Tau: -0.3090909090909091
2024-08-11 10:27:54,140-main.py:471-INFO- ------------------------------------------------------------------
2024-08-11 10:27:54,140-main.py:474-INFO- Average Latency : 66.76461480 ms
2024-08-11 16:15:31,676-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-11 16:15:31,676-main.py:76-INFO-Loading dataset:
2024-08-11 16:15:31,682-main.py:274-INFO-Train data = 0, Test data = 0
2024-08-11 16:15:52,017-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-11 16:15:52,017-main.py:76-INFO-Loading dataset:
2024-08-11 16:15:54,268-main.py:274-INFO-Train data = 1, Test data = 29
2024-08-11 16:15:55,011-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-11 16:15:55,012-main.py:109-INFO-Loading model:
2024-08-11 16:15:55,013-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-11 16:15:55,020-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-11 16:15:55,608-main.py:466-INFO- ------------------------------------------------------------------
2024-08-11 16:15:55,608-main.py:467-INFO- * Speed: 18.58963 ms/iter
2024-08-11 16:15:55,608-main.py:468-INFO- * MAPE: 0.73292
2024-08-11 16:15:55,608-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-11 16:15:55,608-main.py:470-INFO- * Kendall's Tau: 0.05911330049261083
2024-08-11 16:15:55,608-main.py:471-INFO- ------------------------------------------------------------------
2024-08-11 16:15:55,609-main.py:474-INFO- Average Latency : 17.11162205 ms
2024-08-13 14:14:14,482-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-13 14:14:14,483-main.py:76-INFO-Loading dataset:
2024-08-13 14:14:32,610-main.py:274-INFO-Train data = 1, Test data = 23
2024-08-13 14:14:33,890-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-13 14:14:33,891-main.py:109-INFO-Loading model:
2024-08-13 14:14:33,893-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-13 14:14:33,913-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-13 14:14:34,901-main.py:466-INFO- ------------------------------------------------------------------
2024-08-13 14:14:34,901-main.py:467-INFO- * Speed: 36.66366 ms/iter
2024-08-13 14:14:34,901-main.py:468-INFO- * MAPE: 0.86049
2024-08-13 14:14:34,901-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-13 14:14:34,901-main.py:470-INFO- * Kendall's Tau: -0.1225296442687747
2024-08-13 14:14:34,902-main.py:471-INFO- ------------------------------------------------------------------
2024-08-13 14:14:34,902-main.py:474-INFO- Average Latency : 34.84395276 ms
2024-08-15 15:07:32,057-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-15 15:07:32,058-main.py:76-INFO-Loading dataset:
2024-08-15 15:07:53,573-main.py:274-INFO-Train data = 1, Test data = 23
2024-08-15 15:07:54,829-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-15 15:07:54,830-main.py:109-INFO-Loading model:
2024-08-15 15:07:54,831-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-15 15:07:54,851-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-15 15:07:55,813-main.py:466-INFO- ------------------------------------------------------------------
2024-08-15 15:07:55,814-main.py:467-INFO- * Speed: 36.01706 ms/iter
2024-08-15 15:07:55,814-main.py:468-INFO- * MAPE: 0.86049
2024-08-15 15:07:55,814-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-15 15:07:55,814-main.py:470-INFO- * Kendall's Tau: -0.1225296442687747
2024-08-15 15:07:55,815-main.py:471-INFO- ------------------------------------------------------------------
2024-08-15 15:07:55,815-main.py:474-INFO- Average Latency : 34.14737660 ms
2024-08-16 12:49:44,773-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-16 12:49:44,774-main.py:76-INFO-Loading dataset:
2024-08-16 12:49:49,645-main.py:274-INFO-Train data = 0, Test data = 22
2024-08-16 12:50:20,222-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-16 12:50:20,223-main.py:76-INFO-Loading dataset:
2024-08-16 12:50:25,419-main.py:274-INFO-Train data = 1, Test data = 22
2024-08-16 12:50:26,748-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-16 12:50:26,749-main.py:109-INFO-Loading model:
2024-08-16 12:50:26,752-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-16 12:50:26,772-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-16 12:50:27,780-main.py:466-INFO- ------------------------------------------------------------------
2024-08-16 12:50:27,780-main.py:467-INFO- * Speed: 39.55816 ms/iter
2024-08-16 12:50:27,780-main.py:468-INFO- * MAPE: 0.84274
2024-08-16 12:50:27,781-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-16 12:50:27,781-main.py:470-INFO- * Kendall's Tau: -0.2207792207792208
2024-08-16 12:50:27,781-main.py:471-INFO- ------------------------------------------------------------------
2024-08-16 12:50:27,781-main.py:474-INFO- Average Latency : 37.73987293 ms
2024-08-16 20:40:09,973-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-16 20:40:09,974-main.py:76-INFO-Loading dataset:
2024-08-16 20:40:16,248-main.py:274-INFO-Train data = 1, Test data = 22
2024-08-16 20:40:17,625-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-16 20:40:17,626-main.py:109-INFO-Loading model:
2024-08-16 20:40:17,626-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-16 20:40:17,647-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-16 20:40:18,741-main.py:466-INFO- ------------------------------------------------------------------
2024-08-16 20:40:18,741-main.py:467-INFO- * Speed: 43.46125 ms/iter
2024-08-16 20:40:18,741-main.py:468-INFO- * MAPE: 0.84274
2024-08-16 20:40:18,742-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-16 20:40:18,742-main.py:470-INFO- * Kendall's Tau: -0.2207792207792208
2024-08-16 20:40:18,742-main.py:471-INFO- ------------------------------------------------------------------
2024-08-16 20:40:18,742-main.py:474-INFO- Average Latency : 41.14291885 ms
2024-08-16 20:41:10,728-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-16 20:41:10,729-main.py:76-INFO-Loading dataset:
2024-08-16 20:41:13,768-main.py:274-INFO-Train data = 1, Test data = 27
2024-08-16 20:41:14,559-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-16 20:41:14,560-main.py:109-INFO-Loading model:
2024-08-16 20:41:14,561-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-16 20:41:14,568-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-16 20:41:15,123-main.py:466-INFO- ------------------------------------------------------------------
2024-08-16 20:41:15,123-main.py:467-INFO- * Speed: 18.76593 ms/iter
2024-08-16 20:41:15,123-main.py:468-INFO- * MAPE: 0.84121
2024-08-16 20:41:15,124-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-16 20:41:15,124-main.py:470-INFO- * Kendall's Tau: 0.36752136752136755
2024-08-16 20:41:15,124-main.py:471-INFO- ------------------------------------------------------------------
2024-08-16 20:41:15,124-main.py:474-INFO- Average Latency : 17.24733247 ms
2024-08-17 11:28:11,620-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mnasnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-17 11:28:11,620-main.py:76-INFO-Loading dataset:
2024-08-17 11:28:35,771-main.py:274-INFO-Train data = 1, Test data = 20
2024-08-17 11:28:37,051-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-17 11:28:37,051-main.py:109-INFO-Loading model:
2024-08-17 11:28:37,052-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-17 11:28:37,074-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-17 11:28:38,035-main.py:466-INFO- ------------------------------------------------------------------
2024-08-17 11:28:38,035-main.py:467-INFO- * Speed: 41.13073 ms/iter
2024-08-17 11:28:38,036-main.py:468-INFO- * MAPE: 0.76138
2024-08-17 11:28:38,036-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-17 11:28:38,036-main.py:470-INFO- * Kendall's Tau: 0.19999999999999998
2024-08-17 11:28:38,036-main.py:471-INFO- ------------------------------------------------------------------
2024-08-17 11:28:38,036-main.py:474-INFO- Average Latency : 39.18513060 ms
2024-08-17 12:05:03,960-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-17 12:05:03,960-main.py:76-INFO-Loading dataset:
2024-08-17 12:05:13,368-main.py:274-INFO-Train data = 1, Test data = 13
2024-08-17 12:05:14,124-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-17 12:05:14,125-main.py:109-INFO-Loading model:
2024-08-17 12:05:14,127-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-17 12:05:14,133-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-17 12:05:14,607-main.py:466-INFO- ------------------------------------------------------------------
2024-08-17 12:05:14,607-main.py:467-INFO- * Speed: 32.83666 ms/iter
2024-08-17 12:05:14,607-main.py:468-INFO- * MAPE: 0.79817
2024-08-17 12:05:14,607-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-17 12:05:14,607-main.py:470-INFO- * Kendall's Tau: -0.3589743589743589
2024-08-17 12:05:14,607-main.py:471-INFO- ------------------------------------------------------------------
2024-08-17 12:05:14,608-main.py:474-INFO- Average Latency : 31.32961347 ms
2024-08-19 14:37:03,313-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 14:37:03,313-main.py:76-INFO-Loading dataset:
2024-08-19 14:37:04,518-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 14:37:05,823-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 14:37:05,824-main.py:109-INFO-Loading model:
2024-08-19 14:37:05,825-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 14:37:05,843-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 14:37:06,702-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 14:37:06,702-main.py:467-INFO- * Speed: 723.70434 ms/iter
2024-08-19 14:37:06,703-main.py:468-INFO- * MAPE: 0.67163
2024-08-19 14:37:06,703-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-19 14:37:06,703-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 14:37:06,703-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 14:37:06,703-main.py:474-INFO- Average Latency : 715.70444107 ms
2024-08-19 15:44:00,378-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 15:44:00,378-main.py:76-INFO-Loading dataset:
2024-08-19 15:44:00,385-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 15:44:01,235-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 15:44:01,236-main.py:109-INFO-Loading model:
2024-08-19 15:44:01,237-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:44:01,254-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:44:01,711-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 15:44:01,712-main.py:467-INFO- * Speed: 409.94573 ms/iter
2024-08-19 15:44:01,712-main.py:468-INFO- * MAPE: 0.67163
2024-08-19 15:44:01,712-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-19 15:44:01,712-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 15:44:01,712-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 15:44:01,712-main.py:474-INFO- Average Latency : 405.94577789 ms
2024-08-19 15:44:33,632-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 15:44:33,632-main.py:76-INFO-Loading dataset:
2024-08-19 15:44:34,326-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 15:44:35,104-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 15:44:35,105-main.py:109-INFO-Loading model:
2024-08-19 15:44:35,106-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:44:35,113-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:44:35,566-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 15:44:35,566-main.py:467-INFO- * Speed: 404.13809 ms/iter
2024-08-19 15:44:35,566-main.py:468-INFO- * MAPE: 0.10548
2024-08-19 15:44:35,566-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-19 15:44:35,566-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 15:44:35,567-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 15:44:35,567-main.py:474-INFO- Average Latency : 402.13775635 ms
2024-08-19 15:48:49,788-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 15:48:49,790-main.py:76-INFO-Loading dataset:
2024-08-19 15:48:50,427-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 15:48:51,222-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 15:48:51,223-main.py:109-INFO-Loading model:
2024-08-19 15:48:51,224-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:48:51,230-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:48:51,685-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 15:48:51,685-main.py:467-INFO- * Speed: 404.74319 ms/iter
2024-08-19 15:48:51,685-main.py:468-INFO- * MAPE: 0.10548
2024-08-19 15:48:51,685-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-19 15:48:51,685-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 15:48:51,686-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 15:48:51,686-main.py:474-INFO- Average Latency : 401.74341202 ms
2024-08-19 15:53:33,405-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 15:53:33,406-main.py:76-INFO-Loading dataset:
2024-08-19 15:53:34,003-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 15:53:34,820-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 15:53:34,821-main.py:109-INFO-Loading model:
2024-08-19 15:53:34,822-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:53:34,829-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 15:53:35,294-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 15:53:35,294-main.py:467-INFO- * Speed: 414.44755 ms/iter
2024-08-19 15:53:35,294-main.py:468-INFO- * MAPE: 0.12557
2024-08-19 15:53:35,295-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-19 15:53:35,295-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 15:53:35,295-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 15:53:35,295-main.py:474-INFO- Average Latency : 412.44745255 ms
2024-08-19 21:54:34,328-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 21:54:34,329-main.py:76-INFO-Loading dataset:
2024-08-19 21:54:34,336-main.py:274-INFO-Train data = 0, Test data = 1
2024-08-19 21:55:55,413-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 21:55:55,413-main.py:76-INFO-Loading dataset:
2024-08-19 21:55:55,589-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 21:55:56,969-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 21:55:56,970-main.py:109-INFO-Loading model:
2024-08-19 21:55:56,970-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 21:55:56,991-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 21:55:58,033-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 21:55:58,033-main.py:467-INFO- * Speed: 895.02645 ms/iter
2024-08-19 21:55:58,033-main.py:468-INFO- * MAPE: 0.04769
2024-08-19 21:55:58,034-main.py:469-INFO- * ErrorBound: [1. 1. 0.]
2024-08-19 21:55:58,034-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 21:55:58,034-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 21:55:58,034-main.py:474-INFO- Average Latency : 877.02560425 ms
2024-08-19 21:59:43,056-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 21:59:43,056-main.py:76-INFO-Loading dataset:
2024-08-19 21:59:43,204-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 21:59:44,001-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 21:59:44,003-main.py:109-INFO-Loading model:
2024-08-19 21:59:44,004-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 21:59:44,011-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 21:59:44,489-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 21:59:44,489-main.py:467-INFO- * Speed: 427.42562 ms/iter
2024-08-19 21:59:44,489-main.py:468-INFO- * MAPE: 0.18046
2024-08-19 21:59:44,489-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-19 21:59:44,489-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 21:59:44,490-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 21:59:44,490-main.py:474-INFO- Average Latency : 424.42536354 ms
2024-08-19 22:01:18,708-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/ran.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-19 22:01:18,708-main.py:76-INFO-Loading dataset:
2024-08-19 22:01:18,809-main.py:274-INFO-Train data = 1, Test data = 1
2024-08-19 22:01:19,614-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-19 22:01:19,616-main.py:109-INFO-Loading model:
2024-08-19 22:01:19,617-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-19 22:01:19,623-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-19 22:01:20,080-main.py:466-INFO- ------------------------------------------------------------------
2024-08-19 22:01:20,080-main.py:467-INFO- * Speed: 409.68180 ms/iter
2024-08-19 22:01:20,081-main.py:468-INFO- * MAPE: 0.47380
2024-08-19 22:01:20,082-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-19 22:01:20,082-main.py:470-INFO- * Kendall's Tau: nan
2024-08-19 22:01:20,082-main.py:471-INFO- ------------------------------------------------------------------
2024-08-19 22:01:20,082-main.py:474-INFO- Average Latency : 406.68535233 ms
2024-08-20 15:27:34,195-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-20 15:27:34,195-main.py:76-INFO-Loading dataset:
2024-08-20 15:27:37,080-main.py:274-INFO-Train data = 1, Test data = 31
2024-08-20 15:27:38,436-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-20 15:27:38,438-main.py:109-INFO-Loading model:
2024-08-20 15:27:38,439-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-20 15:27:38,459-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-20 15:27:39,569-main.py:466-INFO- ------------------------------------------------------------------
2024-08-20 15:27:39,569-main.py:467-INFO- * Speed: 31.27043 ms/iter
2024-08-20 15:27:39,569-main.py:468-INFO- * MAPE: 0.24273
2024-08-20 15:27:39,570-main.py:469-INFO- * ErrorBound: [0.16129032 0.09677419 0.        ]
2024-08-20 15:27:39,570-main.py:470-INFO- * Kendall's Tau: -0.12258064516129034
2024-08-20 15:27:39,570-main.py:471-INFO- ------------------------------------------------------------------
2024-08-20 15:27:39,570-main.py:474-INFO- Average Latency : 29.23834708 ms
2024-08-30 20:11:59,595-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-30 20:11:59,596-main.py:76-INFO-Loading dataset:
2024-08-30 20:13:08,799-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-30 20:13:08,799-main.py:76-INFO-Loading dataset:
2024-08-30 20:13:53,610-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-30 20:13:53,610-main.py:76-INFO-Loading dataset:
2024-08-30 20:14:18,185-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-30 20:14:18,185-main.py:76-INFO-Loading dataset:
2024-08-30 20:14:18,457-main.py:274-INFO-Train data = 1, Test data = 2
2024-08-30 20:14:19,779-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-30 20:14:19,779-main.py:109-INFO-Loading model:
2024-08-30 20:14:19,780-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-30 20:14:19,789-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-30 20:14:20,641-main.py:466-INFO- ------------------------------------------------------------------
2024-08-30 20:14:20,641-main.py:467-INFO- * Speed: 371.37532 ms/iter
2024-08-30 20:14:20,641-main.py:468-INFO- * MAPE: 0.64645
2024-08-30 20:14:20,642-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-30 20:14:20,642-main.py:470-INFO- * Kendall's Tau: nan
2024-08-30 20:14:20,642-main.py:471-INFO- ------------------------------------------------------------------
2024-08-30 20:14:20,643-main.py:474-INFO- Average Latency : 362.90323734 ms
2024-08-30 20:56:50,615-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-30 20:56:50,615-main.py:76-INFO-Loading dataset:
2024-08-30 20:56:51,236-main.py:274-INFO-Train data = 1, Test data = 4
2024-08-30 20:56:52,004-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-30 20:56:52,005-main.py:109-INFO-Loading model:
2024-08-30 20:56:52,006-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-30 20:56:52,012-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-30 20:56:52,458-main.py:466-INFO- ------------------------------------------------------------------
2024-08-30 20:56:52,458-main.py:467-INFO- * Speed: 99.41828 ms/iter
2024-08-30 20:56:52,458-main.py:468-INFO- * MAPE: 0.64543
2024-08-30 20:56:52,459-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-30 20:56:52,459-main.py:470-INFO- * Kendall's Tau: nan
2024-08-30 20:56:52,459-main.py:471-INFO- ------------------------------------------------------------------
2024-08-30 20:56:52,459-main.py:474-INFO- Average Latency : 97.92327881 ms
2024-08-31 22:31:26,382-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-31 22:31:26,383-main.py:76-INFO-Loading dataset:
2024-08-31 22:31:28,238-main.py:274-INFO-Train data = 1, Test data = 4
2024-08-31 22:31:29,539-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-31 22:31:29,540-main.py:109-INFO-Loading model:
2024-08-31 22:31:29,541-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-31 22:31:29,558-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-31 22:31:30,047-main.py:466-INFO- ------------------------------------------------------------------
2024-08-31 22:31:30,047-main.py:467-INFO- * Speed: 110.16321 ms/iter
2024-08-31 22:31:30,047-main.py:468-INFO- * MAPE: 0.58806
2024-08-31 22:31:30,048-main.py:469-INFO- * ErrorBound: [0.25 0.   0.  ]
2024-08-31 22:31:30,048-main.py:470-INFO- * Kendall's Tau: nan
2024-08-31 22:31:30,048-main.py:471-INFO- ------------------------------------------------------------------
2024-08-31 22:31:30,048-main.py:474-INFO- Average Latency : 106.91326857 ms
2024-08-31 22:32:15,299-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-08-31 22:32:15,300-main.py:76-INFO-Loading dataset:
2024-08-31 22:32:17,163-main.py:274-INFO-Train data = 1, Test data = 4
2024-08-31 22:32:17,935-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-08-31 22:32:17,936-main.py:109-INFO-Loading model:
2024-08-31 22:32:17,937-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-08-31 22:32:17,943-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-08-31 22:32:18,397-main.py:466-INFO- ------------------------------------------------------------------
2024-08-31 22:32:18,397-main.py:467-INFO- * Speed: 101.24999 ms/iter
2024-08-31 22:32:18,397-main.py:468-INFO- * MAPE: 0.84760
2024-08-31 22:32:18,397-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-08-31 22:32:18,397-main.py:470-INFO- * Kendall's Tau: 0.3333333333333334
2024-08-31 22:32:18,397-main.py:471-INFO- ------------------------------------------------------------------
2024-08-31 22:32:18,398-main.py:474-INFO- Average Latency : 99.25007820 ms
2024-09-01 17:27:35,265-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-01 17:27:35,266-main.py:76-INFO-Loading dataset:
2024-09-01 17:27:35,277-main.py:274-INFO-Train data = 1, Test data = 4
2024-09-01 17:27:36,598-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-01 17:27:36,600-main.py:109-INFO-Loading model:
2024-09-01 17:27:36,602-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-01 17:27:36,626-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-01 17:27:37,575-main.py:466-INFO- ------------------------------------------------------------------
2024-09-01 17:27:37,575-main.py:467-INFO- * Speed: 200.96833 ms/iter
2024-09-01 17:27:37,575-main.py:468-INFO- * MAPE: 0.84760
2024-09-01 17:27:37,575-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-09-01 17:27:37,576-main.py:470-INFO- * Kendall's Tau: 0.3333333333333334
2024-09-01 17:27:37,576-main.py:471-INFO- ------------------------------------------------------------------
2024-09-01 17:27:37,576-main.py:474-INFO- Average Latency : 193.71628761 ms
2024-09-02 18:07:09,955-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-02 18:07:09,956-main.py:76-INFO-Loading dataset:
2024-09-02 18:07:10,105-main.py:274-INFO-Train data = 1, Test data = 2
2024-09-02 18:07:10,867-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-02 18:07:10,868-main.py:109-INFO-Loading model:
2024-09-02 18:07:10,869-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-02 18:07:10,887-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-02 18:07:11,733-main.py:466-INFO- ------------------------------------------------------------------
2024-09-02 18:07:11,733-main.py:467-INFO- * Speed: 352.98061 ms/iter
2024-09-02 18:07:11,733-main.py:468-INFO- * MAPE: 0.78565
2024-09-02 18:07:11,733-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-09-02 18:07:11,733-main.py:470-INFO- * Kendall's Tau: -1.0
2024-09-02 18:07:11,733-main.py:471-INFO- ------------------------------------------------------------------
2024-09-02 18:07:11,734-main.py:474-INFO- Average Latency : 348.98042679 ms
2024-09-02 18:14:22,749-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-02 18:14:22,750-main.py:76-INFO-Loading dataset:
2024-09-02 18:14:22,786-main.py:274-INFO-Train data = 0, Test data = 1
2024-09-02 18:14:55,903-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-02 18:14:55,904-main.py:76-INFO-Loading dataset:
2024-09-02 18:14:55,963-main.py:274-INFO-Train data = 1, Test data = 1
2024-09-02 18:14:56,733-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-02 18:14:56,733-main.py:109-INFO-Loading model:
2024-09-02 18:14:56,734-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-02 18:14:56,744-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-02 18:14:57,171-main.py:466-INFO- ------------------------------------------------------------------
2024-09-02 18:14:57,171-main.py:467-INFO- * Speed: 377.28095 ms/iter
2024-09-02 18:14:57,171-main.py:468-INFO- * MAPE: 0.52897
2024-09-02 18:14:57,172-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-09-02 18:14:57,172-main.py:470-INFO- * Kendall's Tau: nan
2024-09-02 18:14:57,172-main.py:471-INFO- ------------------------------------------------------------------
2024-09-02 18:14:57,172-main.py:474-INFO- Average Latency : 374.77636337 ms
2024-09-02 23:33:28,335-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-02 23:33:28,336-main.py:76-INFO-Loading dataset:
2024-09-02 23:33:28,342-main.py:274-INFO-Train data = 1, Test data = 1
2024-09-02 23:33:29,660-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-02 23:33:29,661-main.py:109-INFO-Loading model:
2024-09-02 23:33:29,662-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-02 23:33:29,681-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-02 23:33:30,658-main.py:466-INFO- ------------------------------------------------------------------
2024-09-02 23:33:30,658-main.py:467-INFO- * Speed: 836.74908 ms/iter
2024-09-02 23:33:30,658-main.py:468-INFO- * MAPE: 0.52897
2024-09-02 23:33:30,659-main.py:469-INFO- * ErrorBound: [0. 0. 0.]
2024-09-02 23:33:30,659-main.py:470-INFO- * Kendall's Tau: nan
2024-09-02 23:33:30,659-main.py:471-INFO- ------------------------------------------------------------------
2024-09-02 23:33:30,659-main.py:474-INFO- Average Latency : 807.74903297 ms
2024-09-03 12:07:28,591-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-03 12:07:28,592-main.py:76-INFO-Loading dataset:
2024-09-03 12:07:29,454-main.py:274-INFO-Train data = 1, Test data = 2
2024-09-03 12:07:30,765-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-03 12:07:30,765-main.py:109-INFO-Loading model:
2024-09-03 12:07:30,766-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-03 12:07:30,784-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-03 12:07:31,624-main.py:465-INFO- ------------------------------------------------------------------
2024-09-03 12:07:31,624-main.py:466-INFO- * Speed: 350.98708 ms/iter
2024-09-03 12:07:31,624-main.py:467-INFO- * MAPE: 0.94056
2024-09-03 12:07:31,624-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-03 12:07:31,624-main.py:469-INFO- * Kendall's Tau: 1.0
2024-09-03 12:07:31,625-main.py:470-INFO- ------------------------------------------------------------------
2024-09-03 12:07:31,625-main.py:473-INFO- Average Latency : 347.48673439 ms
2024-09-03 12:09:35,845-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-03 12:09:35,845-main.py:76-INFO-Loading dataset:
2024-09-03 12:09:36,542-main.py:274-INFO-Train data = 1, Test data = 3
2024-09-03 12:09:37,311-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-03 12:09:37,312-main.py:109-INFO-Loading model:
2024-09-03 12:09:37,312-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-03 12:09:37,319-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-03 12:09:37,746-main.py:465-INFO- ------------------------------------------------------------------
2024-09-03 12:09:37,746-main.py:466-INFO- * Speed: 125.99985 ms/iter
2024-09-03 12:09:37,746-main.py:467-INFO- * MAPE: 0.94112
2024-09-03 12:09:37,746-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-03 12:09:37,747-main.py:469-INFO- * Kendall's Tau: 1.0
2024-09-03 12:09:37,747-main.py:470-INFO- ------------------------------------------------------------------
2024-09-03 12:09:37,748-main.py:473-INFO- Average Latency : 123.99983406 ms
2024-09-03 13:31:10,235-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-03 13:31:10,236-main.py:76-INFO-Loading dataset:
2024-09-03 13:31:11,907-main.py:274-INFO-Train data = 1, Test data = 4
2024-09-03 13:31:12,662-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-03 13:31:12,663-main.py:109-INFO-Loading model:
2024-09-03 13:31:12,664-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:31:12,670-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:31:13,101-main.py:465-INFO- ------------------------------------------------------------------
2024-09-03 13:31:13,101-main.py:466-INFO- * Speed: 95.69550 ms/iter
2024-09-03 13:31:13,101-main.py:467-INFO- * MAPE: 0.85776
2024-09-03 13:31:13,101-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-03 13:31:13,101-main.py:469-INFO- * Kendall's Tau: 0.0
2024-09-03 13:31:13,101-main.py:470-INFO- ------------------------------------------------------------------
2024-09-03 13:31:13,102-main.py:473-INFO- Average Latency : 93.69552135 ms
2024-09-03 13:32:35,525-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-03 13:32:35,525-main.py:76-INFO-Loading dataset:
2024-09-03 13:32:37,274-main.py:274-INFO-Train data = 1, Test data = 4
2024-09-03 13:32:38,030-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-03 13:32:38,031-main.py:109-INFO-Loading model:
2024-09-03 13:32:38,032-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:32:38,038-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:32:38,469-main.py:465-INFO- ------------------------------------------------------------------
2024-09-03 13:32:38,470-main.py:466-INFO- * Speed: 95.95853 ms/iter
2024-09-03 13:32:38,470-main.py:467-INFO- * MAPE: 0.87843
2024-09-03 13:32:38,470-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-03 13:32:38,470-main.py:469-INFO- * Kendall's Tau: 0.0
2024-09-03 13:32:38,470-main.py:470-INFO- ------------------------------------------------------------------
2024-09-03 13:32:38,470-main.py:473-INFO- Average Latency : 94.20835972 ms
2024-09-03 13:33:40,918-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-03 13:33:40,918-main.py:76-INFO-Loading dataset:
2024-09-03 13:33:42,752-main.py:274-INFO-Train data = 1, Test data = 4
2024-09-03 13:33:43,505-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-03 13:33:43,505-main.py:109-INFO-Loading model:
2024-09-03 13:33:43,506-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:33:43,513-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:33:43,959-main.py:465-INFO- ------------------------------------------------------------------
2024-09-03 13:33:43,959-main.py:466-INFO- * Speed: 99.45762 ms/iter
2024-09-03 13:33:43,959-main.py:467-INFO- * MAPE: 0.90951
2024-09-03 13:33:43,959-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-03 13:33:43,959-main.py:469-INFO- * Kendall's Tau: 0.3333333333333334
2024-09-03 13:33:43,959-main.py:470-INFO- ------------------------------------------------------------------
2024-09-03 13:33:43,960-main.py:473-INFO- Average Latency : 97.20760584 ms
2024-09-03 13:34:55,816-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-03 13:34:55,816-main.py:76-INFO-Loading dataset:
2024-09-03 13:34:57,635-main.py:274-INFO-Train data = 1, Test data = 4
2024-09-03 13:34:58,395-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-03 13:34:58,396-main.py:109-INFO-Loading model:
2024-09-03 13:34:58,397-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:34:58,403-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-03 13:34:58,841-main.py:465-INFO- ------------------------------------------------------------------
2024-09-03 13:34:58,841-main.py:466-INFO- * Speed: 97.97478 ms/iter
2024-09-03 13:34:58,841-main.py:467-INFO- * MAPE: 0.88370
2024-09-03 13:34:58,841-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-03 13:34:58,842-main.py:469-INFO- * Kendall's Tau: 0.0
2024-09-03 13:34:58,842-main.py:470-INFO- ------------------------------------------------------------------
2024-09-03 13:34:58,842-main.py:473-INFO- Average Latency : 96.22472525 ms
2024-09-03 15:02:05,756-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-03 15:02:05,756-main.py:76-INFO-Loading dataset:
2024-09-03 15:02:05,789-main.py:274-INFO-Train data = 1, Test data = 5
2024-09-03 15:02:06,546-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-03 15:02:06,547-main.py:109-INFO-Loading model:
2024-09-03 15:02:06,547-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-03 15:02:06,554-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-03 15:02:07,014-main.py:465-INFO- ------------------------------------------------------------------
2024-09-03 15:02:07,014-main.py:466-INFO- * Speed: 82.82752 ms/iter
2024-09-03 15:02:07,014-main.py:467-INFO- * MAPE: 0.78115
2024-09-03 15:02:07,015-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-03 15:02:07,015-main.py:469-INFO- * Kendall's Tau: -0.39999999999999997
2024-09-03 15:02:07,015-main.py:470-INFO- ------------------------------------------------------------------
2024-09-03 15:02:07,016-main.py:473-INFO- Average Latency : 81.22749329 ms
2024-09-04 12:37:34,883-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:37:34,883-main.py:76-INFO-Loading dataset:
2024-09-04 12:37:37,164-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:37:38,484-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:37:38,484-main.py:109-INFO-Loading model:
2024-09-04 12:37:38,485-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:37:38,506-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:37:39,402-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:37:39,402-main.py:466-INFO- * Speed: 126.09788 ms/iter
2024-09-04 12:37:39,402-main.py:467-INFO- * MAPE: 0.72649
2024-09-04 12:37:39,403-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:37:39,403-main.py:469-INFO- * Kendall's Tau: -0.4666666666666666
2024-09-04 12:37:39,403-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:37:39,403-main.py:473-INFO- Average Latency : 123.60624472 ms
2024-09-04 12:43:03,426-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:43:03,426-main.py:76-INFO-Loading dataset:
2024-09-04 12:43:05,372-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:43:06,176-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:43:06,177-main.py:109-INFO-Loading model:
2024-09-04 12:43:06,177-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:43:06,184-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:43:06,625-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:43:06,625-main.py:466-INFO- * Speed: 65.50026 ms/iter
2024-09-04 12:43:06,625-main.py:467-INFO- * MAPE: 0.67133
2024-09-04 12:43:06,625-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:43:06,625-main.py:469-INFO- * Kendall's Tau: -0.6
2024-09-04 12:43:06,625-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:43:06,626-main.py:473-INFO- Average Latency : 63.83915742 ms
2024-09-04 12:44:23,579-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:44:23,580-main.py:76-INFO-Loading dataset:
2024-09-04 12:44:25,540-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:44:26,345-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:44:26,345-main.py:109-INFO-Loading model:
2024-09-04 12:44:26,346-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:44:26,352-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:44:26,798-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:44:26,798-main.py:466-INFO- * Speed: 66.00181 ms/iter
2024-09-04 12:44:26,799-main.py:467-INFO- * MAPE: 0.69394
2024-09-04 12:44:26,799-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:44:26,799-main.py:469-INFO- * Kendall's Tau: -0.4666666666666666
2024-09-04 12:44:26,799-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:44:26,800-main.py:473-INFO- Average Latency : 64.50736523 ms
2024-09-04 12:45:41,869-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:45:41,869-main.py:76-INFO-Loading dataset:
2024-09-04 12:45:43,810-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:45:44,613-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:45:44,613-main.py:109-INFO-Loading model:
2024-09-04 12:45:44,614-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:45:44,621-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:45:45,059-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:45:45,060-main.py:466-INFO- * Speed: 64.90151 ms/iter
2024-09-04 12:45:45,060-main.py:467-INFO- * MAPE: 0.69457
2024-09-04 12:45:45,060-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:45:45,060-main.py:469-INFO- * Kendall's Tau: -0.4666666666666666
2024-09-04 12:45:45,061-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:45:45,061-main.py:473-INFO- Average Latency : 63.24040890 ms
2024-09-04 12:46:48,594-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:46:48,594-main.py:76-INFO-Loading dataset:
2024-09-04 12:46:50,537-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:46:51,332-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:46:51,333-main.py:109-INFO-Loading model:
2024-09-04 12:46:51,334-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:46:51,340-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:46:51,781-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:46:51,781-main.py:466-INFO- * Speed: 65.67705 ms/iter
2024-09-04 12:46:51,781-main.py:467-INFO- * MAPE: 0.65468
2024-09-04 12:46:51,781-main.py:468-INFO- * ErrorBound: [0.16666667 0.16666667 0.        ]
2024-09-04 12:46:51,781-main.py:469-INFO- * Kendall's Tau: -0.6
2024-09-04 12:46:51,782-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:46:51,782-main.py:473-INFO- Average Latency : 64.01578585 ms
2024-09-04 12:48:57,984-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:48:57,984-main.py:76-INFO-Loading dataset:
2024-09-04 12:48:59,947-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:49:00,724-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:49:00,725-main.py:109-INFO-Loading model:
2024-09-04 12:49:00,725-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:49:00,732-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:49:01,188-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:49:01,188-main.py:466-INFO- * Speed: 67.47071 ms/iter
2024-09-04 12:49:01,188-main.py:467-INFO- * MAPE: 0.67133
2024-09-04 12:49:01,189-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:49:01,190-main.py:469-INFO- * Kendall's Tau: -0.6
2024-09-04 12:49:01,190-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:49:01,190-main.py:473-INFO- Average Latency : 65.64323107 ms
2024-09-04 12:54:46,633-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:54:46,633-main.py:76-INFO-Loading dataset:
2024-09-04 12:54:48,612-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:54:49,408-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:54:49,408-main.py:109-INFO-Loading model:
2024-09-04 12:54:49,409-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:54:49,415-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:54:49,859-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:54:49,860-main.py:466-INFO- * Speed: 66.27826 ms/iter
2024-09-04 12:54:49,860-main.py:467-INFO- * MAPE: 0.69394
2024-09-04 12:54:49,860-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:54:49,860-main.py:469-INFO- * Kendall's Tau: -0.4666666666666666
2024-09-04 12:54:49,860-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:54:49,861-main.py:473-INFO- Average Latency : 64.61711725 ms
2024-09-04 12:55:48,214-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:55:48,214-main.py:76-INFO-Loading dataset:
2024-09-04 12:55:50,180-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:55:50,951-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:55:50,952-main.py:109-INFO-Loading model:
2024-09-04 12:55:50,953-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:55:50,959-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:55:51,412-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:55:51,412-main.py:466-INFO- * Speed: 67.47377 ms/iter
2024-09-04 12:55:51,413-main.py:467-INFO- * MAPE: 0.69457
2024-09-04 12:55:51,413-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:55:51,413-main.py:469-INFO- * Kendall's Tau: -0.4666666666666666
2024-09-04 12:55:51,413-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:55:51,413-main.py:473-INFO- Average Latency : 65.97888470 ms
2024-09-04 12:56:47,512-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:56:47,512-main.py:76-INFO-Loading dataset:
2024-09-04 12:56:49,484-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:56:50,276-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:56:50,277-main.py:109-INFO-Loading model:
2024-09-04 12:56:50,278-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:56:50,284-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:56:50,724-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:56:50,724-main.py:466-INFO- * Speed: 65.80905 ms/iter
2024-09-04 12:56:50,724-main.py:467-INFO- * MAPE: 0.71666
2024-09-04 12:56:50,724-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:56:50,724-main.py:469-INFO- * Kendall's Tau: -0.4666666666666666
2024-09-04 12:56:50,725-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:56:50,725-main.py:473-INFO- Average Latency : 64.31357066 ms
2024-09-04 12:57:55,785-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-04 12:57:55,785-main.py:76-INFO-Loading dataset:
2024-09-04 12:57:57,727-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-04 12:57:58,520-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-04 12:57:58,521-main.py:109-INFO-Loading model:
2024-09-04 12:57:58,522-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:57:58,528-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-04 12:57:58,979-main.py:465-INFO- ------------------------------------------------------------------
2024-09-04 12:57:58,979-main.py:466-INFO- * Speed: 67.04104 ms/iter
2024-09-04 12:57:58,979-main.py:467-INFO- * MAPE: 0.67514
2024-09-04 12:57:58,979-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-04 12:57:58,979-main.py:469-INFO- * Kendall's Tau: -0.6
2024-09-04 12:57:58,979-main.py:470-INFO- ------------------------------------------------------------------
2024-09-04 12:57:58,980-main.py:473-INFO- Average Latency : 65.37977854 ms
2024-09-20 15:50:12,315-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-20 15:50:12,316-main.py:76-INFO-Loading dataset:
2024-09-20 15:50:14,820-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-20 15:50:16,136-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-20 15:50:16,139-main.py:109-INFO-Loading model:
2024-09-20 15:50:16,140-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-20 15:50:16,158-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-20 15:50:17,129-main.py:465-INFO- ------------------------------------------------------------------
2024-09-20 15:50:17,129-main.py:466-INFO- * Speed: 143.36721 ms/iter
2024-09-20 15:50:17,129-main.py:467-INFO- * MAPE: 0.67514
2024-09-20 15:50:17,129-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-20 15:50:17,129-main.py:469-INFO- * Kendall's Tau: -0.6
2024-09-20 15:50:17,130-main.py:470-INFO- ------------------------------------------------------------------
2024-09-20 15:50:17,130-main.py:473-INFO- Average Latency : 133.28254223 ms
2024-09-20 15:55:12,885-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-20 15:55:12,885-main.py:76-INFO-Loading dataset:
2024-09-20 15:55:14,935-main.py:274-INFO-Train data = 1, Test data = 6
2024-09-20 15:55:15,726-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-20 15:55:15,727-main.py:109-INFO-Loading model:
2024-09-20 15:55:15,728-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-20 15:55:15,735-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-20 15:55:16,228-main.py:465-INFO- ------------------------------------------------------------------
2024-09-20 15:55:16,228-main.py:466-INFO- * Speed: 74.46130 ms/iter
2024-09-20 15:55:16,228-main.py:467-INFO- * MAPE: 0.67514
2024-09-20 15:55:16,229-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-09-20 15:55:16,229-main.py:469-INFO- * Kendall's Tau: -0.6
2024-09-20 15:55:16,229-main.py:470-INFO- ------------------------------------------------------------------
2024-09-20 15:55:16,229-main.py:473-INFO- Average Latency : 68.29476357 ms
2024-09-20 15:55:47,987-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/torchpruing.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-20 15:55:47,988-main.py:76-INFO-Loading dataset:
2024-09-20 15:55:58,024-main.py:274-INFO-Train data = 1, Test data = 37
2024-09-20 15:55:58,802-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-20 15:55:58,802-main.py:109-INFO-Loading model:
2024-09-20 15:55:58,803-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-20 15:55:58,809-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-20 15:55:59,681-main.py:465-INFO- ------------------------------------------------------------------
2024-09-20 15:55:59,681-main.py:466-INFO- * Speed: 22.29614 ms/iter
2024-09-20 15:55:59,681-main.py:467-INFO- * MAPE: 3.37302
2024-09-20 15:55:59,682-main.py:468-INFO- * ErrorBound: [0.02702703 0.02702703 0.        ]
2024-09-20 15:55:59,682-main.py:469-INFO- * Kendall's Tau: -0.1203008878975136
2024-09-20 15:55:59,682-main.py:470-INFO- ------------------------------------------------------------------
2024-09-20 15:55:59,682-main.py:473-INFO- Average Latency : 13.51270160 ms
2024-09-20 16:01:08,309-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/NPGR.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-20 16:01:08,309-main.py:76-INFO-Loading dataset:
2024-09-20 16:01:11,742-main.py:274-INFO-Train data = 1, Test data = 18
2024-09-20 16:01:12,508-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-20 16:01:12,509-main.py:109-INFO-Loading model:
2024-09-20 16:01:12,510-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-20 16:01:12,516-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-20 16:01:13,154-main.py:465-INFO- ------------------------------------------------------------------
2024-09-20 16:01:13,155-main.py:466-INFO- * Speed: 32.82090 ms/iter
2024-09-20 16:01:13,155-main.py:467-INFO- * MAPE: 0.90698
2024-09-20 16:01:13,155-main.py:468-INFO- * ErrorBound: [0.05555556 0.         0.        ]
2024-09-20 16:01:13,155-main.py:469-INFO- * Kendall's Tau: -0.47712418300653603
2024-09-20 16:01:13,155-main.py:470-INFO- ------------------------------------------------------------------
2024-09-20 16:01:13,155-main.py:473-INFO- Average Latency : 24.43201012 ms
2024-09-20 16:03:59,998-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/PFEC.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-20 16:03:59,998-main.py:76-INFO-Loading dataset:
2024-09-20 16:04:03,517-main.py:274-INFO-Train data = 1, Test data = 18
2024-09-20 16:04:04,308-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-20 16:04:04,309-main.py:109-INFO-Loading model:
2024-09-20 16:04:04,310-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-20 16:04:04,317-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-20 16:04:04,961-main.py:465-INFO- ------------------------------------------------------------------
2024-09-20 16:04:04,961-main.py:466-INFO- * Speed: 33.13976 ms/iter
2024-09-20 16:04:04,961-main.py:467-INFO- * MAPE: 0.89068
2024-09-20 16:04:04,961-main.py:468-INFO- * ErrorBound: [0.05555556 0.05555556 0.05555556]
2024-09-20 16:04:04,961-main.py:469-INFO- * Kendall's Tau: -0.5163398692810458
2024-09-20 16:04:04,962-main.py:470-INFO- ------------------------------------------------------------------
2024-09-20 16:04:04,962-main.py:473-INFO- Average Latency : 24.94451735 ms
2024-09-22 17:10:08,190-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/NPGR.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-22 17:10:08,191-main.py:76-INFO-Loading dataset:
2024-09-22 17:10:18,844-main.py:274-INFO-Train data = 1, Test data = 36
2024-09-22 17:10:20,229-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-22 17:10:20,230-main.py:109-INFO-Loading model:
2024-09-22 17:10:20,232-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:10:20,255-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:10:21,387-main.py:465-INFO- ------------------------------------------------------------------
2024-09-22 17:10:21,388-main.py:466-INFO- * Speed: 27.72572 ms/iter
2024-09-22 17:10:21,388-main.py:467-INFO- * MAPE: 1.73223
2024-09-22 17:10:21,388-main.py:468-INFO- * ErrorBound: [0.02777778 0.         0.        ]
2024-09-22 17:10:21,388-main.py:469-INFO- * Kendall's Tau: -0.04761904761904763
2024-09-22 17:10:21,388-main.py:470-INFO- ------------------------------------------------------------------
2024-09-22 17:10:21,388-main.py:473-INFO- Average Latency : 25.86479982 ms
2024-09-22 17:11:17,210-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/NPGR.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-22 17:11:17,210-main.py:76-INFO-Loading dataset:
2024-09-22 17:11:26,251-main.py:274-INFO-Train data = 1, Test data = 36
2024-09-22 17:11:27,028-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-22 17:11:27,029-main.py:109-INFO-Loading model:
2024-09-22 17:11:27,030-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:11:27,037-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:11:27,621-main.py:465-INFO- ------------------------------------------------------------------
2024-09-22 17:11:27,621-main.py:466-INFO- * Speed: 14.90052 ms/iter
2024-09-22 17:11:27,621-main.py:467-INFO- * MAPE: 1.73223
2024-09-22 17:11:27,622-main.py:468-INFO- * ErrorBound: [0.02777778 0.         0.        ]
2024-09-22 17:11:27,622-main.py:469-INFO- * Kendall's Tau: -0.04761904761904763
2024-09-22 17:11:27,622-main.py:470-INFO- ------------------------------------------------------------------
2024-09-22 17:11:27,622-main.py:473-INFO- Average Latency : 13.52547937 ms
2024-09-22 17:11:48,428-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/PFEC.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-22 17:11:48,428-main.py:76-INFO-Loading dataset:
2024-09-22 17:11:58,871-main.py:274-INFO-Train data = 1, Test data = 36
2024-09-22 17:11:59,652-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-22 17:11:59,653-main.py:109-INFO-Loading model:
2024-09-22 17:11:59,654-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:11:59,661-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:12:00,269-main.py:465-INFO- ------------------------------------------------------------------
2024-09-22 17:12:00,269-main.py:466-INFO- * Speed: 15.53146 ms/iter
2024-09-22 17:12:00,269-main.py:467-INFO- * MAPE: 1.72732
2024-09-22 17:12:00,269-main.py:468-INFO- * ErrorBound: [0.02777778 0.         0.        ]
2024-09-22 17:12:00,269-main.py:469-INFO- * Kendall's Tau: -0.060317460317460325
2024-09-22 17:12:00,269-main.py:470-INFO- ------------------------------------------------------------------
2024-09-22 17:12:00,270-main.py:473-INFO- Average Latency : 14.00872734 ms
2024-09-22 17:12:25,449-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/torchpruing.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-22 17:12:25,449-main.py:76-INFO-Loading dataset:
2024-09-22 17:14:09,253-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/torchpruing.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-22 17:14:09,253-main.py:76-INFO-Loading dataset:
2024-09-22 17:14:16,387-main.py:274-INFO-Train data = 1, Test data = 28
2024-09-22 17:14:17,193-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-22 17:14:17,194-main.py:109-INFO-Loading model:
2024-09-22 17:14:17,195-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:14:17,202-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-22 17:14:17,767-main.py:465-INFO- ------------------------------------------------------------------
2024-09-22 17:14:17,768-main.py:466-INFO- * Speed: 18.49663 ms/iter
2024-09-22 17:14:17,768-main.py:467-INFO- * MAPE: 2.23450
2024-09-22 17:14:17,768-main.py:468-INFO- * ErrorBound: [0.07142857 0.         0.        ]
2024-09-22 17:14:17,768-main.py:469-INFO- * Kendall's Tau: -0.07936507936507936
2024-09-22 17:14:17,768-main.py:470-INFO- ------------------------------------------------------------------
2024-09-22 17:14:17,768-main.py:473-INFO- Average Latency : 17.16963734 ms
2024-09-23 16:11:47,060-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/torchpruing.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-09-23 16:11:47,061-main.py:76-INFO-Loading dataset:
2024-09-23 16:11:54,406-main.py:274-INFO-Train data = 1, Test data = 36
2024-09-23 16:11:55,760-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-09-23 16:11:55,760-main.py:109-INFO-Loading model:
2024-09-23 16:11:55,761-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-09-23 16:11:55,783-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-09-23 16:11:56,867-main.py:465-INFO- ------------------------------------------------------------------
2024-09-23 16:11:56,868-main.py:466-INFO- * Speed: 26.21508 ms/iter
2024-09-23 16:11:56,868-main.py:467-INFO- * MAPE: 1.88287
2024-09-23 16:11:56,869-main.py:468-INFO- * ErrorBound: [0.08333333 0.02777778 0.        ]
2024-09-23 16:11:56,869-main.py:469-INFO- * Kendall's Tau: -0.041269841269841276
2024-09-23 16:11:56,869-main.py:470-INFO- ------------------------------------------------------------------
2024-09-23 16:11:56,869-main.py:473-INFO- Average Latency : 24.30478732 ms
2024-11-04 13:09:43,153-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-04 13:09:43,153-main.py:76-INFO-Loading dataset:
2024-11-04 13:09:43,161-main.py:274-INFO-Train data = 0, Test data = 0
2024-11-04 13:10:16,118-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-04 13:10:16,118-main.py:76-INFO-Loading dataset:
2024-11-04 13:10:16,125-main.py:274-INFO-Train data = 0, Test data = 0
2024-11-04 13:11:17,101-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-04 13:11:17,101-main.py:76-INFO-Loading dataset:
2024-11-04 13:11:18,094-main.py:274-INFO-Train data = 1, Test data = 8
2024-11-04 13:11:19,504-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-04 13:11:19,504-main.py:109-INFO-Loading model:
2024-11-04 13:11:19,505-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-04 13:11:19,527-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-04 13:11:20,445-main.py:465-INFO- ------------------------------------------------------------------
2024-11-04 13:11:20,445-main.py:466-INFO- * Speed: 96.78838 ms/iter
2024-11-04 13:11:20,445-main.py:467-INFO- * MAPE: 0.32897
2024-11-04 13:11:20,445-main.py:468-INFO- * ErrorBound: [0.125 0.    0.   ]
2024-11-04 13:11:20,446-main.py:469-INFO- * Kendall's Tau: 0.40006613209931935
2024-11-04 13:11:20,446-main.py:470-INFO- ------------------------------------------------------------------
2024-11-04 13:11:20,446-main.py:473-INFO- Average Latency : 93.79810095 ms
2024-11-04 13:26:40,567-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-04 13:26:40,567-main.py:76-INFO-Loading dataset:
2024-11-04 13:26:42,287-main.py:274-INFO-Train data = 1, Test data = 2
2024-11-04 13:26:43,185-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-04 13:26:43,186-main.py:109-INFO-Loading model:
2024-11-04 13:26:43,186-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-04 13:26:43,193-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-04 13:26:43,635-main.py:465-INFO- ------------------------------------------------------------------
2024-11-04 13:26:43,635-main.py:466-INFO- * Speed: 189.93139 ms/iter
2024-11-04 13:26:43,635-main.py:467-INFO- * MAPE: 0.23903
2024-11-04 13:26:43,635-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-11-04 13:26:43,635-main.py:469-INFO- * Kendall's Tau: 1.0
2024-11-04 13:26:43,635-main.py:470-INFO- ------------------------------------------------------------------
2024-11-04 13:26:43,636-main.py:473-INFO- Average Latency : 187.93785572 ms
2024-11-04 14:41:57,884-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-04 14:41:57,885-main.py:76-INFO-Loading dataset:
2024-11-04 14:42:03,552-main.py:274-INFO-Train data = 1, Test data = 7
2024-11-04 14:42:04,423-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-04 14:42:04,424-main.py:109-INFO-Loading model:
2024-11-04 14:42:04,425-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-04 14:42:04,431-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-04 14:42:04,901-main.py:465-INFO- ------------------------------------------------------------------
2024-11-04 14:42:04,901-main.py:466-INFO- * Speed: 58.02076 ms/iter
2024-11-04 14:42:04,901-main.py:467-INFO- * MAPE: 0.65790
2024-11-04 14:42:04,901-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-11-04 14:42:04,901-main.py:469-INFO- * Kendall's Tau: -0.23809523809523814
2024-11-04 14:42:04,901-main.py:470-INFO- ------------------------------------------------------------------
2024-11-04 14:42:04,901-main.py:473-INFO- Average Latency : 56.59675598 ms
2024-11-04 14:43:35,255-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-04 14:43:35,255-main.py:76-INFO-Loading dataset:
2024-11-04 14:43:36,141-main.py:274-INFO-Train data = 1, Test data = 8
2024-11-04 14:43:36,995-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-04 14:43:36,995-main.py:109-INFO-Loading model:
2024-11-04 14:43:36,996-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-04 14:43:37,003-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-04 14:43:37,495-main.py:465-INFO- ------------------------------------------------------------------
2024-11-04 14:43:37,495-main.py:466-INFO- * Speed: 53.47556 ms/iter
2024-11-04 14:43:37,496-main.py:467-INFO- * MAPE: 0.32897
2024-11-04 14:43:37,496-main.py:468-INFO- * ErrorBound: [0.125 0.    0.   ]
2024-11-04 14:43:37,496-main.py:469-INFO- * Kendall's Tau: 0.40006613209931935
2024-11-04 14:43:37,496-main.py:470-INFO- ------------------------------------------------------------------
2024-11-04 14:43:37,496-main.py:473-INFO- Average Latency : 51.98037624 ms
2024-11-13 14:12:02,123-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-13 14:12:02,124-main.py:76-INFO-Loading dataset:
2024-11-13 14:12:02,253-main.py:274-INFO-Train data = 1, Test data = 1
2024-11-13 14:12:03,819-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-13 14:12:03,820-main.py:109-INFO-Loading model:
2024-11-13 14:12:03,821-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-13 14:12:03,845-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-13 14:12:04,858-main.py:465-INFO- ------------------------------------------------------------------
2024-11-13 14:12:04,858-main.py:466-INFO- * Speed: 861.29308 ms/iter
2024-11-13 14:12:04,858-main.py:467-INFO- * MAPE: 0.59847
2024-11-13 14:12:04,859-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-11-13 14:12:04,859-main.py:469-INFO- * Kendall's Tau: nan
2024-11-13 14:12:04,859-main.py:470-INFO- ------------------------------------------------------------------
2024-11-13 14:12:04,859-main.py:473-INFO- Average Latency : 850.29315948 ms
2024-11-22 02:39:50,574-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-22 02:39:50,575-main.py:76-INFO-Loading dataset:
2024-11-22 02:39:52,484-main.py:274-INFO-Train data = 1, Test data = 20
2024-11-22 02:39:54,195-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-22 02:39:54,196-main.py:109-INFO-Loading model:
2024-11-22 02:39:54,197-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-22 02:39:54,221-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-22 02:39:55,339-main.py:465-INFO- ------------------------------------------------------------------
2024-11-22 02:39:55,340-main.py:466-INFO- * Speed: 47.95749 ms/iter
2024-11-22 02:39:55,340-main.py:467-INFO- * MAPE: 0.49620
2024-11-22 02:39:55,340-main.py:468-INFO- * ErrorBound: [0.2 0.  0. ]
2024-11-22 02:39:55,340-main.py:469-INFO- * Kendall's Tau: -0.052631578947368425
2024-11-22 02:39:55,340-main.py:470-INFO- ------------------------------------------------------------------
2024-11-22 02:39:55,340-main.py:473-INFO- Average Latency : 45.50654888 ms
2024-11-29 01:37:34,129-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-29 01:37:34,130-main.py:76-INFO-Loading dataset:
2024-11-29 01:37:35,956-main.py:274-INFO-Train data = 1, Test data = 20
2024-11-29 01:37:37,371-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-29 01:37:37,372-main.py:109-INFO-Loading model:
2024-11-29 01:37:37,373-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-29 01:37:37,394-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-29 01:37:38,392-main.py:465-INFO- ------------------------------------------------------------------
2024-11-29 01:37:38,392-main.py:466-INFO- * Speed: 42.89799 ms/iter
2024-11-29 01:37:38,392-main.py:467-INFO- * MAPE: 0.41173
2024-11-29 01:37:38,392-main.py:468-INFO- * ErrorBound: [0.15 0.15 0.05]
2024-11-29 01:37:38,392-main.py:469-INFO- * Kendall's Tau: 0.24210526315789474
2024-11-29 01:37:38,392-main.py:470-INFO- ------------------------------------------------------------------
2024-11-29 01:37:38,392-main.py:473-INFO- Average Latency : 40.70525169 ms
2024-11-29 01:38:57,889-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-11-29 01:38:57,890-main.py:76-INFO-Loading dataset:
2024-11-29 01:38:59,385-main.py:274-INFO-Train data = 1, Test data = 20
2024-11-29 01:39:00,304-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-11-29 01:39:00,304-main.py:109-INFO-Loading model:
2024-11-29 01:39:00,305-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-11-29 01:39:00,312-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-11-29 01:39:00,874-main.py:465-INFO- ------------------------------------------------------------------
2024-11-29 01:39:00,874-main.py:466-INFO- * Speed: 24.86718 ms/iter
2024-11-29 01:39:00,874-main.py:467-INFO- * MAPE: 0.69644
2024-11-29 01:39:00,874-main.py:468-INFO- * ErrorBound: [0.1  0.05 0.  ]
2024-11-29 01:39:00,874-main.py:469-INFO- * Kendall's Tau: -0.0736842105263158
2024-11-29 01:39:00,874-main.py:470-INFO- ------------------------------------------------------------------
2024-11-29 01:39:00,875-main.py:473-INFO- Average Latency : 23.41434956 ms
2024-12-25 13:13:04,675-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet3-4.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:13:04,676-main.py:76-INFO-Loading dataset:
2024-12-25 13:13:05,736-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:13:07,145-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:13:07,146-main.py:109-INFO-Loading model:
2024-12-25 13:13:07,147-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:13:07,171-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:13:08,300-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:13:08,300-main.py:466-INFO- * Speed: 48.68863 ms/iter
2024-12-25 13:13:08,300-main.py:467-INFO- * MAPE: 0.77494
2024-12-25 13:13:08,301-main.py:468-INFO- * ErrorBound: [0.15 0.1  0.1 ]
2024-12-25 13:13:08,301-main.py:469-INFO- * Kendall's Tau: -0.1368421052631579
2024-12-25 13:13:08,301-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:13:08,301-main.py:473-INFO- Average Latency : 46.44529819 ms
2024-12-25 13:15:30,330-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet4-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:15:30,331-main.py:76-INFO-Loading dataset:
2024-12-25 13:15:31,932-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:15:32,821-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:15:32,821-main.py:109-INFO-Loading model:
2024-12-25 13:15:32,822-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:15:32,829-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:15:33,360-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:15:33,360-main.py:466-INFO- * Speed: 23.44121 ms/iter
2024-12-25 13:15:33,360-main.py:467-INFO- * MAPE: 0.66590
2024-12-25 13:15:33,361-main.py:468-INFO- * ErrorBound: [0.15 0.1  0.  ]
2024-12-25 13:15:33,361-main.py:469-INFO- * Kendall's Tau: 0.12631578947368421
2024-12-25 13:15:33,361-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:15:33,361-main.py:473-INFO- Average Latency : 21.99598551 ms
2024-12-25 13:17:18,968-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet4-6.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:17:18,969-main.py:76-INFO-Loading dataset:
2024-12-25 13:17:20,431-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:17:21,319-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:17:21,320-main.py:109-INFO-Loading model:
2024-12-25 13:17:21,321-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:17:21,329-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:17:21,863-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:17:21,863-main.py:466-INFO- * Speed: 23.53523 ms/iter
2024-12-25 13:17:21,863-main.py:467-INFO- * MAPE: 0.74800
2024-12-25 13:17:21,863-main.py:468-INFO- * ErrorBound: [0.2 0.1 0. ]
2024-12-25 13:17:21,863-main.py:469-INFO- * Kendall's Tau: -0.30526315789473685
2024-12-25 13:17:21,863-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:17:21,863-main.py:473-INFO- Average Latency : 22.08993435 ms
2024-12-25 13:17:42,558-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squeezenet4-6.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:17:42,558-main.py:76-INFO-Loading dataset:
2024-12-25 13:17:43,879-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:17:44,765-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:17:44,766-main.py:109-INFO-Loading model:
2024-12-25 13:17:44,767-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:17:44,773-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:17:45,297-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:17:45,297-main.py:466-INFO- * Speed: 23.11283 ms/iter
2024-12-25 13:17:45,297-main.py:467-INFO- * MAPE: 0.74800
2024-12-25 13:17:45,297-main.py:468-INFO- * ErrorBound: [0.2 0.1 0. ]
2024-12-25 13:17:45,297-main.py:469-INFO- * Kendall's Tau: -0.30526315789473685
2024-12-25 13:17:45,297-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:17:45,298-main.py:473-INFO- Average Latency : 21.81714773 ms
2024-12-25 13:22:23,376-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res2-1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:22:23,376-main.py:76-INFO-Loading dataset:
2024-12-25 13:22:26,180-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:22:27,072-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:22:27,073-main.py:109-INFO-Loading model:
2024-12-25 13:22:27,073-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:22:27,080-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:22:27,645-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:22:27,645-main.py:466-INFO- * Speed: 25.01197 ms/iter
2024-12-25 13:22:27,645-main.py:467-INFO- * MAPE: 0.85289
2024-12-25 13:22:27,646-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-12-25 13:22:27,646-main.py:469-INFO- * Kendall's Tau: -0.031578947368421054
2024-12-25 13:22:27,646-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:22:27,646-main.py:473-INFO- Average Latency : 23.61667156 ms
2024-12-25 13:23:02,083-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res3-2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:23:02,084-main.py:76-INFO-Loading dataset:
2024-12-25 13:23:04,656-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:23:05,560-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:23:05,561-main.py:109-INFO-Loading model:
2024-12-25 13:23:05,562-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:23:05,568-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:23:06,106-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:23:06,106-main.py:466-INFO- * Speed: 23.74382 ms/iter
2024-12-25 13:23:06,106-main.py:467-INFO- * MAPE: 0.81190
2024-12-25 13:23:06,107-main.py:468-INFO- * ErrorBound: [0.05 0.   0.  ]
2024-12-25 13:23:06,107-main.py:469-INFO- * Kendall's Tau: 0.09473684210526316
2024-12-25 13:23:06,107-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:23:06,107-main.py:473-INFO- Average Latency : 22.34847546 ms
2024-12-25 13:23:40,900-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res3-4.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:23:40,900-main.py:76-INFO-Loading dataset:
2024-12-25 13:23:43,232-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:23:44,089-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:23:44,090-main.py:109-INFO-Loading model:
2024-12-25 13:23:44,090-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:23:44,098-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:23:44,620-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:23:44,620-main.py:466-INFO- * Speed: 23.00705 ms/iter
2024-12-25 13:23:44,620-main.py:467-INFO- * MAPE: 0.87727
2024-12-25 13:23:44,620-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-12-25 13:23:44,620-main.py:469-INFO- * Kendall's Tau: 0.16842105263157894
2024-12-25 13:23:44,621-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:23:44,621-main.py:473-INFO- Average Latency : 21.61164284 ms
2024-12-25 13:24:07,199-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res4-3.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:24:07,199-main.py:76-INFO-Loading dataset:
2024-12-25 13:24:09,505-main.py:274-INFO-Train data = 1, Test data = 19
2024-12-25 13:24:10,413-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:24:10,414-main.py:109-INFO-Loading model:
2024-12-25 13:24:10,414-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:24:10,420-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:24:10,940-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:24:10,940-main.py:466-INFO- * Speed: 24.07937 ms/iter
2024-12-25 13:24:10,940-main.py:467-INFO- * MAPE: 0.74754
2024-12-25 13:24:10,941-main.py:468-INFO- * ErrorBound: [0.10526316 0.05263158 0.        ]
2024-12-25 13:24:10,941-main.py:469-INFO- * Kendall's Tau: -0.029239766081871343
2024-12-25 13:24:10,941-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:24:10,941-main.py:473-INFO- Average Latency : 22.61063927 ms
2024-12-25 13:24:33,802-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res4-6.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:24:33,803-main.py:76-INFO-Loading dataset:
2024-12-25 13:24:37,516-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:24:38,436-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:24:38,436-main.py:109-INFO-Loading model:
2024-12-25 13:24:38,437-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:24:38,443-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:24:38,999-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:24:38,999-main.py:466-INFO- * Speed: 24.68446 ms/iter
2024-12-25 13:24:38,999-main.py:467-INFO- * MAPE: 0.63991
2024-12-25 13:24:38,999-main.py:468-INFO- * ErrorBound: [0.15 0.05 0.  ]
2024-12-25 13:24:38,999-main.py:469-INFO- * Kendall's Tau: 0.11578947368421053
2024-12-25 13:24:39,000-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:24:39,000-main.py:473-INFO- Average Latency : 23.28912020 ms
2024-12-25 13:27:39,744-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res5-4.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:27:39,744-main.py:76-INFO-Loading dataset:
2024-12-25 13:27:42,546-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:27:43,417-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:27:43,418-main.py:109-INFO-Loading model:
2024-12-25 13:27:43,419-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:27:43,426-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:27:43,978-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:27:43,978-main.py:466-INFO- * Speed: 24.45958 ms/iter
2024-12-25 13:27:43,979-main.py:467-INFO- * MAPE: 1.36242
2024-12-25 13:27:43,979-main.py:468-INFO- * ErrorBound: [0.05 0.05 0.05]
2024-12-25 13:27:43,979-main.py:469-INFO- * Kendall's Tau: 0.37894736842105264
2024-12-25 13:27:43,979-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:27:43,979-main.py:473-INFO- Average Latency : 22.91438580 ms
2024-12-25 13:28:07,744-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res5-8.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2024-12-25 13:28:07,744-main.py:76-INFO-Loading dataset:
2024-12-25 13:28:10,497-main.py:274-INFO-Train data = 1, Test data = 20
2024-12-25 13:28:11,367-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2024-12-25 13:28:11,367-main.py:109-INFO-Loading model:
2024-12-25 13:28:11,368-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:28:11,374-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2024-12-25 13:28:11,929-main.py:465-INFO- ------------------------------------------------------------------
2024-12-25 13:28:11,929-main.py:466-INFO- * Speed: 24.50261 ms/iter
2024-12-25 13:28:11,929-main.py:467-INFO- * MAPE: 1.03180
2024-12-25 13:28:11,930-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2024-12-25 13:28:11,930-main.py:469-INFO- * Kendall's Tau: 0.2105263157894737
2024-12-25 13:28:11,930-main.py:470-INFO- ------------------------------------------------------------------
2024-12-25 13:28:11,930-main.py:473-INFO- Average Latency : 23.10723066 ms
2025-01-03 00:01:12,376-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squ20.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-03 00:01:12,376-main.py:76-INFO-Loading dataset:
2025-01-03 00:01:14,181-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-03 00:01:15,616-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-03 00:01:15,616-main.py:109-INFO-Loading model:
2025-01-03 00:01:15,617-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-03 00:01:15,637-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-03 00:01:16,513-main.py:465-INFO- ------------------------------------------------------------------
2025-01-03 00:01:16,513-main.py:466-INFO- * Speed: 40.62443 ms/iter
2025-01-03 00:01:16,513-main.py:467-INFO- * MAPE: 0.49779
2025-01-03 00:01:16,514-main.py:468-INFO- * ErrorBound: [0.3  0.15 0.  ]
2025-01-03 00:01:16,514-main.py:469-INFO- * Kendall's Tau: -0.021052631578947368
2025-01-03 00:01:16,515-main.py:470-INFO- ------------------------------------------------------------------
2025-01-03 00:01:16,515-main.py:473-INFO- Average Latency : 38.77395391 ms
2025-01-03 00:02:15,916-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/res20.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-03 00:02:15,916-main.py:76-INFO-Loading dataset:
2025-01-03 00:02:20,300-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-03 00:02:21,436-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-03 00:02:21,436-main.py:109-INFO-Loading model:
2025-01-03 00:02:21,437-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-03 00:02:21,444-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-03 00:02:22,014-main.py:465-INFO- ------------------------------------------------------------------
2025-01-03 00:02:22,015-main.py:466-INFO- * Speed: 25.49081 ms/iter
2025-01-03 00:02:22,015-main.py:467-INFO- * MAPE: 0.81710
2025-01-03 00:02:22,015-main.py:468-INFO- * ErrorBound: [0.1  0.05 0.  ]
2025-01-03 00:02:22,015-main.py:469-INFO- * Kendall's Tau: -0.16842105263157894
2025-01-03 00:02:22,015-main.py:470-INFO- ------------------------------------------------------------------
2025-01-03 00:02:22,015-main.py:473-INFO- Average Latency : 24.09516573 ms
2025-01-03 00:36:35,936-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squ20.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-03 00:36:35,936-main.py:76-INFO-Loading dataset:
2025-01-03 00:36:37,593-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-03 00:36:38,523-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-03 00:36:38,523-main.py:109-INFO-Loading model:
2025-01-03 00:36:38,524-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-03 00:36:38,531-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-03 00:36:39,088-main.py:465-INFO- ------------------------------------------------------------------
2025-01-03 00:36:39,088-main.py:466-INFO- * Speed: 24.74999 ms/iter
2025-01-03 00:36:39,088-main.py:467-INFO- * MAPE: 0.50350
2025-01-03 00:36:39,088-main.py:468-INFO- * ErrorBound: [0.25 0.15 0.  ]
2025-01-03 00:36:39,088-main.py:469-INFO- * Kendall's Tau: -0.010526315789473684
2025-01-03 00:36:39,089-main.py:470-INFO- ------------------------------------------------------------------
2025-01-03 00:36:39,089-main.py:473-INFO- Average Latency : 23.24979305 ms
2025-01-03 01:25:02,288-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/squ20.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset5/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-03 01:25:02,288-main.py:76-INFO-Loading dataset:
2025-01-03 01:25:04,000-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-03 01:25:04,956-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-03 01:25:04,956-main.py:109-INFO-Loading model:
2025-01-03 01:25:04,957-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-03 01:25:04,964-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-03 01:25:05,534-main.py:465-INFO- ------------------------------------------------------------------
2025-01-03 01:25:05,534-main.py:466-INFO- * Speed: 25.32145 ms/iter
2025-01-03 01:25:05,534-main.py:467-INFO- * MAPE: 0.50350
2025-01-03 01:25:05,534-main.py:468-INFO- * ErrorBound: [0.25 0.15 0.  ]
2025-01-03 01:25:05,534-main.py:469-INFO- * Kendall's Tau: -0.010526315789473684
2025-01-03 01:25:05,534-main.py:470-INFO- ------------------------------------------------------------------
2025-01-03 01:25:05,535-main.py:473-INFO- Average Latency : 23.94893169 ms
2025-01-04 20:28:55,552-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/alexnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:28:55,553-main.py:76-INFO-Loading dataset:
2025-01-04 20:29:09,206-main.py:274-INFO-Train data = 1, Test data = 19
2025-01-04 20:29:10,690-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:29:10,691-main.py:109-INFO-Loading model:
2025-01-04 20:29:10,692-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:29:10,713-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:29:11,803-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:29:11,803-main.py:466-INFO- * Speed: 49.68361 ms/iter
2025-01-04 20:29:11,803-main.py:467-INFO- * MAPE: 1.15815
2025-01-04 20:29:11,804-main.py:468-INFO- * ErrorBound: [0.10526316 0.05263158 0.05263158]
2025-01-04 20:29:11,804-main.py:469-INFO- * Kendall's Tau: -0.08771929824561403
2025-01-04 20:29:11,804-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:29:11,805-main.py:473-INFO- Average Latency : 47.47275302 ms
2025-01-04 20:30:31,135-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/googlenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:30:31,135-main.py:76-INFO-Loading dataset:
2025-01-04 20:30:39,452-main.py:274-INFO-Train data = 1, Test data = 25
2025-01-04 20:30:40,653-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:30:40,654-main.py:109-INFO-Loading model:
2025-01-04 20:30:40,655-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:30:40,662-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:30:41,325-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:30:41,325-main.py:466-INFO- * Speed: 24.08478 ms/iter
2025-01-04 20:30:41,325-main.py:467-INFO- * MAPE: 0.47956
2025-01-04 20:30:41,326-main.py:468-INFO- * ErrorBound: [0.12 0.08 0.04]
2025-01-04 20:30:41,326-main.py:469-INFO- * Kendall's Tau: -0.05999999999999999
2025-01-04 20:30:41,326-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:30:41,326-main.py:473-INFO- Average Latency : 22.52763748 ms
2025-01-04 20:31:10,141-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/mnasnet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:31:10,142-main.py:76-INFO-Loading dataset:
2025-01-04 20:31:46,612-main.py:274-INFO-Train data = 1, Test data = 19
2025-01-04 20:31:47,512-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:31:47,512-main.py:109-INFO-Loading model:
2025-01-04 20:31:47,513-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:31:47,520-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:31:48,056-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:31:48,056-main.py:466-INFO- * Speed: 24.94937 ms/iter
2025-01-04 20:31:48,056-main.py:467-INFO- * MAPE: 0.43409
2025-01-04 20:31:48,057-main.py:468-INFO- * ErrorBound: [0.26315789 0.26315789 0.05263158]
2025-01-04 20:31:48,057-main.py:469-INFO- * Kendall's Tau: -0.21637426900584794
2025-01-04 20:31:48,057-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:31:48,057-main.py:473-INFO- Average Latency : 23.38115793 ms
2025-01-04 20:32:20,694-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/mobilenetv2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:32:20,694-main.py:76-INFO-Loading dataset:
2025-01-04 20:32:52,123-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-04 20:32:53,022-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:32:53,023-main.py:109-INFO-Loading model:
2025-01-04 20:32:53,024-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:32:53,031-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:32:53,574-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:32:53,574-main.py:466-INFO- * Speed: 24.07640 ms/iter
2025-01-04 20:32:53,574-main.py:467-INFO- * MAPE: 0.30555
2025-01-04 20:32:53,574-main.py:468-INFO- * ErrorBound: [0.2  0.2  0.05]
2025-01-04 20:32:53,575-main.py:469-INFO- * Kendall's Tau: 0.11578947368421053
2025-01-04 20:32:53,575-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:32:53,575-main.py:473-INFO- Average Latency : 22.55107164 ms
2025-01-04 20:33:15,358-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:33:15,358-main.py:76-INFO-Loading dataset:
2025-01-04 20:33:18,024-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-04 20:33:18,956-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:33:18,957-main.py:109-INFO-Loading model:
2025-01-04 20:33:18,958-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:33:18,965-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:33:19,513-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:33:19,513-main.py:466-INFO- * Speed: 24.31580 ms/iter
2025-01-04 20:33:19,513-main.py:467-INFO- * MAPE: 0.72685
2025-01-04 20:33:19,513-main.py:468-INFO- * ErrorBound: [0.05 0.05 0.  ]
2025-01-04 20:33:19,513-main.py:469-INFO- * Kendall's Tau: 0.17894736842105263
2025-01-04 20:33:19,513-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:33:19,513-main.py:473-INFO- Average Latency : 22.86531925 ms
2025-01-04 20:33:36,562-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/resnet18.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:33:36,562-main.py:76-INFO-Loading dataset:
2025-01-04 20:33:38,971-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-04 20:33:39,863-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:33:39,863-main.py:109-INFO-Loading model:
2025-01-04 20:33:39,864-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:33:39,872-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:33:40,437-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:33:40,437-main.py:466-INFO- * Speed: 25.11967 ms/iter
2025-01-04 20:33:40,437-main.py:467-INFO- * MAPE: 0.72685
2025-01-04 20:33:40,437-main.py:468-INFO- * ErrorBound: [0.05 0.05 0.  ]
2025-01-04 20:33:40,438-main.py:469-INFO- * Kendall's Tau: 0.17894736842105263
2025-01-04 20:33:40,438-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:33:40,438-main.py:473-INFO- Average Latency : 23.56556654 ms
2025-01-04 20:33:58,767-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/squeezenet.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:33:58,767-main.py:76-INFO-Loading dataset:
2025-01-04 20:34:00,166-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-04 20:34:01,092-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:34:01,092-main.py:109-INFO-Loading model:
2025-01-04 20:34:01,093-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:34:01,100-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:34:01,678-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:34:01,678-main.py:466-INFO- * Speed: 25.84709 ms/iter
2025-01-04 20:34:01,679-main.py:467-INFO- * MAPE: 0.65448
2025-01-04 20:34:01,679-main.py:468-INFO- * ErrorBound: [0.1  0.05 0.05]
2025-01-04 20:34:01,679-main.py:469-INFO- * Kendall's Tau: 0.021052631578947368
2025-01-04 20:34:01,679-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:34:01,679-main.py:473-INFO- Average Latency : 24.34706688 ms
2025-01-04 20:34:24,624-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/vgg16.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-04 20:34:24,624-main.py:76-INFO-Loading dataset:
2025-01-04 20:34:55,603-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-04 20:34:56,504-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-04 20:34:56,505-main.py:109-INFO-Loading model:
2025-01-04 20:34:56,506-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:34:56,513-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-04 20:34:57,057-main.py:465-INFO- ------------------------------------------------------------------
2025-01-04 20:34:57,057-main.py:466-INFO- * Speed: 24.07318 ms/iter
2025-01-04 20:34:57,057-main.py:467-INFO- * MAPE: 0.26697
2025-01-04 20:34:57,057-main.py:468-INFO- * ErrorBound: [0.2 0.  0. ]
2025-01-04 20:34:57,057-main.py:469-INFO- * Kendall's Tau: 0.25263157894736843
2025-01-04 20:34:57,058-main.py:470-INFO- ------------------------------------------------------------------
2025-01-04 20:34:57,058-main.py:473-INFO- Average Latency : 22.68171310 ms
2025-01-06 13:14:18,478-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/alexnet2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-06 13:14:18,478-main.py:76-INFO-Loading dataset:
2025-01-06 13:14:18,488-main.py:274-INFO-Train data = 1, Test data = 7
2025-01-06 13:14:20,087-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-06 13:14:20,088-main.py:109-INFO-Loading model:
2025-01-06 13:14:20,088-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-06 13:14:20,111-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-06 13:14:21,181-main.py:465-INFO- ------------------------------------------------------------------
2025-01-06 13:14:21,181-main.py:466-INFO- * Speed: 131.29636 ms/iter
2025-01-06 13:14:21,181-main.py:467-INFO- * MAPE: 0.19272
2025-01-06 13:14:21,182-main.py:468-INFO- * ErrorBound: [0.28571429 0.         0.        ]
2025-01-06 13:14:21,182-main.py:469-INFO- * Kendall's Tau: -0.33333333333333337
2025-01-06 13:14:21,182-main.py:470-INFO- ------------------------------------------------------------------
2025-01-06 13:14:21,182-main.py:473-INFO- Average Latency : 125.43923514 ms
2025-01-06 13:15:51,218-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/resnet2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-06 13:15:51,218-main.py:76-INFO-Loading dataset:
2025-01-06 13:15:51,984-main.py:274-INFO-Train data = 1, Test data = 9
2025-01-06 13:15:52,871-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-06 13:15:52,871-main.py:109-INFO-Loading model:
2025-01-06 13:15:52,872-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-06 13:15:52,879-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-06 13:15:53,389-main.py:465-INFO- ------------------------------------------------------------------
2025-01-06 13:15:53,389-main.py:466-INFO- * Speed: 49.51326 ms/iter
2025-01-06 13:15:53,389-main.py:467-INFO- * MAPE: 1.24094
2025-01-06 13:15:53,389-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-01-06 13:15:53,390-main.py:469-INFO- * Kendall's Tau: 0.3333333333333333
2025-01-06 13:15:53,390-main.py:470-INFO- ------------------------------------------------------------------
2025-01-06 13:15:53,390-main.py:473-INFO- Average Latency : 47.95763228 ms
2025-01-14 13:05:12,460-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/alexnet2.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-14 13:05:12,460-main.py:76-INFO-Loading dataset:
2025-01-14 13:05:19,626-main.py:274-INFO-Train data = 1, Test data = 7
2025-01-14 13:05:21,625-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-14 13:05:21,626-main.py:109-INFO-Loading model:
2025-01-14 13:05:21,627-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-14 13:05:21,648-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-14 13:05:22,905-main.py:465-INFO- ------------------------------------------------------------------
2025-01-14 13:05:22,905-main.py:466-INFO- * Speed: 156.99325 ms/iter
2025-01-14 13:05:22,905-main.py:467-INFO- * MAPE: 0.98024
2025-01-14 13:05:22,974-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-01-14 13:05:22,974-main.py:469-INFO- * Kendall's Tau: -0.5238095238095238
2025-01-14 13:05:22,976-main.py:470-INFO- ------------------------------------------------------------------
2025-01-14 13:05:22,976-main.py:473-INFO- Average Latency : 153.13601494 ms
2025-01-15 15:44:29,373-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/ale-500.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-15 15:44:29,373-main.py:76-INFO-Loading dataset:
2025-01-15 15:44:47,007-main.py:274-INFO-Train data = 1, Test data = 26
2025-01-15 15:44:48,475-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-15 15:44:48,476-main.py:109-INFO-Loading model:
2025-01-15 15:44:48,477-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-15 15:44:48,499-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-15 15:44:49,676-main.py:465-INFO- ------------------------------------------------------------------
2025-01-15 15:44:49,676-main.py:466-INFO- * Speed: 39.67608 ms/iter
2025-01-15 15:44:49,676-main.py:467-INFO- * MAPE: 0.69423
2025-01-15 15:44:49,677-main.py:468-INFO- * ErrorBound: [0.07692308 0.03846154 0.        ]
2025-01-15 15:44:49,677-main.py:469-INFO- * Kendall's Tau: 0.1753846153846154
2025-01-15 15:44:49,677-main.py:470-INFO- ------------------------------------------------------------------
2025-01-15 15:44:49,678-main.py:473-INFO- Average Latency : 37.71460973 ms
2025-01-15 15:45:34,774-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/vgg16-1000.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-01-15 15:45:34,774-main.py:76-INFO-Loading dataset:
2025-01-15 15:46:15,829-main.py:274-INFO-Train data = 1, Test data = 20
2025-01-15 15:46:16,718-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-01-15 15:46:16,718-main.py:109-INFO-Loading model:
2025-01-15 15:46:16,719-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-01-15 15:46:16,726-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-01-15 15:46:17,275-main.py:465-INFO- ------------------------------------------------------------------
2025-01-15 15:46:17,276-main.py:466-INFO- * Speed: 24.30787 ms/iter
2025-01-15 15:46:17,276-main.py:467-INFO- * MAPE: 0.24746
2025-01-15 15:46:17,276-main.py:468-INFO- * ErrorBound: [0.2 0.  0. ]
2025-01-15 15:46:17,276-main.py:469-INFO- * Kendall's Tau: 0.4105263157894737
2025-01-15 15:46:17,276-main.py:470-INFO- ------------------------------------------------------------------
2025-01-15 15:46:17,276-main.py:473-INFO- Average Latency : 22.75789976 ms
2025-02-25 13:07:14,718-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/vgg16-1000.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 13:07:14,718-main.py:76-INFO-Loading dataset:
2025-02-25 13:07:50,516-main.py:274-INFO-Train data = 1, Test data = 20
2025-02-25 13:07:51,911-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 13:07:51,912-main.py:109-INFO-Loading model:
2025-02-25 13:07:51,913-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 13:07:51,932-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 13:07:52,885-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 13:07:52,886-main.py:466-INFO- * Speed: 40.78261 ms/iter
2025-02-25 13:07:52,886-main.py:467-INFO- * MAPE: 0.24746
2025-02-25 13:07:52,886-main.py:468-INFO- * ErrorBound: [0.2 0.  0. ]
2025-02-25 13:07:52,886-main.py:469-INFO- * Kendall's Tau: 0.4105263157894737
2025-02-25 13:07:52,886-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 13:07:52,887-main.py:473-INFO- Average Latency : 38.93308640 ms
2025-02-25 13:08:33,722-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/pru.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 13:08:33,722-main.py:76-INFO-Loading dataset:
2025-02-25 13:17:26,330-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/pru.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 13:17:26,330-main.py:76-INFO-Loading dataset:
2025-02-25 13:19:09,353-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/pru.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 13:19:09,353-main.py:76-INFO-Loading dataset:
2025-02-25 13:19:15,269-main.py:274-INFO-Train data = 1, Test data = 5
2025-02-25 13:19:16,333-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 13:19:16,334-main.py:109-INFO-Loading model:
2025-02-25 13:19:16,334-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 13:19:16,340-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 13:19:16,915-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 13:19:16,915-main.py:466-INFO- * Speed: 102.62613 ms/iter
2025-02-25 13:19:16,916-main.py:467-INFO- * MAPE: 0.61548
2025-02-25 13:19:16,916-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 13:19:16,916-main.py:469-INFO- * Kendall's Tau: 0.39999999999999997
2025-02-25 13:19:16,916-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 13:19:16,916-main.py:473-INFO- Average Latency : 101.02629662 ms
2025-02-25 14:03:57,550-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:03:57,550-main.py:76-INFO-Loading dataset:
2025-02-25 14:03:57,555-main.py:274-INFO-Train data = 0, Test data = 0
2025-02-25 14:05:13,501-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:05:13,501-main.py:76-INFO-Loading dataset:
2025-02-25 14:05:22,900-main.py:274-INFO-Train data = 1, Test data = 8
2025-02-25 14:05:23,840-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 14:05:23,841-main.py:109-INFO-Loading model:
2025-02-25 14:05:23,842-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:05:23,848-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:05:24,322-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 14:05:24,322-main.py:466-INFO- * Speed: 51.41687 ms/iter
2025-02-25 14:05:24,322-main.py:467-INFO- * MAPE: 0.91291
2025-02-25 14:05:24,323-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 14:05:24,323-main.py:469-INFO- * Kendall's Tau: -0.9999999999999998
2025-02-25 14:05:24,323-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 14:05:24,323-main.py:473-INFO- Average Latency : 49.91650581 ms
2025-02-25 14:10:40,057-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:10:40,057-main.py:76-INFO-Loading dataset:
2025-02-25 14:10:41,566-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 14:10:42,442-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 14:10:42,443-main.py:109-INFO-Loading model:
2025-02-25 14:10:42,444-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:10:42,450-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:10:42,928-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 14:10:42,928-main.py:466-INFO- * Speed: 46.28905 ms/iter
2025-02-25 14:10:42,928-main.py:467-INFO- * MAPE: 0.80266
2025-02-25 14:10:42,929-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 14:10:42,929-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-02-25 14:10:42,929-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 14:10:42,929-main.py:473-INFO- Average Latency : 44.84454791 ms
2025-02-25 14:14:09,820-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:14:09,820-main.py:76-INFO-Loading dataset:
2025-02-25 14:14:11,914-main.py:274-INFO-Train data = 1, Test data = 10
2025-02-25 14:14:12,780-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 14:14:12,781-main.py:109-INFO-Loading model:
2025-02-25 14:14:12,782-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:14:12,788-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:14:13,267-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 14:14:13,267-main.py:466-INFO- * Speed: 41.67228 ms/iter
2025-02-25 14:14:13,267-main.py:467-INFO- * MAPE: 0.84722
2025-02-25 14:14:13,267-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 14:14:13,267-main.py:469-INFO- * Kendall's Tau: -0.6888888888888888
2025-02-25 14:14:13,267-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 14:14:13,267-main.py:473-INFO- Average Latency : 40.07194042 ms
2025-02-25 14:31:55,374-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:31:55,374-main.py:76-INFO-Loading dataset:
2025-02-25 14:31:55,385-main.py:274-INFO-Train data = 0, Test data = 0
2025-02-25 14:33:37,944-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:33:37,944-main.py:76-INFO-Loading dataset:
2025-02-25 14:33:40,747-main.py:274-INFO-Train data = 1, Test data = 10
2025-02-25 14:33:41,632-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 14:33:41,632-main.py:109-INFO-Loading model:
2025-02-25 14:33:41,633-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:33:41,640-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:33:42,144-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 14:33:42,144-main.py:466-INFO- * Speed: 44.21270 ms/iter
2025-02-25 14:33:42,144-main.py:467-INFO- * MAPE: 0.86218
2025-02-25 14:33:42,144-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 14:33:42,145-main.py:469-INFO- * Kendall's Tau: 0.1111111111111111
2025-02-25 14:33:42,145-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 14:33:42,145-main.py:473-INFO- Average Latency : 42.61269569 ms
2025-02-25 14:41:51,019-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:41:51,020-main.py:76-INFO-Loading dataset:
2025-02-25 14:41:52,106-main.py:274-INFO-Train data = 1, Test data = 6
2025-02-25 14:41:52,997-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 14:41:52,998-main.py:109-INFO-Loading model:
2025-02-25 14:41:52,999-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:41:53,005-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:41:53,472-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 14:41:53,472-main.py:466-INFO- * Speed: 67.61309 ms/iter
2025-02-25 14:41:53,473-main.py:467-INFO- * MAPE: 0.86375
2025-02-25 14:41:53,473-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 14:41:53,473-main.py:469-INFO- * Kendall's Tau: 0.3333333333333333
2025-02-25 14:41:53,474-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 14:41:53,474-main.py:473-INFO- Average Latency : 66.27984842 ms
2025-02-25 14:49:00,936-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 14:49:00,936-main.py:76-INFO-Loading dataset:
2025-02-25 14:49:10,667-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 14:49:11,654-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 14:49:11,655-main.py:109-INFO-Loading model:
2025-02-25 14:49:11,656-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:49:11,663-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 14:49:12,180-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 14:49:12,181-main.py:466-INFO- * Speed: 50.51374 ms/iter
2025-02-25 14:49:12,181-main.py:467-INFO- * MAPE: 0.92377
2025-02-25 14:49:12,181-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 14:49:12,181-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-25 14:49:12,181-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 14:49:12,181-main.py:473-INFO- Average Latency : 49.29108090 ms
2025-02-25 15:02:05,222-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:02:05,222-main.py:76-INFO-Loading dataset:
2025-02-25 15:02:06,942-main.py:274-INFO-Train data = 1, Test data = 6
2025-02-25 15:02:07,851-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:02:07,852-main.py:109-INFO-Loading model:
2025-02-25 15:02:07,853-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:02:07,859-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:02:08,341-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:02:08,341-main.py:466-INFO- * Speed: 69.76553 ms/iter
2025-02-25 15:02:08,342-main.py:467-INFO- * MAPE: 0.86714
2025-02-25 15:02:08,342-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:02:08,342-main.py:469-INFO- * Kendall's Tau: -0.3333333333333333
2025-02-25 15:02:08,342-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:02:08,342-main.py:473-INFO- Average Latency : 68.59866778 ms
2025-02-25 15:08:09,863-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:08:09,863-main.py:76-INFO-Loading dataset:
2025-02-25 15:08:11,146-main.py:274-INFO-Train data = 1, Test data = 5
2025-02-25 15:08:12,086-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:08:12,086-main.py:109-INFO-Loading model:
2025-02-25 15:08:12,087-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:08:12,094-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:08:12,562-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:08:12,562-main.py:466-INFO- * Speed: 81.23755 ms/iter
2025-02-25 15:08:12,562-main.py:467-INFO- * MAPE: 0.86046
2025-02-25 15:08:12,562-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:08:12,562-main.py:469-INFO- * Kendall's Tau: -0.6
2025-02-25 15:08:12,562-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:08:12,562-main.py:473-INFO- Average Latency : 79.83746529 ms
2025-02-25 15:22:16,790-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:22:16,790-main.py:76-INFO-Loading dataset:
2025-02-25 15:22:33,543-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 15:22:34,430-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:22:34,430-main.py:109-INFO-Loading model:
2025-02-25 15:22:34,431-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:22:34,450-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:22:35,251-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:22:35,251-main.py:466-INFO- * Speed: 81.87021 ms/iter
2025-02-25 15:22:35,251-main.py:467-INFO- * MAPE: 0.95365
2025-02-25 15:22:35,251-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:22:35,251-main.py:469-INFO- * Kendall's Tau: -0.8888888888888888
2025-02-25 15:22:35,251-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:22:35,251-main.py:473-INFO- Average Latency : 80.64799839 ms
2025-02-25 15:25:53,458-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:25:53,458-main.py:76-INFO-Loading dataset:
2025-02-25 15:25:55,657-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 15:25:56,559-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:25:56,560-main.py:109-INFO-Loading model:
2025-02-25 15:25:56,561-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:25:56,567-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:25:57,060-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:25:57,060-main.py:466-INFO- * Speed: 47.97075 ms/iter
2025-02-25 15:25:57,060-main.py:467-INFO- * MAPE: 0.88338
2025-02-25 15:25:57,060-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:25:57,061-main.py:469-INFO- * Kendall's Tau: 0.4444444444444444
2025-02-25 15:25:57,061-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:25:57,061-main.py:473-INFO- Average Latency : 46.41519652 ms
2025-02-25 15:32:03,026-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:32:03,026-main.py:76-INFO-Loading dataset:
2025-02-25 15:32:03,308-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 15:32:04,206-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:32:04,207-main.py:109-INFO-Loading model:
2025-02-25 15:32:04,207-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:32:04,214-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:32:04,688-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:32:04,688-main.py:466-INFO- * Speed: 45.84103 ms/iter
2025-02-25 15:32:04,688-main.py:467-INFO- * MAPE: 0.86542
2025-02-25 15:32:04,689-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:32:04,689-main.py:469-INFO- * Kendall's Tau: 0.5
2025-02-25 15:32:04,689-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:32:04,689-main.py:473-INFO- Average Latency : 44.28513845 ms
2025-02-25 15:34:53,992-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:34:53,992-main.py:76-INFO-Loading dataset:
2025-02-25 15:35:03,545-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 15:35:04,469-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:35:04,470-main.py:109-INFO-Loading model:
2025-02-25 15:35:04,471-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:35:04,478-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:35:04,997-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:35:04,997-main.py:466-INFO- * Speed: 50.55560 ms/iter
2025-02-25 15:35:04,997-main.py:467-INFO- * MAPE: 0.90635
2025-02-25 15:35:04,997-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:35:04,998-main.py:469-INFO- * Kendall's Tau: -0.7777777777777778
2025-02-25 15:35:04,998-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:35:04,998-main.py:473-INFO- Average Latency : 49.11118084 ms
2025-02-25 15:39:20,237-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:39:20,237-main.py:76-INFO-Loading dataset:
2025-02-25 15:39:20,952-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 15:39:21,818-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:39:21,819-main.py:109-INFO-Loading model:
2025-02-25 15:39:21,820-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:39:21,826-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:39:22,313-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:39:22,313-main.py:466-INFO- * Speed: 46.26075 ms/iter
2025-02-25 15:39:22,313-main.py:467-INFO- * MAPE: 0.71866
2025-02-25 15:39:22,313-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:39:22,313-main.py:469-INFO- * Kendall's Tau: 0.16666666666666666
2025-02-25 15:39:22,314-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:39:22,314-main.py:473-INFO- Average Latency : 44.81625557 ms
2025-02-25 15:42:23,368-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 15:42:23,369-main.py:76-INFO-Loading dataset:
2025-02-25 15:42:25,126-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 15:42:26,013-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 15:42:26,014-main.py:109-INFO-Loading model:
2025-02-25 15:42:26,015-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:42:26,021-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 15:42:26,492-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 15:42:26,492-main.py:466-INFO- * Speed: 45.54163 ms/iter
2025-02-25 15:42:26,492-main.py:467-INFO- * MAPE: 0.83309
2025-02-25 15:42:26,493-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 15:42:26,493-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-25 15:42:26,493-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 15:42:26,493-main.py:473-INFO- Average Latency : 43.87513796 ms
2025-02-25 16:02:35,250-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:02:35,250-main.py:76-INFO-Loading dataset:
2025-02-25 16:02:43,937-main.py:274-INFO-Train data = 1, Test data = 12
2025-02-25 16:02:44,822-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:02:44,823-main.py:109-INFO-Loading model:
2025-02-25 16:02:44,824-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:02:44,830-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:02:45,336-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:02:45,336-main.py:466-INFO- * Speed: 36.39573 ms/iter
2025-02-25 16:02:45,336-main.py:467-INFO- * MAPE: 0.68691
2025-02-25 16:02:45,337-main.py:468-INFO- * ErrorBound: [0.25 0.25 0.25]
2025-02-25 16:02:45,337-main.py:469-INFO- * Kendall's Tau: -0.8787878787878787
2025-02-25 16:02:45,337-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:02:45,337-main.py:473-INFO- Average Latency : 35.06179651 ms
2025-02-25 16:19:25,132-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:19:25,132-main.py:76-INFO-Loading dataset:
2025-02-25 16:19:36,875-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 16:19:37,764-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:19:37,765-main.py:109-INFO-Loading model:
2025-02-25 16:19:37,765-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:19:37,772-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:19:38,281-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:19:38,281-main.py:466-INFO- * Speed: 48.94188 ms/iter
2025-02-25 16:19:38,281-main.py:467-INFO- * MAPE: 0.92797
2025-02-25 16:19:38,282-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 16:19:38,282-main.py:469-INFO- * Kendall's Tau: -0.7222222222222222
2025-02-25 16:19:38,282-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:19:38,282-main.py:473-INFO- Average Latency : 47.38635487 ms
2025-02-25 16:26:54,322-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:26:54,322-main.py:76-INFO-Loading dataset:
2025-02-25 16:27:06,034-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 16:27:06,914-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:27:06,914-main.py:109-INFO-Loading model:
2025-02-25 16:27:06,915-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:27:06,921-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:27:07,423-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:27:07,423-main.py:466-INFO- * Speed: 48.86320 ms/iter
2025-02-25 16:27:07,423-main.py:467-INFO- * MAPE: 0.92795
2025-02-25 16:27:07,423-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 16:27:07,424-main.py:469-INFO- * Kendall's Tau: -0.7222222222222222
2025-02-25 16:27:07,424-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:27:07,424-main.py:473-INFO- Average Latency : 47.30762376 ms
2025-02-25 16:29:37,536-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:29:37,536-main.py:76-INFO-Loading dataset:
2025-02-25 16:29:37,542-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 16:29:38,438-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:29:38,439-main.py:109-INFO-Loading model:
2025-02-25 16:29:38,440-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:29:38,447-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:29:38,939-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:29:38,939-main.py:466-INFO- * Speed: 47.62398 ms/iter
2025-02-25 16:29:38,939-main.py:467-INFO- * MAPE: 0.92795
2025-02-25 16:29:38,939-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 16:29:38,939-main.py:469-INFO- * Kendall's Tau: -0.7222222222222222
2025-02-25 16:29:38,939-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:29:38,939-main.py:473-INFO- Average Latency : 46.17998335 ms
2025-02-25 16:30:03,904-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:30:03,904-main.py:76-INFO-Loading dataset:
2025-02-25 16:30:13,290-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 16:30:14,271-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:30:14,272-main.py:109-INFO-Loading model:
2025-02-25 16:30:14,272-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:30:14,278-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:30:14,794-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:30:14,794-main.py:466-INFO- * Speed: 49.63099 ms/iter
2025-02-25 16:30:14,794-main.py:467-INFO- * MAPE: 0.90635
2025-02-25 16:30:14,794-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 16:30:14,794-main.py:469-INFO- * Kendall's Tau: -0.7777777777777778
2025-02-25 16:30:14,794-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:30:14,795-main.py:473-INFO- Average Latency : 48.18648762 ms
2025-02-25 16:34:46,083-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:34:46,083-main.py:76-INFO-Loading dataset:
2025-02-25 16:34:47,820-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 16:34:48,694-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:34:48,695-main.py:109-INFO-Loading model:
2025-02-25 16:34:48,696-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:34:48,702-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:34:49,186-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:34:49,186-main.py:466-INFO- * Speed: 46.90798 ms/iter
2025-02-25 16:34:49,186-main.py:467-INFO- * MAPE: 0.83309
2025-02-25 16:34:49,186-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 16:34:49,187-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-25 16:34:49,187-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:34:49,187-main.py:473-INFO- Average Latency : 45.13027933 ms
2025-02-25 16:41:57,954-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:41:57,954-main.py:76-INFO-Loading dataset:
2025-02-25 16:42:06,545-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-25 16:42:07,486-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:42:07,487-main.py:109-INFO-Loading model:
2025-02-25 16:42:07,487-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:42:07,494-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:42:07,982-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:42:07,982-main.py:466-INFO- * Speed: 46.93630 ms/iter
2025-02-25 16:42:07,982-main.py:467-INFO- * MAPE: 0.91468
2025-02-25 16:42:07,982-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 16:42:07,982-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-02-25 16:42:07,982-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:42:07,983-main.py:473-INFO- Average Latency : 45.26959525 ms
2025-02-25 16:49:34,834-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-25 16:49:34,834-main.py:76-INFO-Loading dataset:
2025-02-25 16:49:36,036-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-25 16:49:36,917-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-25 16:49:36,918-main.py:109-INFO-Loading model:
2025-02-25 16:49:36,918-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:49:36,925-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-25 16:49:37,417-main.py:465-INFO- ------------------------------------------------------------------
2025-02-25 16:49:37,417-main.py:466-INFO- * Speed: 39.19190 ms/iter
2025-02-25 16:49:37,417-main.py:467-INFO- * MAPE: 0.83806
2025-02-25 16:49:37,417-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-25 16:49:37,417-main.py:469-INFO- * Kendall's Tau: -0.1272727272727273
2025-02-25 16:49:37,417-main.py:470-INFO- ------------------------------------------------------------------
2025-02-25 16:49:37,418-main.py:473-INFO- Average Latency : 37.91939129 ms
2025-02-26 12:38:00,779-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/GReg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 12:38:00,780-main.py:76-INFO-Loading dataset:
2025-02-26 12:38:04,389-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 12:38:05,506-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 12:38:05,506-main.py:109-INFO-Loading model:
2025-02-26 12:38:05,507-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:38:05,527-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:38:06,173-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 12:38:06,173-main.py:466-INFO- * Speed: 62.55017 ms/iter
2025-02-26 12:38:06,173-main.py:467-INFO- * MAPE: 0.94119
2025-02-26 12:38:06,173-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 12:38:06,173-main.py:469-INFO- * Kendall's Tau: -0.5555555555555556
2025-02-26 12:38:06,173-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 12:38:06,173-main.py:473-INFO- Average Latency : 60.66770024 ms
2025-02-26 12:42:21,229-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/GReg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 12:42:21,229-main.py:76-INFO-Loading dataset:
2025-02-26 12:42:22,047-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 12:42:22,907-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 12:42:22,908-main.py:109-INFO-Loading model:
2025-02-26 12:42:22,909-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:42:22,915-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:42:23,403-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 12:42:23,403-main.py:466-INFO- * Speed: 38.84079 ms/iter
2025-02-26 12:42:23,403-main.py:467-INFO- * MAPE: 0.82803
2025-02-26 12:42:23,404-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 12:42:23,404-main.py:469-INFO- * Kendall's Tau: -0.9636363636363636
2025-02-26 12:42:23,404-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 12:42:23,404-main.py:473-INFO- Average Latency : 37.30047833 ms
2025-02-26 12:50:12,594-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 12:50:12,594-main.py:76-INFO-Loading dataset:
2025-02-26 12:50:15,898-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 12:50:16,860-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 12:50:16,861-main.py:109-INFO-Loading model:
2025-02-26 12:50:16,862-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:50:16,868-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:50:17,443-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 12:50:17,443-main.py:466-INFO- * Speed: 55.47176 ms/iter
2025-02-26 12:50:17,443-main.py:467-INFO- * MAPE: 0.93901
2025-02-26 12:50:17,444-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 12:50:17,444-main.py:469-INFO- * Kendall's Tau: -0.7222222222222222
2025-02-26 12:50:17,444-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 12:50:17,444-main.py:473-INFO- Average Latency : 54.25379011 ms
2025-02-26 12:54:35,773-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 12:54:35,773-main.py:76-INFO-Loading dataset:
2025-02-26 12:54:36,610-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 12:54:37,475-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 12:54:37,476-main.py:109-INFO-Loading model:
2025-02-26 12:54:37,476-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:54:37,483-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 12:54:37,972-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 12:54:37,972-main.py:466-INFO- * Speed: 39.01430 ms/iter
2025-02-26 12:54:37,972-main.py:467-INFO- * MAPE: 0.84222
2025-02-26 12:54:37,972-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 12:54:37,972-main.py:469-INFO- * Kendall's Tau: -0.9636363636363636
2025-02-26 12:54:37,972-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 12:54:37,973-main.py:473-INFO- Average Latency : 37.47385198 ms
2025-02-26 13:05:29,217-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 13:05:29,217-main.py:76-INFO-Loading dataset:
2025-02-26 13:05:29,223-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 13:05:30,068-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 13:05:30,068-main.py:109-INFO-Loading model:
2025-02-26 13:05:30,069-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:05:30,075-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:05:30,663-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 13:05:30,663-main.py:466-INFO- * Speed: 47.70689 ms/iter
2025-02-26 13:05:30,663-main.py:467-INFO- * MAPE: 0.84222
2025-02-26 13:05:30,663-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 13:05:30,663-main.py:469-INFO- * Kendall's Tau: -0.9636363636363636
2025-02-26 13:05:30,664-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 13:05:30,664-main.py:473-INFO- Average Latency : 46.52898962 ms
2025-02-26 13:05:44,010-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 13:05:44,010-main.py:76-INFO-Loading dataset:
2025-02-26 13:05:44,817-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 13:05:45,722-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 13:05:45,723-main.py:109-INFO-Loading model:
2025-02-26 13:05:45,723-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:05:45,730-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:05:46,210-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 13:05:46,210-main.py:466-INFO- * Speed: 37.96402 ms/iter
2025-02-26 13:05:46,210-main.py:467-INFO- * MAPE: 0.84309
2025-02-26 13:05:46,211-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 13:05:46,211-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-26 13:05:46,211-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 13:05:46,211-main.py:473-INFO- Average Latency : 36.60479459 ms
2025-02-26 13:21:42,818-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 13:21:42,819-main.py:76-INFO-Loading dataset:
2025-02-26 13:21:45,093-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 13:21:45,947-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 13:21:45,947-main.py:109-INFO-Loading model:
2025-02-26 13:21:45,948-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:21:45,955-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:21:46,439-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 13:21:46,439-main.py:466-INFO- * Speed: 38.57004 ms/iter
2025-02-26 13:21:46,439-main.py:467-INFO- * MAPE: 0.93488
2025-02-26 13:21:46,440-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 13:21:46,440-main.py:469-INFO- * Kendall's Tau: -0.6363636363636364
2025-02-26 13:21:46,440-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 13:21:46,440-main.py:473-INFO- Average Latency : 37.21089797 ms
2025-02-26 13:26:07,676-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 13:26:07,676-main.py:76-INFO-Loading dataset:
2025-02-26 13:26:12,096-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 13:26:13,190-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 13:26:13,190-main.py:109-INFO-Loading model:
2025-02-26 13:26:13,191-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:26:13,199-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:26:13,758-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 13:26:13,758-main.py:466-INFO- * Speed: 54.51979 ms/iter
2025-02-26 13:26:13,758-main.py:467-INFO- * MAPE: 0.95854
2025-02-26 13:26:13,759-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 13:26:13,759-main.py:469-INFO- * Kendall's Tau: -0.8888888888888888
2025-02-26 13:26:13,759-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 13:26:13,759-main.py:473-INFO- Average Latency : 52.85880301 ms
2025-02-26 13:30:31,809-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 13:30:31,809-main.py:76-INFO-Loading dataset:
2025-02-26 13:30:34,448-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 13:30:35,309-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 13:30:35,310-main.py:109-INFO-Loading model:
2025-02-26 13:30:35,311-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:30:35,318-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:30:35,794-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 13:30:35,794-main.py:466-INFO- * Speed: 46.06830 ms/iter
2025-02-26 13:30:35,794-main.py:467-INFO- * MAPE: 0.90182
2025-02-26 13:30:35,794-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 13:30:35,794-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-26 13:30:35,795-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 13:30:35,795-main.py:473-INFO- Average Latency : 44.62885857 ms
2025-02-26 13:35:21,995-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 13:35:21,995-main.py:76-INFO-Loading dataset:
2025-02-26 13:35:23,146-main.py:274-INFO-Train data = 1, Test data = 19
2025-02-26 13:35:23,985-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 13:35:23,985-main.py:109-INFO-Loading model:
2025-02-26 13:35:23,986-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:35:23,991-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:35:24,554-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 13:35:24,554-main.py:466-INFO- * Speed: 26.45176 ms/iter
2025-02-26 13:35:24,555-main.py:467-INFO- * MAPE: 0.76529
2025-02-26 13:35:24,555-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 13:35:24,555-main.py:469-INFO- * Kendall's Tau: -0.6959064327485379
2025-02-26 13:35:24,555-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 13:35:24,555-main.py:473-INFO- Average Latency : 25.14026040 ms
2025-02-26 13:57:20,449-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 13:57:20,450-main.py:76-INFO-Loading dataset:
2025-02-26 13:57:22,793-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 13:57:23,636-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 13:57:23,636-main.py:109-INFO-Loading model:
2025-02-26 13:57:23,637-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:57:23,644-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 13:57:24,109-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 13:57:24,109-main.py:466-INFO- * Speed: 44.91833 ms/iter
2025-02-26 13:57:24,110-main.py:467-INFO- * MAPE: 0.86962
2025-02-26 13:57:24,110-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 13:57:24,110-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-26 13:57:24,110-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 13:57:24,110-main.py:473-INFO- Average Latency : 43.47870085 ms
2025-02-26 14:01:22,239-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 14:01:22,239-main.py:76-INFO-Loading dataset:
2025-02-26 14:01:22,815-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 14:01:23,695-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 14:01:23,695-main.py:109-INFO-Loading model:
2025-02-26 14:01:23,696-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 14:01:23,702-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 14:01:24,197-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 14:01:24,197-main.py:466-INFO- * Speed: 48.22082 ms/iter
2025-02-26 14:01:24,198-main.py:467-INFO- * MAPE: 0.76925
2025-02-26 14:01:24,198-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 14:01:24,198-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-02-26 14:01:24,199-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 14:01:24,199-main.py:473-INFO- Average Latency : 46.67027791 ms
2025-02-26 14:05:23,107-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 14:05:23,107-main.py:76-INFO-Loading dataset:
2025-02-26 14:05:23,380-main.py:274-INFO-Train data = 1, Test data = 14
2025-02-26 14:05:24,284-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 14:05:24,285-main.py:109-INFO-Loading model:
2025-02-26 14:05:24,286-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 14:05:24,293-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 14:05:24,807-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 14:05:24,807-main.py:466-INFO- * Speed: 32.32050 ms/iter
2025-02-26 14:05:24,807-main.py:467-INFO- * MAPE: 0.76013
2025-02-26 14:05:24,807-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 14:05:24,807-main.py:469-INFO- * Kendall's Tau: -0.9069767441860465
2025-02-26 14:05:24,808-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 14:05:24,808-main.py:473-INFO- Average Latency : 30.46951975 ms
2025-02-26 14:05:35,766-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 14:05:35,767-main.py:76-INFO-Loading dataset:
2025-02-26 14:05:36,784-main.py:274-INFO-Train data = 1, Test data = 14
2025-02-26 14:05:37,668-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 14:05:37,668-main.py:109-INFO-Loading model:
2025-02-26 14:05:37,669-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 14:05:37,676-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 14:05:38,175-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 14:05:38,175-main.py:466-INFO- * Speed: 31.11025 ms/iter
2025-02-26 14:05:38,175-main.py:467-INFO- * MAPE: 0.80027
2025-02-26 14:05:38,175-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 14:05:38,176-main.py:469-INFO- * Kendall's Tau: -0.9780219780219781
2025-02-26 14:05:38,176-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 14:05:38,176-main.py:473-INFO- Average Latency : 29.54394477 ms
2025-02-26 15:21:38,689-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:21:38,690-main.py:76-INFO-Loading dataset:
2025-02-26 15:21:38,696-main.py:274-INFO-Train data = 0, Test data = 0
2025-02-26 15:22:35,119-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:22:35,119-main.py:76-INFO-Loading dataset:
2025-02-26 15:22:35,129-main.py:274-INFO-Train data = 0, Test data = 0
2025-02-26 15:22:55,249-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/GReg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:22:55,249-main.py:76-INFO-Loading dataset:
2025-02-26 15:23:14,057-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 15:23:15,465-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 15:23:15,466-main.py:109-INFO-Loading model:
2025-02-26 15:23:15,467-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:23:15,487-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:23:16,440-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 15:23:16,440-main.py:466-INFO- * Speed: 90.11804 ms/iter
2025-02-26 15:23:16,440-main.py:467-INFO- * MAPE: 0.96108
2025-02-26 15:23:16,440-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 15:23:16,440-main.py:469-INFO- * Kendall's Tau: -0.5555555555555556
2025-02-26 15:23:16,441-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 15:23:16,441-main.py:473-INFO- Average Latency : 87.45996157 ms
2025-02-26 15:29:13,184-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/GReg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:29:13,184-main.py:76-INFO-Loading dataset:
2025-02-26 15:29:27,142-main.py:274-INFO-Train data = 1, Test data = 18
2025-02-26 15:29:28,554-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 15:29:28,555-main.py:109-INFO-Loading model:
2025-02-26 15:29:28,556-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:29:28,576-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:29:29,546-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 15:29:29,547-main.py:466-INFO- * Speed: 46.03562 ms/iter
2025-02-26 15:29:29,547-main.py:467-INFO- * MAPE: 0.89622
2025-02-26 15:29:29,547-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 15:29:29,547-main.py:469-INFO- * Kendall's Tau: 0.5816993464052289
2025-02-26 15:29:29,548-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 15:29:29,548-main.py:473-INFO- Average Latency : 43.98686356 ms
2025-02-26 15:37:10,456-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/GReg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:37:10,456-main.py:76-INFO-Loading dataset:
2025-02-26 15:37:14,252-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 15:37:15,224-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 15:37:15,225-main.py:109-INFO-Loading model:
2025-02-26 15:37:15,226-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:37:15,232-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:37:15,795-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 15:37:15,795-main.py:466-INFO- * Speed: 53.04488 ms/iter
2025-02-26 15:37:15,796-main.py:467-INFO- * MAPE: 0.88048
2025-02-26 15:37:15,796-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 15:37:15,796-main.py:469-INFO- * Kendall's Tau: 0.1111111111111111
2025-02-26 15:37:15,796-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 15:37:15,796-main.py:473-INFO- Average Latency : 51.60509215 ms
2025-02-26 15:45:44,478-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/GReg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:45:44,479-main.py:76-INFO-Loading dataset:
2025-02-26 15:45:46,855-main.py:274-INFO-Train data = 0, Test data = 3
2025-02-26 15:46:32,015-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:46:32,015-main.py:76-INFO-Loading dataset:
2025-02-26 15:46:48,375-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 15:46:49,272-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 15:46:49,272-main.py:109-INFO-Loading model:
2025-02-26 15:46:49,273-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:46:49,301-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:46:50,187-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 15:46:50,187-main.py:466-INFO- * Speed: 82.31197 ms/iter
2025-02-26 15:46:50,187-main.py:467-INFO- * MAPE: 0.95166
2025-02-26 15:46:50,187-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 15:46:50,187-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-26 15:46:50,187-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 15:46:50,188-main.py:473-INFO- Average Latency : 80.76159159 ms
2025-02-26 15:50:42,495-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 15:50:42,495-main.py:76-INFO-Loading dataset:
2025-02-26 15:50:45,330-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 15:50:46,213-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 15:50:46,213-main.py:109-INFO-Loading model:
2025-02-26 15:50:46,214-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:50:46,220-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 15:50:46,781-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 15:50:46,781-main.py:466-INFO- * Speed: 44.87759 ms/iter
2025-02-26 15:50:46,781-main.py:467-INFO- * MAPE: 0.91758
2025-02-26 15:50:46,781-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 15:50:46,781-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-26 15:50:46,781-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 15:50:46,781-main.py:473-INFO- Average Latency : 43.56267235 ms
2025-02-26 16:00:47,445-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 16:00:47,445-main.py:76-INFO-Loading dataset:
2025-02-26 16:00:47,450-main.py:274-INFO-Train data = 0, Test data = 0
2025-02-26 16:01:46,586-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 16:01:46,586-main.py:76-INFO-Loading dataset:
2025-02-26 16:02:00,342-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 16:02:02,089-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 16:02:02,090-main.py:109-INFO-Loading model:
2025-02-26 16:02:02,091-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 16:02:02,110-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 16:02:03,153-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 16:02:03,153-main.py:466-INFO- * Speed: 100.06118 ms/iter
2025-02-26 16:02:03,153-main.py:467-INFO- * MAPE: 0.94047
2025-02-26 16:02:03,153-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 16:02:03,153-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-02-26 16:02:03,153-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 16:02:03,153-main.py:473-INFO- Average Latency : 97.73551093 ms
2025-02-26 16:08:35,807-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 16:08:35,808-main.py:76-INFO-Loading dataset:
2025-02-26 16:09:05,928-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 16:09:07,334-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 16:09:07,335-main.py:109-INFO-Loading model:
2025-02-26 16:09:07,336-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 16:09:07,355-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 16:09:08,282-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 16:09:08,282-main.py:466-INFO- * Speed: 87.28109 ms/iter
2025-02-26 16:09:08,282-main.py:467-INFO- * MAPE: 0.97580
2025-02-26 16:09:08,282-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 16:09:08,282-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-26 16:09:08,282-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 16:09:08,283-main.py:473-INFO- Average Latency : 84.51255163 ms
2025-02-26 17:15:07,949-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 17:15:07,950-main.py:76-INFO-Loading dataset:
2025-02-26 17:15:12,182-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 17:15:13,242-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 17:15:13,242-main.py:109-INFO-Loading model:
2025-02-26 17:15:13,243-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 17:15:13,249-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 17:15:13,873-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 17:15:13,873-main.py:466-INFO- * Speed: 51.21608 ms/iter
2025-02-26 17:15:13,873-main.py:467-INFO- * MAPE: 0.92658
2025-02-26 17:15:13,873-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 17:15:13,873-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-26 17:15:13,873-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 17:15:13,873-main.py:473-INFO- Average Latency : 49.85696619 ms
2025-02-26 17:18:49,988-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 17:18:49,988-main.py:76-INFO-Loading dataset:
2025-02-26 17:19:01,858-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-26 17:19:02,744-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 17:19:02,745-main.py:109-INFO-Loading model:
2025-02-26 17:19:02,746-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 17:19:02,752-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 17:19:03,256-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 17:19:03,256-main.py:466-INFO- * Speed: 49.01526 ms/iter
2025-02-26 17:19:03,256-main.py:467-INFO- * MAPE: 0.94873
2025-02-26 17:19:03,256-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 17:19:03,256-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-26 17:19:03,256-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 17:19:03,256-main.py:473-INFO- Average Latency : 47.57563273 ms
2025-02-26 17:21:48,265-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-26 17:21:48,265-main.py:76-INFO-Loading dataset:
2025-02-26 17:21:49,908-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-26 17:21:50,794-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-26 17:21:50,794-main.py:109-INFO-Loading model:
2025-02-26 17:21:50,795-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-26 17:21:50,802-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-26 17:21:51,299-main.py:465-INFO- ------------------------------------------------------------------
2025-02-26 17:21:51,299-main.py:466-INFO- * Speed: 39.23386 ms/iter
2025-02-26 17:21:51,299-main.py:467-INFO- * MAPE: 0.89324
2025-02-26 17:21:51,299-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-26 17:21:51,299-main.py:469-INFO- * Kendall's Tau: -0.8909090909090909
2025-02-26 17:21:51,299-main.py:470-INFO- ------------------------------------------------------------------
2025-02-26 17:21:51,299-main.py:473-INFO- Average Latency : 37.74751316 ms
2025-02-27 12:52:23,912-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 12:52:23,913-main.py:76-INFO-Loading dataset:
2025-02-27 12:52:23,919-main.py:274-INFO-Train data = 0, Test data = 0
2025-02-27 12:52:42,135-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 12:52:42,135-main.py:76-INFO-Loading dataset:
2025-02-27 12:53:02,023-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 12:53:03,408-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 12:53:03,408-main.py:109-INFO-Loading model:
2025-02-27 12:53:03,409-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 12:53:03,430-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 12:53:04,338-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 12:53:04,338-main.py:466-INFO- * Speed: 85.24058 ms/iter
2025-02-27 12:53:04,338-main.py:467-INFO- * MAPE: 0.95177
2025-02-27 12:53:04,338-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 12:53:04,338-main.py:469-INFO- * Kendall's Tau: -0.8888888888888888
2025-02-27 12:53:04,338-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 12:53:04,338-main.py:473-INFO- Average Latency : 82.24060800 ms
2025-02-27 12:55:33,539-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 12:55:33,539-main.py:76-INFO-Loading dataset:
2025-02-27 12:55:51,648-main.py:274-INFO-Train data = 1, Test data = 19
2025-02-27 12:55:52,739-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 12:55:52,740-main.py:109-INFO-Loading model:
2025-02-27 12:55:52,740-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 12:55:52,747-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 12:55:53,274-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 12:55:53,274-main.py:466-INFO- * Speed: 24.43750 ms/iter
2025-02-27 12:55:53,274-main.py:467-INFO- * MAPE: 0.89446
2025-02-27 12:55:53,274-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 12:55:53,274-main.py:469-INFO- * Kendall's Tau: -0.8362573099415204
2025-02-27 12:55:53,274-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 12:55:53,274-main.py:473-INFO- Average Latency : 23.01636495 ms
2025-02-27 12:59:06,536-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 12:59:06,536-main.py:76-INFO-Loading dataset:
2025-02-27 12:59:09,404-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-27 12:59:10,278-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 12:59:10,279-main.py:109-INFO-Loading model:
2025-02-27 12:59:10,279-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 12:59:10,285-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 12:59:10,779-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 12:59:10,779-main.py:466-INFO- * Speed: 39.37791 ms/iter
2025-02-27 12:59:10,779-main.py:467-INFO- * MAPE: 0.91867
2025-02-27 12:59:10,780-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 12:59:10,780-main.py:469-INFO- * Kendall's Tau: -1.0
2025-02-27 12:59:10,780-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 12:59:10,780-main.py:473-INFO- Average Latency : 37.46884519 ms
2025-02-27 13:34:53,890-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:34:53,890-main.py:76-INFO-Loading dataset:
2025-02-27 13:34:53,896-main.py:274-INFO-Train data = 0, Test data = 0
2025-02-27 13:35:41,308-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:35:41,309-main.py:76-INFO-Loading dataset:
2025-02-27 13:35:44,619-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 13:35:45,488-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:35:45,489-main.py:109-INFO-Loading model:
2025-02-27 13:35:45,490-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:35:45,496-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:35:46,091-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:35:46,091-main.py:466-INFO- * Speed: 59.11989 ms/iter
2025-02-27 13:35:46,091-main.py:467-INFO- * MAPE: 0.85653
2025-02-27 13:35:46,091-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 13:35:46,091-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-27 13:35:46,091-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:35:46,091-main.py:473-INFO- Average Latency : 57.78654416 ms
2025-02-27 13:39:00,371-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:39:00,371-main.py:76-INFO-Loading dataset:
2025-02-27 13:39:01,076-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 13:39:01,952-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:39:01,952-main.py:109-INFO-Loading model:
2025-02-27 13:39:01,952-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:39:01,959-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:39:02,433-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:39:02,433-main.py:466-INFO- * Speed: 45.83197 ms/iter
2025-02-27 13:39:02,433-main.py:467-INFO- * MAPE: 0.78574
2025-02-27 13:39:02,433-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 13:39:02,433-main.py:469-INFO- * Kendall's Tau: 0.5555555555555556
2025-02-27 13:39:02,433-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:39:02,433-main.py:473-INFO- Average Latency : 44.49860255 ms
2025-02-27 13:41:59,691-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:41:59,691-main.py:76-INFO-Loading dataset:
2025-02-27 13:42:00,032-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 13:42:00,919-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:42:00,920-main.py:109-INFO-Loading model:
2025-02-27 13:42:00,920-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:42:00,926-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:42:01,404-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:42:01,404-main.py:466-INFO- * Speed: 46.15858 ms/iter
2025-02-27 13:42:01,404-main.py:467-INFO- * MAPE: 0.64053
2025-02-27 13:42:01,404-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 13:42:01,405-main.py:469-INFO- * Kendall's Tau: 0.8333333333333334
2025-02-27 13:42:01,405-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:42:01,405-main.py:473-INFO- Average Latency : 44.82454724 ms
2025-02-27 13:45:47,924-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:45:47,925-main.py:76-INFO-Loading dataset:
2025-02-27 13:45:48,009-main.py:274-INFO-Train data = 0, Test data = 3
2025-02-27 13:46:13,513-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:46:13,513-main.py:76-INFO-Loading dataset:
2025-02-27 13:46:15,913-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 13:46:16,840-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:46:16,840-main.py:109-INFO-Loading model:
2025-02-27 13:46:16,841-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:46:16,847-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:46:17,325-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:46:17,325-main.py:466-INFO- * Speed: 46.18666 ms/iter
2025-02-27 13:46:17,325-main.py:467-INFO- * MAPE: 0.53710
2025-02-27 13:46:17,326-main.py:468-INFO- * ErrorBound: [0.33333333 0.33333333 0.33333333]
2025-02-27 13:46:17,326-main.py:469-INFO- * Kendall's Tau: -0.5555555555555556
2025-02-27 13:46:17,326-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:46:17,326-main.py:473-INFO- Average Latency : 44.74218686 ms
2025-02-27 13:49:19,679-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:49:19,679-main.py:76-INFO-Loading dataset:
2025-02-27 13:49:23,912-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 13:49:24,915-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:49:24,916-main.py:109-INFO-Loading model:
2025-02-27 13:49:24,916-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:49:24,923-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:49:25,415-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:49:25,415-main.py:466-INFO- * Speed: 47.73190 ms/iter
2025-02-27 13:49:25,416-main.py:467-INFO- * MAPE: 0.85690
2025-02-27 13:49:25,416-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 13:49:25,416-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-27 13:49:25,416-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:49:25,417-main.py:473-INFO- Average Latency : 46.39850722 ms
2025-02-27 13:50:51,452-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:50:51,452-main.py:76-INFO-Loading dataset:
2025-02-27 13:50:54,420-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 13:50:55,312-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:50:55,313-main.py:109-INFO-Loading model:
2025-02-27 13:50:55,313-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:50:55,319-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:50:55,932-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:50:55,932-main.py:466-INFO- * Speed: 60.49140 ms/iter
2025-02-27 13:50:55,932-main.py:467-INFO- * MAPE: 0.76178
2025-02-27 13:50:55,933-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 13:50:55,933-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-27 13:50:55,933-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:50:55,933-main.py:473-INFO- Average Latency : 58.93577470 ms
2025-02-27 13:52:32,376-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:52:32,377-main.py:76-INFO-Loading dataset:
2025-02-27 13:52:32,703-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-27 13:52:33,640-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:52:33,641-main.py:109-INFO-Loading model:
2025-02-27 13:52:33,642-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:52:33,648-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:52:34,133-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:52:34,133-main.py:466-INFO- * Speed: 38.38843 ms/iter
2025-02-27 13:52:34,133-main.py:467-INFO- * MAPE: 0.55269
2025-02-27 13:52:34,133-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 13:52:34,133-main.py:469-INFO- * Kendall's Tau: 0.5636363636363636
2025-02-27 13:52:34,134-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:52:34,134-main.py:473-INFO- Average Latency : 36.93387725 ms
2025-02-27 13:57:31,150-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:57:31,150-main.py:76-INFO-Loading dataset:
2025-02-27 13:57:35,037-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 13:57:35,912-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 13:57:35,913-main.py:109-INFO-Loading model:
2025-02-27 13:57:35,913-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:57:35,921-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 13:57:36,554-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 13:57:36,555-main.py:466-INFO- * Speed: 61.08859 ms/iter
2025-02-27 13:57:36,555-main.py:467-INFO- * MAPE: 0.87500
2025-02-27 13:57:36,555-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 13:57:36,555-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-27 13:57:36,555-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 13:57:36,555-main.py:473-INFO- Average Latency : 59.86621645 ms
2025-02-27 13:59:56,275-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 13:59:56,275-main.py:76-INFO-Loading dataset:
2025-02-27 13:59:59,240-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 14:00:00,147-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 14:00:00,148-main.py:109-INFO-Loading model:
2025-02-27 14:00:00,148-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:00:00,156-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:00:00,655-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 14:00:00,655-main.py:466-INFO- * Speed: 48.69665 ms/iter
2025-02-27 14:00:00,655-main.py:467-INFO- * MAPE: 0.76178
2025-02-27 14:00:00,655-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 14:00:00,656-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-27 14:00:00,656-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 14:00:00,656-main.py:473-INFO- Average Latency : 47.25217819 ms
2025-02-27 14:03:38,708-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 14:03:38,708-main.py:76-INFO-Loading dataset:
2025-02-27 14:03:39,042-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-27 14:03:39,931-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 14:03:39,932-main.py:109-INFO-Loading model:
2025-02-27 14:03:39,932-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:03:39,938-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:03:40,425-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 14:03:40,425-main.py:466-INFO- * Speed: 38.57027 ms/iter
2025-02-27 14:03:40,426-main.py:467-INFO- * MAPE: 0.55269
2025-02-27 14:03:40,426-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 14:03:40,426-main.py:469-INFO- * Kendall's Tau: 0.5636363636363636
2025-02-27 14:03:40,426-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 14:03:40,426-main.py:473-INFO- Average Latency : 37.29759563 ms
2025-02-27 14:09:46,159-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 14:09:46,159-main.py:76-INFO-Loading dataset:
2025-02-27 14:09:49,100-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 14:09:49,965-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 14:09:49,966-main.py:109-INFO-Loading model:
2025-02-27 14:09:49,967-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:09:49,973-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:09:50,462-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 14:09:50,462-main.py:466-INFO- * Speed: 47.36469 ms/iter
2025-02-27 14:09:50,462-main.py:467-INFO- * MAPE: 0.76178
2025-02-27 14:09:50,462-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 14:09:50,463-main.py:469-INFO- * Kendall's Tau: -0.6666666666666666
2025-02-27 14:09:50,463-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 14:09:50,463-main.py:473-INFO- Average Latency : 45.80916299 ms
2025-02-27 14:13:35,506-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 14:13:35,507-main.py:76-INFO-Loading dataset:
2025-02-27 14:13:35,833-main.py:274-INFO-Train data = 1, Test data = 11
2025-02-27 14:13:36,705-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 14:13:36,706-main.py:109-INFO-Loading model:
2025-02-27 14:13:36,706-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:13:36,712-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:13:37,190-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 14:13:37,190-main.py:466-INFO- * Speed: 37.90912 ms/iter
2025-02-27 14:13:37,190-main.py:467-INFO- * MAPE: 0.55269
2025-02-27 14:13:37,190-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 14:13:37,191-main.py:469-INFO- * Kendall's Tau: 0.5636363636363636
2025-02-27 14:13:37,191-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 14:13:37,191-main.py:473-INFO- Average Latency : 36.63633086 ms
2025-02-27 14:24:59,095-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 14:24:59,095-main.py:76-INFO-Loading dataset:
2025-02-27 14:25:01,440-main.py:274-INFO-Train data = 1, Test data = 9
2025-02-27 14:25:02,309-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 14:25:02,309-main.py:109-INFO-Loading model:
2025-02-27 14:25:02,310-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:25:02,316-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:25:02,785-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 14:25:02,785-main.py:466-INFO- * Speed: 44.99997 ms/iter
2025-02-27 14:25:02,785-main.py:467-INFO- * MAPE: 0.77461
2025-02-27 14:25:02,785-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 14:25:02,785-main.py:469-INFO- * Kendall's Tau: -0.7777777777777778
2025-02-27 14:25:02,785-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 14:25:02,786-main.py:473-INFO- Average Latency : 43.77773073 ms
2025-02-27 14:34:30,907-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-02-27 14:34:30,907-main.py:76-INFO-Loading dataset:
2025-02-27 14:34:31,435-main.py:274-INFO-Train data = 1, Test data = 17
2025-02-27 14:34:32,303-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-02-27 14:34:32,304-main.py:109-INFO-Loading model:
2025-02-27 14:34:32,304-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:34:32,311-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-02-27 14:34:32,818-main.py:465-INFO- ------------------------------------------------------------------
2025-02-27 14:34:32,818-main.py:466-INFO- * Speed: 26.19152 ms/iter
2025-02-27 14:34:32,818-main.py:467-INFO- * MAPE: 0.45114
2025-02-27 14:34:32,818-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-02-27 14:34:32,818-main.py:469-INFO- * Kendall's Tau: -0.02941176470588235
2025-02-27 14:34:32,818-main.py:470-INFO- ------------------------------------------------------------------
2025-02-27 14:34:32,818-main.py:473-INFO- Average Latency : 24.77975453 ms
2025-03-03 14:06:14,727-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:06:14,727-main.py:76-INFO-Loading dataset:
2025-03-03 14:06:24,305-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 14:06:25,800-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:06:25,800-main.py:109-INFO-Loading model:
2025-03-03 14:06:25,801-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:06:25,822-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:06:26,802-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:06:26,802-main.py:466-INFO- * Speed: 92.03474 ms/iter
2025-03-03 14:06:26,802-main.py:467-INFO- * MAPE: 0.95986
2025-03-03 14:06:26,802-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:06:26,802-main.py:469-INFO- * Kendall's Tau: -0.611111111111111
2025-03-03 14:06:26,803-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:06:26,803-main.py:473-INFO- Average Latency : 89.59854974 ms
2025-03-03 14:14:28,382-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:14:28,382-main.py:76-INFO-Loading dataset:
2025-03-03 14:14:36,912-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 14:14:37,931-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:14:37,932-main.py:109-INFO-Loading model:
2025-03-03 14:14:37,933-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:14:37,939-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:14:38,444-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:14:38,444-main.py:466-INFO- * Speed: 49.09025 ms/iter
2025-03-03 14:14:38,444-main.py:467-INFO- * MAPE: 0.91974
2025-03-03 14:14:38,445-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:14:38,445-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-03-03 14:14:38,445-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:14:38,445-main.py:473-INFO- Average Latency : 47.76130782 ms
2025-03-03 14:16:54,199-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:16:54,199-main.py:76-INFO-Loading dataset:
2025-03-03 14:16:57,091-main.py:274-INFO-Train data = 1, Test data = 11
2025-03-03 14:16:58,001-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:16:58,002-main.py:109-INFO-Loading model:
2025-03-03 14:16:58,004-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:16:58,013-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:16:58,527-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:16:58,528-main.py:466-INFO- * Speed: 40.99991 ms/iter
2025-03-03 14:16:58,528-main.py:467-INFO- * MAPE: 0.91557
2025-03-03 14:16:58,528-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:16:58,528-main.py:469-INFO- * Kendall's Tau: -1.0
2025-03-03 14:16:58,528-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:16:58,528-main.py:473-INFO- Average Latency : 39.55036944 ms
2025-03-03 14:27:53,641-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:27:53,641-main.py:76-INFO-Loading dataset:
2025-03-03 14:29:26,023-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:29:26,024-main.py:76-INFO-Loading dataset:
2025-03-03 14:29:36,496-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 14:29:37,397-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:29:37,397-main.py:109-INFO-Loading model:
2025-03-03 14:29:37,398-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:29:37,405-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:29:37,905-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:29:37,905-main.py:466-INFO- * Speed: 48.12821 ms/iter
2025-03-03 14:29:37,905-main.py:467-INFO- * MAPE: 0.96064
2025-03-03 14:29:37,905-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:29:37,905-main.py:469-INFO- * Kendall's Tau: -0.7777777777777778
2025-03-03 14:29:37,906-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:29:37,906-main.py:473-INFO- Average Latency : 46.46738370 ms
2025-03-03 14:31:37,178-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:31:37,178-main.py:76-INFO-Loading dataset:
2025-03-03 14:31:45,793-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 14:31:46,699-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:31:46,699-main.py:109-INFO-Loading model:
2025-03-03 14:31:46,700-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:31:46,707-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:31:47,212-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:31:47,212-main.py:466-INFO- * Speed: 48.80073 ms/iter
2025-03-03 14:31:47,213-main.py:467-INFO- * MAPE: 0.91974
2025-03-03 14:31:47,213-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:31:47,213-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-03-03 14:31:47,213-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:31:47,213-main.py:473-INFO- Average Latency : 47.13930024 ms
2025-03-03 14:33:33,256-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:33:33,256-main.py:76-INFO-Loading dataset:
2025-03-03 14:33:36,171-main.py:274-INFO-Train data = 1, Test data = 11
2025-03-03 14:33:37,086-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:33:37,087-main.py:109-INFO-Loading model:
2025-03-03 14:33:37,087-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:33:37,094-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:33:37,672-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:33:37,672-main.py:466-INFO- * Speed: 46.63721 ms/iter
2025-03-03 14:33:37,672-main.py:467-INFO- * MAPE: 0.91557
2025-03-03 14:33:37,672-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:33:37,672-main.py:469-INFO- * Kendall's Tau: -1.0
2025-03-03 14:33:37,672-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:33:37,672-main.py:473-INFO- Average Latency : 45.00621015 ms
2025-03-03 14:38:44,836-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:38:44,836-main.py:76-INFO-Loading dataset:
2025-03-03 14:38:57,563-main.py:274-INFO-Train data = 1, Test data = 10
2025-03-03 14:38:58,484-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:38:58,484-main.py:109-INFO-Loading model:
2025-03-03 14:38:58,485-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:38:58,494-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:38:59,029-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:38:59,029-main.py:466-INFO- * Speed: 44.31267 ms/iter
2025-03-03 14:38:59,029-main.py:467-INFO- * MAPE: 0.94278
2025-03-03 14:38:59,029-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:38:59,029-main.py:469-INFO- * Kendall's Tau: -0.5111111111111111
2025-03-03 14:38:59,029-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:38:59,030-main.py:473-INFO- Average Latency : 42.41900444 ms
2025-03-03 14:42:05,714-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:42:05,714-main.py:76-INFO-Loading dataset:
2025-03-03 14:42:14,773-main.py:274-INFO-Train data = 1, Test data = 19
2025-03-03 14:42:15,648-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:42:15,649-main.py:109-INFO-Loading model:
2025-03-03 14:42:15,649-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:42:15,656-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:42:16,183-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:42:16,183-main.py:466-INFO- * Speed: 24.28166 ms/iter
2025-03-03 14:42:16,183-main.py:467-INFO- * MAPE: 0.88683
2025-03-03 14:42:16,184-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:42:16,184-main.py:469-INFO- * Kendall's Tau: 0.5321637426900584
2025-03-03 14:42:16,184-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:42:16,184-main.py:473-INFO- Average Latency : 22.91783534 ms
2025-03-03 14:45:42,019-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:45:42,020-main.py:76-INFO-Loading dataset:
2025-03-03 14:45:42,868-main.py:274-INFO-Train data = 1, Test data = 12
2025-03-03 14:45:43,879-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:45:43,879-main.py:109-INFO-Loading model:
2025-03-03 14:45:43,880-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:45:43,886-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:45:44,377-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:45:44,377-main.py:466-INFO- * Speed: 35.75174 ms/iter
2025-03-03 14:45:44,377-main.py:467-INFO- * MAPE: 0.90469
2025-03-03 14:45:44,377-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:45:44,377-main.py:469-INFO- * Kendall's Tau: -0.9393939393939392
2025-03-03 14:45:44,378-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:45:44,378-main.py:473-INFO- Average Latency : 34.25699472 ms
2025-03-03 14:52:36,067-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:52:36,067-main.py:76-INFO-Loading dataset:
2025-03-03 14:52:37,017-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-03 14:52:37,891-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:52:37,892-main.py:109-INFO-Loading model:
2025-03-03 14:52:37,893-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:52:37,899-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:52:38,409-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:52:38,409-main.py:466-INFO- * Speed: 29.79754 ms/iter
2025-03-03 14:52:38,409-main.py:467-INFO- * MAPE: 0.90105
2025-03-03 14:52:38,409-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:52:38,409-main.py:469-INFO- * Kendall's Tau: -0.9378097778799172
2025-03-03 14:52:38,409-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:52:38,409-main.py:473-INFO- Average Latency : 28.17252477 ms
2025-03-03 14:57:53,066-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 14:57:53,066-main.py:76-INFO-Loading dataset:
2025-03-03 14:58:05,325-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 14:58:06,207-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 14:58:06,208-main.py:109-INFO-Loading model:
2025-03-03 14:58:06,208-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:58:06,214-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 14:58:06,702-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 14:58:06,702-main.py:466-INFO- * Speed: 47.25387 ms/iter
2025-03-03 14:58:06,703-main.py:467-INFO- * MAPE: 0.96796
2025-03-03 14:58:06,703-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 14:58:06,703-main.py:469-INFO- * Kendall's Tau: -0.611111111111111
2025-03-03 14:58:06,703-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 14:58:06,703-main.py:473-INFO- Average Latency : 45.81422276 ms
2025-03-03 15:00:55,709-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:00:55,709-main.py:76-INFO-Loading dataset:
2025-03-03 15:01:04,155-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 15:01:05,250-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:01:05,250-main.py:109-INFO-Loading model:
2025-03-03 15:01:05,251-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:01:05,259-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:01:05,754-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:01:05,754-main.py:466-INFO- * Speed: 48.20177 ms/iter
2025-03-03 15:01:05,754-main.py:467-INFO- * MAPE: 0.91974
2025-03-03 15:01:05,754-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:01:05,755-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-03-03 15:01:05,755-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:01:05,755-main.py:473-INFO- Average Latency : 46.53011428 ms
2025-03-03 15:07:13,345-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:07:13,345-main.py:76-INFO-Loading dataset:
2025-03-03 15:07:16,916-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-03 15:07:17,918-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:07:17,918-main.py:109-INFO-Loading model:
2025-03-03 15:07:17,919-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:07:17,926-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:07:18,537-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:07:18,537-main.py:466-INFO- * Speed: 36.54648 ms/iter
2025-03-03 15:07:18,537-main.py:467-INFO- * MAPE: 0.91209
2025-03-03 15:07:18,537-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:07:18,537-main.py:469-INFO- * Kendall's Tau: -0.8365771355618076
2025-03-03 15:07:18,537-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:07:18,537-main.py:473-INFO- Average Latency : 35.15117963 ms
2025-03-03 15:12:17,486-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:12:17,486-main.py:76-INFO-Loading dataset:
2025-03-03 15:12:23,023-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 15:12:24,103-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:12:24,103-main.py:109-INFO-Loading model:
2025-03-03 15:12:24,104-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:12:24,112-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:12:24,595-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:12:24,595-main.py:466-INFO- * Speed: 46.28963 ms/iter
2025-03-03 15:12:24,595-main.py:467-INFO- * MAPE: 0.90719
2025-03-03 15:12:24,595-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:12:24,595-main.py:469-INFO- * Kendall's Tau: -1.0
2025-03-03 15:12:24,596-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:12:24,596-main.py:473-INFO- Average Latency : 44.96073723 ms
2025-03-03 15:15:38,953-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:15:38,953-main.py:76-INFO-Loading dataset:
2025-03-03 15:15:41,572-main.py:274-INFO-Train data = 1, Test data = 20
2025-03-03 15:15:42,442-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:15:42,443-main.py:109-INFO-Loading model:
2025-03-03 15:15:42,444-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:15:42,450-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:15:42,977-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:15:42,977-main.py:466-INFO- * Speed: 23.20302 ms/iter
2025-03-03 15:15:42,977-main.py:467-INFO- * MAPE: 0.89497
2025-03-03 15:15:42,978-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:15:42,978-main.py:469-INFO- * Kendall's Tau: -0.8105263157894737
2025-03-03 15:15:42,978-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:15:42,978-main.py:473-INFO- Average Latency : 21.75784111 ms
2025-03-03 15:25:22,097-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:25:22,097-main.py:76-INFO-Loading dataset:
2025-03-03 15:25:22,102-main.py:274-INFO-Train data = 0, Test data = 0
2025-03-03 15:26:15,733-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:26:15,733-main.py:76-INFO-Loading dataset:
2025-03-03 15:26:20,174-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 15:26:21,188-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:26:21,189-main.py:109-INFO-Loading model:
2025-03-03 15:26:21,190-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:26:21,196-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:26:21,698-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:26:21,699-main.py:466-INFO- * Speed: 48.90172 ms/iter
2025-03-03 15:26:21,699-main.py:467-INFO- * MAPE: 0.79240
2025-03-03 15:26:21,699-main.py:468-INFO- * ErrorBound: [0.11111111 0.11111111 0.        ]
2025-03-03 15:26:21,699-main.py:469-INFO- * Kendall's Tau: -1.0
2025-03-03 15:26:21,700-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:26:21,700-main.py:473-INFO- Average Latency : 47.35136032 ms
2025-03-03 15:34:56,483-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:34:56,483-main.py:76-INFO-Loading dataset:
2025-03-03 15:34:57,526-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-03 15:34:58,395-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:34:58,396-main.py:109-INFO-Loading model:
2025-03-03 15:34:58,396-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:34:58,403-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:34:58,918-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:34:58,918-main.py:466-INFO- * Speed: 25.22704 ms/iter
2025-03-03 15:34:58,918-main.py:467-INFO- * MAPE: 0.52878
2025-03-03 15:34:58,919-main.py:468-INFO- * ErrorBound: [0.05555556 0.         0.        ]
2025-03-03 15:34:58,919-main.py:469-INFO- * Kendall's Tau: -0.9738562091503269
2025-03-03 15:34:58,919-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:34:58,919-main.py:473-INFO- Average Latency : 23.95354377 ms
2025-03-03 15:37:57,873-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:37:57,873-main.py:76-INFO-Loading dataset:
2025-03-03 15:38:01,891-main.py:274-INFO-Train data = 1, Test data = 11
2025-03-03 15:38:02,904-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:38:02,905-main.py:109-INFO-Loading model:
2025-03-03 15:38:02,906-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:38:02,912-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:38:03,403-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:38:03,403-main.py:466-INFO- * Speed: 39.01948 ms/iter
2025-03-03 15:38:03,404-main.py:467-INFO- * MAPE: 0.58767
2025-03-03 15:38:03,404-main.py:468-INFO- * ErrorBound: [0.27272727 0.27272727 0.27272727]
2025-03-03 15:38:03,404-main.py:469-INFO- * Kendall's Tau: -0.34545454545454546
2025-03-03 15:38:03,404-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:38:03,404-main.py:473-INFO- Average Latency : 37.87335483 ms
2025-03-03 15:39:24,678-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:39:24,678-main.py:76-INFO-Loading dataset:
2025-03-03 15:39:30,083-main.py:274-INFO-Train data = 1, Test data = 11
2025-03-03 15:39:31,050-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:39:31,051-main.py:109-INFO-Loading model:
2025-03-03 15:39:31,051-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:39:31,057-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:39:31,601-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:39:31,601-main.py:466-INFO- * Speed: 43.78269 ms/iter
2025-03-03 15:39:31,601-main.py:467-INFO- * MAPE: 0.61933
2025-03-03 15:39:31,602-main.py:468-INFO- * ErrorBound: [0.27272727 0.27272727 0.27272727]
2025-03-03 15:39:31,602-main.py:469-INFO- * Kendall's Tau: -0.23636363636363636
2025-03-03 15:39:31,602-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:39:31,602-main.py:473-INFO- Average Latency : 42.15158116 ms
2025-03-03 15:41:52,623-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:41:52,623-main.py:76-INFO-Loading dataset:
2025-03-03 15:42:01,112-main.py:274-INFO-Train data = 1, Test data = 14
2025-03-03 15:42:02,013-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:42:02,014-main.py:109-INFO-Loading model:
2025-03-03 15:42:02,015-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:42:02,021-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:42:02,534-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:42:02,534-main.py:466-INFO- * Speed: 32.15386 ms/iter
2025-03-03 15:42:02,535-main.py:467-INFO- * MAPE: 0.81246
2025-03-03 15:42:02,535-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:42:02,535-main.py:469-INFO- * Kendall's Tau: 0.8241758241758242
2025-03-03 15:42:02,535-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:42:02,535-main.py:473-INFO- Average Latency : 30.80098970 ms
2025-03-03 15:45:22,737-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:45:22,737-main.py:76-INFO-Loading dataset:
2025-03-03 15:45:24,340-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-03 15:45:25,220-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:45:25,221-main.py:109-INFO-Loading model:
2025-03-03 15:45:25,222-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:45:25,228-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:45:25,747-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:45:25,747-main.py:466-INFO- * Speed: 25.35203 ms/iter
2025-03-03 15:45:25,747-main.py:467-INFO- * MAPE: 0.73449
2025-03-03 15:45:25,747-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:45:25,747-main.py:469-INFO- * Kendall's Tau: -0.9738562091503269
2025-03-03 15:45:25,747-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:45:25,747-main.py:473-INFO- Average Latency : 23.85225561 ms
2025-03-03 15:49:39,060-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:49:39,061-main.py:76-INFO-Loading dataset:
2025-03-03 15:49:43,613-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 15:49:44,496-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:49:44,496-main.py:109-INFO-Loading model:
2025-03-03 15:49:44,498-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:49:44,504-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:49:44,997-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:49:44,998-main.py:466-INFO- * Speed: 47.02142 ms/iter
2025-03-03 15:49:44,998-main.py:467-INFO- * MAPE: 0.78458
2025-03-03 15:49:44,998-main.py:468-INFO- * ErrorBound: [0.11111111 0.11111111 0.        ]
2025-03-03 15:49:44,998-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-03-03 15:49:44,998-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:49:44,998-main.py:473-INFO- Average Latency : 45.58171166 ms
2025-03-03 15:53:23,327-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:53:23,327-main.py:76-INFO-Loading dataset:
2025-03-03 15:53:25,365-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-03 15:53:26,236-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:53:26,237-main.py:109-INFO-Loading model:
2025-03-03 15:53:26,238-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:53:26,244-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:53:26,758-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:53:26,759-main.py:466-INFO- * Speed: 24.85855 ms/iter
2025-03-03 15:53:26,759-main.py:467-INFO- * MAPE: 0.75778
2025-03-03 15:53:26,759-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:53:26,759-main.py:469-INFO- * Kendall's Tau: -0.9738562091503269
2025-03-03 15:53:26,759-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:53:26,759-main.py:473-INFO- Average Latency : 23.64038097 ms
2025-03-03 15:56:36,929-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 15:56:36,929-main.py:76-INFO-Loading dataset:
2025-03-03 15:56:39,750-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-03 15:56:40,629-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 15:56:40,629-main.py:109-INFO-Loading model:
2025-03-03 15:56:40,630-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:56:40,636-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 15:56:41,153-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 15:56:41,153-main.py:466-INFO- * Speed: 25.02746 ms/iter
2025-03-03 15:56:41,153-main.py:467-INFO- * MAPE: 0.86954
2025-03-03 15:56:41,153-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 15:56:41,153-main.py:469-INFO- * Kendall's Tau: -0.9477124183006538
2025-03-03 15:56:41,153-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 15:56:41,153-main.py:473-INFO- Average Latency : 23.80941974 ms
2025-03-03 16:00:02,219-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:00:02,220-main.py:76-INFO-Loading dataset:
2025-03-03 16:00:03,768-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-03 16:00:04,642-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:00:04,642-main.py:109-INFO-Loading model:
2025-03-03 16:00:04,643-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:00:04,649-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:00:05,183-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:00:05,183-main.py:466-INFO- * Speed: 31.25186 ms/iter
2025-03-03 16:00:05,183-main.py:467-INFO- * MAPE: 0.83950
2025-03-03 16:00:05,183-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:00:05,183-main.py:469-INFO- * Kendall's Tau: -0.5428571428571429
2025-03-03 16:00:05,183-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:00:05,183-main.py:473-INFO- Average Latency : 28.79350980 ms
2025-03-03 16:02:35,817-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:02:35,817-main.py:76-INFO-Loading dataset:
2025-03-03 16:02:36,325-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-03 16:02:37,215-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:02:37,215-main.py:109-INFO-Loading model:
2025-03-03 16:02:37,216-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:02:37,222-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:02:37,745-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:02:37,745-main.py:466-INFO- * Speed: 30.45041 ms/iter
2025-03-03 16:02:37,745-main.py:467-INFO- * MAPE: 0.43187
2025-03-03 16:02:37,745-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:02:37,745-main.py:469-INFO- * Kendall's Tau: -0.7333333333333334
2025-03-03 16:02:37,745-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:02:37,745-main.py:473-INFO- Average Latency : 27.99194654 ms
2025-03-03 16:05:14,583-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:05:14,583-main.py:76-INFO-Loading dataset:
2025-03-03 16:05:16,169-main.py:274-INFO-Train data = 1, Test data = 20
2025-03-03 16:05:17,059-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:05:17,059-main.py:109-INFO-Loading model:
2025-03-03 16:05:17,060-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:05:17,067-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:05:17,600-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:05:17,600-main.py:466-INFO- * Speed: 23.26380 ms/iter
2025-03-03 16:05:17,600-main.py:467-INFO- * MAPE: 0.71587
2025-03-03 16:05:17,600-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:05:17,600-main.py:469-INFO- * Kendall's Tau: -0.9052631578947369
2025-03-03 16:05:17,600-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:05:17,600-main.py:473-INFO- Average Latency : 21.86847925 ms
2025-03-03 16:16:15,777-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:16:15,777-main.py:76-INFO-Loading dataset:
2025-03-03 16:16:19,858-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-03 16:16:20,880-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:16:20,880-main.py:109-INFO-Loading model:
2025-03-03 16:16:20,881-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:16:20,887-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:16:21,463-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:16:21,464-main.py:466-INFO- * Speed: 57.17468 ms/iter
2025-03-03 16:16:21,464-main.py:467-INFO- * MAPE: 0.75200
2025-03-03 16:16:21,464-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:16:21,464-main.py:469-INFO- * Kendall's Tau: -0.8888888888888888
2025-03-03 16:16:21,464-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:16:21,464-main.py:473-INFO- Average Latency : 56.06725481 ms
2025-03-03 16:22:21,523-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:22:21,523-main.py:76-INFO-Loading dataset:
2025-03-03 16:22:26,716-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-03 16:22:27,732-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:22:27,732-main.py:109-INFO-Loading model:
2025-03-03 16:22:27,733-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:22:27,739-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:22:28,290-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:22:28,290-main.py:466-INFO- * Speed: 28.68672 ms/iter
2025-03-03 16:22:28,290-main.py:467-INFO- * MAPE: 0.84553
2025-03-03 16:22:28,290-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:22:28,290-main.py:469-INFO- * Kendall's Tau: -0.9705882352941175
2025-03-03 16:22:28,290-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:22:28,290-main.py:473-INFO- Average Latency : 27.51413514 ms
2025-03-03 16:27:31,098-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:27:31,098-main.py:76-INFO-Loading dataset:
2025-03-03 16:27:34,430-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-03 16:27:35,310-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:27:35,311-main.py:109-INFO-Loading model:
2025-03-03 16:27:35,311-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:27:35,318-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:27:35,840-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:27:35,841-main.py:466-INFO- * Speed: 25.65244 ms/iter
2025-03-03 16:27:35,841-main.py:467-INFO- * MAPE: 0.60586
2025-03-03 16:27:35,841-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:27:35,841-main.py:469-INFO- * Kendall's Tau: 0.045751633986928116
2025-03-03 16:27:35,841-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:27:35,841-main.py:473-INFO- Average Latency : 24.48961470 ms
2025-03-03 16:30:08,804-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:30:08,804-main.py:76-INFO-Loading dataset:
2025-03-03 16:30:14,408-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-03 16:30:15,476-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:30:15,476-main.py:109-INFO-Loading model:
2025-03-03 16:30:15,477-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:30:15,483-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:30:16,078-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:30:16,078-main.py:466-INFO- * Speed: 31.30704 ms/iter
2025-03-03 16:30:16,078-main.py:467-INFO- * MAPE: 0.82891
2025-03-03 16:30:16,078-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:30:16,078-main.py:469-INFO- * Kendall's Tau: -0.6617647058823529
2025-03-03 16:30:16,079-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:30:16,079-main.py:473-INFO- Average Latency : 30.07590069 ms
2025-03-03 16:32:56,222-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:32:56,222-main.py:76-INFO-Loading dataset:
2025-03-03 16:33:01,407-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-03 16:33:02,494-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:33:02,494-main.py:109-INFO-Loading model:
2025-03-03 16:33:02,495-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:33:02,501-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:33:02,996-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:33:02,996-main.py:466-INFO- * Speed: 25.51920 ms/iter
2025-03-03 16:33:02,996-main.py:467-INFO- * MAPE: 0.84679
2025-03-03 16:33:02,996-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:33:02,996-main.py:469-INFO- * Kendall's Tau: -0.8970588235294118
2025-03-03 16:33:02,996-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:33:02,996-main.py:473-INFO- Average Latency : 24.22944237 ms
2025-03-03 16:36:37,938-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:36:37,938-main.py:76-INFO-Loading dataset:
2025-03-03 16:36:49,144-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-03 16:36:50,060-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:36:50,061-main.py:109-INFO-Loading model:
2025-03-03 16:36:50,062-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:36:50,068-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:36:50,562-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:36:50,562-main.py:466-INFO- * Speed: 25.48267 ms/iter
2025-03-03 16:36:50,562-main.py:467-INFO- * MAPE: 0.89179
2025-03-03 16:36:50,562-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:36:50,562-main.py:469-INFO- * Kendall's Tau: -0.7794117647058824
2025-03-03 16:36:50,562-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:36:50,562-main.py:473-INFO- Average Latency : 24.36876297 ms
2025-03-03 16:41:38,869-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:41:38,869-main.py:76-INFO-Loading dataset:
2025-03-03 16:41:45,507-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-03 16:41:46,457-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:41:46,458-main.py:109-INFO-Loading model:
2025-03-03 16:41:46,458-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:41:46,465-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:41:46,973-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:41:46,974-main.py:466-INFO- * Speed: 26.41815 ms/iter
2025-03-03 16:41:46,974-main.py:467-INFO- * MAPE: 0.80077
2025-03-03 16:41:46,974-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:41:46,974-main.py:469-INFO- * Kendall's Tau: -0.9852941176470588
2025-03-03 16:41:46,974-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:41:46,974-main.py:473-INFO- Average Latency : 25.18693139 ms
2025-03-03 16:45:25,706-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:45:25,707-main.py:76-INFO-Loading dataset:
2025-03-03 16:45:27,332-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-03 16:45:28,198-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:45:28,198-main.py:109-INFO-Loading model:
2025-03-03 16:45:28,199-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:45:28,205-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:45:28,713-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:45:28,713-main.py:466-INFO- * Speed: 26.22334 ms/iter
2025-03-03 16:45:28,713-main.py:467-INFO- * MAPE: 0.47104
2025-03-03 16:45:28,713-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:45:28,713-main.py:469-INFO- * Kendall's Tau: -0.9411764705882352
2025-03-03 16:45:28,713-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:45:28,713-main.py:473-INFO- Average Latency : 25.05086450 ms
2025-03-03 16:46:50,234-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:46:50,235-main.py:76-INFO-Loading dataset:
2025-03-03 16:46:55,002-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-03 16:46:56,026-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:46:56,027-main.py:109-INFO-Loading model:
2025-03-03 16:46:56,028-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:46:56,034-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:46:56,634-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:46:56,634-main.py:466-INFO- * Speed: 31.69619 ms/iter
2025-03-03 16:46:56,634-main.py:467-INFO- * MAPE: 0.81661
2025-03-03 16:46:56,634-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:46:56,634-main.py:469-INFO- * Kendall's Tau: -0.926470588235294
2025-03-03 16:46:56,634-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:46:56,634-main.py:473-INFO- Average Latency : 30.40629275 ms
2025-03-03 16:48:54,159-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-03 16:48:54,160-main.py:76-INFO-Loading dataset:
2025-03-03 16:48:58,595-main.py:274-INFO-Train data = 1, Test data = 14
2025-03-03 16:48:59,539-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-03 16:48:59,540-main.py:109-INFO-Loading model:
2025-03-03 16:48:59,541-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:48:59,547-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-03 16:49:00,089-main.py:465-INFO- ------------------------------------------------------------------
2025-03-03 16:49:00,089-main.py:466-INFO- * Speed: 34.34341 ms/iter
2025-03-03 16:49:00,089-main.py:467-INFO- * MAPE: 0.86332
2025-03-03 16:49:00,089-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-03 16:49:00,089-main.py:469-INFO- * Kendall's Tau: -0.28729720245711154
2025-03-03 16:49:00,089-main.py:470-INFO- ------------------------------------------------------------------
2025-03-03 16:49:00,089-main.py:473-INFO- Average Latency : 33.00373895 ms
2025-03-04 12:54:23,496-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 12:54:23,497-main.py:76-INFO-Loading dataset:
2025-03-04 12:54:28,770-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-04 12:54:29,825-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 12:54:29,826-main.py:109-INFO-Loading model:
2025-03-04 12:54:29,827-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 12:54:29,848-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 12:54:30,926-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 12:54:30,926-main.py:466-INFO- * Speed: 53.83385 ms/iter
2025-03-04 12:54:30,926-main.py:467-INFO- * MAPE: 0.84760
2025-03-04 12:54:30,926-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 12:54:30,926-main.py:469-INFO- * Kendall's Tau: -0.9558823529411764
2025-03-04 12:54:30,926-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 12:54:30,927-main.py:473-INFO- Average Latency : 52.12800643 ms
2025-03-04 13:02:53,937-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:02:53,938-main.py:76-INFO-Loading dataset:
2025-03-04 13:02:59,634-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-04 13:03:00,581-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:03:00,581-main.py:109-INFO-Loading model:
2025-03-04 13:03:00,582-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:03:00,589-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:03:01,176-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:03:01,176-main.py:466-INFO- * Speed: 30.82705 ms/iter
2025-03-04 13:03:01,176-main.py:467-INFO- * MAPE: 0.83012
2025-03-04 13:03:01,176-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 13:03:01,176-main.py:469-INFO- * Kendall's Tau: -0.7499999999999999
2025-03-04 13:03:01,176-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:03:01,177-main.py:473-INFO- Average Latency : 29.54418519 ms
2025-03-04 13:12:21,156-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:12:21,156-main.py:76-INFO-Loading dataset:
2025-03-04 13:12:26,385-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-04 13:12:27,310-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:12:27,310-main.py:109-INFO-Loading model:
2025-03-04 13:12:27,311-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:12:27,317-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:12:27,944-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:12:27,945-main.py:466-INFO- * Speed: 31.95848 ms/iter
2025-03-04 13:12:27,945-main.py:467-INFO- * MAPE: 0.84540
2025-03-04 13:12:27,945-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 13:12:27,945-main.py:469-INFO- * Kendall's Tau: -0.9705882352941175
2025-03-04 13:12:27,945-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:12:27,945-main.py:473-INFO- Average Latency : 30.78201238 ms
2025-03-04 13:15:33,452-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:15:33,452-main.py:76-INFO-Loading dataset:
2025-03-04 13:15:39,655-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-04 13:15:40,718-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:15:40,719-main.py:109-INFO-Loading model:
2025-03-04 13:15:40,720-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:15:40,726-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:15:41,230-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:15:41,230-main.py:466-INFO- * Speed: 26.05552 ms/iter
2025-03-04 13:15:41,230-main.py:467-INFO- * MAPE: 0.68591
2025-03-04 13:15:41,231-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 13:15:41,231-main.py:469-INFO- * Kendall's Tau: -0.30882352941176466
2025-03-04 13:15:41,231-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:15:41,231-main.py:473-INFO- Average Latency : 24.78441070 ms
2025-03-04 13:17:48,350-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:17:48,351-main.py:76-INFO-Loading dataset:
2025-03-04 13:17:58,214-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-04 13:17:59,074-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:17:59,075-main.py:109-INFO-Loading model:
2025-03-04 13:17:59,076-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:17:59,082-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:17:59,627-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:17:59,627-main.py:466-INFO- * Speed: 28.27539 ms/iter
2025-03-04 13:17:59,627-main.py:467-INFO- * MAPE: 0.82288
2025-03-04 13:17:59,627-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 13:17:59,627-main.py:469-INFO- * Kendall's Tau: -0.8529411764705882
2025-03-04 13:17:59,627-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:17:59,628-main.py:473-INFO- Average Latency : 26.92231010 ms
2025-03-04 13:26:24,075-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:26:24,075-main.py:76-INFO-Loading dataset:
2025-03-04 13:26:28,510-main.py:274-INFO-Train data = 1, Test data = 14
2025-03-04 13:26:29,615-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:26:29,615-main.py:109-INFO-Loading model:
2025-03-04 13:26:29,616-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:26:29,623-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:26:30,218-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:26:30,218-main.py:466-INFO- * Speed: 38.05164 ms/iter
2025-03-04 13:26:30,218-main.py:467-INFO- * MAPE: 0.86332
2025-03-04 13:26:30,218-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 13:26:30,219-main.py:469-INFO- * Kendall's Tau: -0.28729720245711154
2025-03-04 13:26:30,219-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:26:30,219-main.py:473-INFO- Average Latency : 36.55157770 ms
2025-03-04 13:35:33,087-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:35:33,087-main.py:76-INFO-Loading dataset:
2025-03-04 13:35:37,652-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-04 13:35:38,612-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:35:38,612-main.py:109-INFO-Loading model:
2025-03-04 13:35:38,613-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:35:38,621-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:35:39,226-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:35:39,226-main.py:466-INFO- * Speed: 59.83080 ms/iter
2025-03-04 13:35:39,226-main.py:467-INFO- * MAPE: 0.79483
2025-03-04 13:35:39,227-main.py:468-INFO- * ErrorBound: [0.11111111 0.11111111 0.        ]
2025-03-04 13:35:39,227-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-03-04 13:35:39,227-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:35:39,227-main.py:473-INFO- Average Latency : 58.27524927 ms
2025-03-04 13:39:56,883-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:39:56,884-main.py:76-INFO-Loading dataset:
2025-03-04 13:39:57,964-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 13:39:58,814-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:39:58,815-main.py:109-INFO-Loading model:
2025-03-04 13:39:58,816-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:39:58,822-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:39:59,341-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:39:59,342-main.py:466-INFO- * Speed: 25.40697 ms/iter
2025-03-04 13:39:59,342-main.py:467-INFO- * MAPE: 0.54320
2025-03-04 13:39:59,342-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 13:39:59,342-main.py:469-INFO- * Kendall's Tau: -0.9477124183006538
2025-03-04 13:39:59,342-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:39:59,342-main.py:473-INFO- Average Latency : 24.07364051 ms
2025-03-04 13:43:13,405-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:43:13,406-main.py:76-INFO-Loading dataset:
2025-03-04 13:43:13,411-main.py:274-INFO-Train data = 0, Test data = 0
2025-03-04 13:45:08,477-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:45:08,478-main.py:76-INFO-Loading dataset:
2025-03-04 13:45:08,484-main.py:274-INFO-Train data = 0, Test data = 0
2025-03-04 13:46:26,756-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 13:46:26,757-main.py:76-INFO-Loading dataset:
2025-03-04 13:46:28,297-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 13:46:29,166-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 13:46:29,166-main.py:109-INFO-Loading model:
2025-03-04 13:46:29,167-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:46:29,174-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 13:46:29,696-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 13:46:29,696-main.py:466-INFO- * Speed: 25.36676 ms/iter
2025-03-04 13:46:29,696-main.py:467-INFO- * MAPE: 0.47658
2025-03-04 13:46:29,696-main.py:468-INFO- * ErrorBound: [0.16666667 0.05555556 0.        ]
2025-03-04 13:46:29,696-main.py:469-INFO- * Kendall's Tau: -0.5555555555555556
2025-03-04 13:46:29,696-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 13:46:29,696-main.py:473-INFO- Average Latency : 23.97778299 ms
2025-03-04 14:03:21,378-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:03:21,379-main.py:76-INFO-Loading dataset:
2025-03-04 14:03:26,226-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-04 14:03:27,228-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:03:27,229-main.py:109-INFO-Loading model:
2025-03-04 14:03:27,230-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:03:27,236-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:03:27,802-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:03:27,802-main.py:466-INFO- * Speed: 56.18310 ms/iter
2025-03-04 14:03:27,802-main.py:467-INFO- * MAPE: 0.78580
2025-03-04 14:03:27,802-main.py:468-INFO- * ErrorBound: [0.11111111 0.11111111 0.        ]
2025-03-04 14:03:27,803-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-03-04 14:03:27,803-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:03:27,803-main.py:473-INFO- Average Latency : 54.73868052 ms
2025-03-04 14:06:50,763-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:06:50,763-main.py:76-INFO-Loading dataset:
2025-03-04 14:06:51,713-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 14:06:52,570-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:06:52,571-main.py:109-INFO-Loading model:
2025-03-04 14:06:52,572-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:06:52,578-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:06:53,093-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:06:53,093-main.py:466-INFO- * Speed: 25.12970 ms/iter
2025-03-04 14:06:53,093-main.py:467-INFO- * MAPE: 0.49767
2025-03-04 14:06:53,094-main.py:468-INFO- * ErrorBound: [0.05555556 0.         0.        ]
2025-03-04 14:06:53,094-main.py:469-INFO- * Kendall's Tau: -1.0
2025-03-04 14:06:53,094-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:06:53,094-main.py:473-INFO- Average Latency : 23.79633321 ms
2025-03-04 14:09:34,583-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:09:34,583-main.py:76-INFO-Loading dataset:
2025-03-04 14:09:37,472-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 14:09:38,333-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:09:38,334-main.py:109-INFO-Loading model:
2025-03-04 14:09:38,335-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:09:38,342-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:09:38,999-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:09:38,999-main.py:466-INFO- * Speed: 33.12908 ms/iter
2025-03-04 14:09:38,999-main.py:467-INFO- * MAPE: 0.79663
2025-03-04 14:09:39,000-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:09:39,000-main.py:469-INFO- * Kendall's Tau: -0.6862745098039217
2025-03-04 14:09:39,000-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:09:39,000-main.py:473-INFO- Average Latency : 31.85134464 ms
2025-03-04 14:11:34,142-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:11:34,142-main.py:76-INFO-Loading dataset:
2025-03-04 14:11:34,692-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 14:11:35,559-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:11:35,559-main.py:109-INFO-Loading model:
2025-03-04 14:11:35,560-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:11:35,567-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:11:36,042-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:11:36,043-main.py:466-INFO- * Speed: 51.57635 ms/iter
2025-03-04 14:11:36,043-main.py:467-INFO- * MAPE: 0.75399
2025-03-04 14:11:36,043-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:11:36,043-main.py:469-INFO- * Kendall's Tau: -0.14285714285714285
2025-03-04 14:11:36,043-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:11:36,043-main.py:473-INFO- Average Latency : 50.32628775 ms
2025-03-04 14:13:19,407-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:13:19,408-main.py:76-INFO-Loading dataset:
2025-03-04 14:13:26,779-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-04 14:13:27,724-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:13:27,725-main.py:109-INFO-Loading model:
2025-03-04 14:13:27,726-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:13:27,732-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:13:28,253-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:13:28,253-main.py:466-INFO- * Speed: 49.72789 ms/iter
2025-03-04 14:13:28,253-main.py:467-INFO- * MAPE: 0.91386
2025-03-04 14:13:28,253-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:13:28,253-main.py:469-INFO- * Kendall's Tau: -0.8888888888888888
2025-03-04 14:13:28,254-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:13:28,254-main.py:473-INFO- Average Latency : 48.10410076 ms
2025-03-04 14:15:18,927-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:15:18,928-main.py:76-INFO-Loading dataset:
2025-03-04 14:15:20,113-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 14:15:20,974-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:15:20,975-main.py:109-INFO-Loading model:
2025-03-04 14:15:20,976-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:15:20,982-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:15:21,515-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:15:21,516-main.py:466-INFO- * Speed: 26.21566 ms/iter
2025-03-04 14:15:21,516-main.py:467-INFO- * MAPE: 0.60630
2025-03-04 14:15:21,516-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:15:21,516-main.py:469-INFO- * Kendall's Tau: -0.934640522875817
2025-03-04 14:15:21,516-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:15:21,516-main.py:473-INFO- Average Latency : 24.88210466 ms
2025-03-04 14:18:18,518-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:18:18,518-main.py:76-INFO-Loading dataset:
2025-03-04 14:18:22,330-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-04 14:18:23,404-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:18:23,404-main.py:109-INFO-Loading model:
2025-03-04 14:18:23,405-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:18:23,412-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:18:24,035-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:18:24,036-main.py:466-INFO- * Speed: 60.65909 ms/iter
2025-03-04 14:18:24,037-main.py:467-INFO- * MAPE: 0.75919
2025-03-04 14:18:24,037-main.py:468-INFO- * ErrorBound: [0.11111111 0.11111111 0.11111111]
2025-03-04 14:18:24,037-main.py:469-INFO- * Kendall's Tau: -0.9444444444444445
2025-03-04 14:18:24,037-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:18:24,037-main.py:473-INFO- Average Latency : 58.99288919 ms
2025-03-04 14:20:08,568-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:20:08,568-main.py:76-INFO-Loading dataset:
2025-03-04 14:20:10,014-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 14:20:10,875-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:20:10,876-main.py:109-INFO-Loading model:
2025-03-04 14:20:10,877-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:20:10,883-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:20:11,426-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:20:11,426-main.py:466-INFO- * Speed: 26.73954 ms/iter
2025-03-04 14:20:11,426-main.py:467-INFO- * MAPE: 0.72003
2025-03-04 14:20:11,426-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:20:11,427-main.py:469-INFO- * Kendall's Tau: -0.9084967320261439
2025-03-04 14:20:11,427-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:20:11,427-main.py:473-INFO- Average Latency : 25.35065015 ms
2025-03-04 14:27:51,035-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:27:51,035-main.py:76-INFO-Loading dataset:
2025-03-04 14:28:00,509-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-04 14:28:01,393-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:28:01,394-main.py:109-INFO-Loading model:
2025-03-04 14:28:01,395-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:28:01,402-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:28:01,919-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:28:01,919-main.py:466-INFO- * Speed: 50.59028 ms/iter
2025-03-04 14:28:01,919-main.py:467-INFO- * MAPE: 0.94355
2025-03-04 14:28:01,920-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:28:01,920-main.py:469-INFO- * Kendall's Tau: -0.8888888888888888
2025-03-04 14:28:01,920-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:28:01,920-main.py:473-INFO- Average Latency : 49.25701353 ms
2025-03-04 14:33:27,820-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:33:27,820-main.py:76-INFO-Loading dataset:
2025-03-04 14:33:32,011-main.py:274-INFO-Train data = 1, Test data = 19
2025-03-04 14:33:33,098-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:33:33,099-main.py:109-INFO-Loading model:
2025-03-04 14:33:33,100-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:33:33,106-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:33:33,772-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:33:33,772-main.py:466-INFO- * Speed: 31.82869 ms/iter
2025-03-04 14:33:33,772-main.py:467-INFO- * MAPE: 0.89712
2025-03-04 14:33:33,772-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:33:33,772-main.py:469-INFO- * Kendall's Tau: -1.0
2025-03-04 14:33:33,772-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:33:33,772-main.py:473-INFO- Average Latency : 30.51279721 ms
2025-03-04 14:37:19,713-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:37:19,713-main.py:76-INFO-Loading dataset:
2025-03-04 14:37:28,376-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 14:37:29,283-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:37:29,283-main.py:109-INFO-Loading model:
2025-03-04 14:37:29,284-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:37:29,290-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:37:29,773-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:37:29,773-main.py:466-INFO- * Speed: 52.28904 ms/iter
2025-03-04 14:37:29,774-main.py:467-INFO- * MAPE: 0.95190
2025-03-04 14:37:29,774-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:37:29,774-main.py:469-INFO- * Kendall's Tau: -0.5714285714285714
2025-03-04 14:37:29,774-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:37:29,774-main.py:473-INFO- Average Latency : 50.53904653 ms
2025-03-04 14:39:35,802-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:39:35,802-main.py:76-INFO-Loading dataset:
2025-03-04 14:39:41,786-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 14:39:42,780-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:39:42,780-main.py:109-INFO-Loading model:
2025-03-04 14:39:42,781-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:39:42,788-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:39:43,464-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:39:43,464-main.py:466-INFO- * Speed: 34.08031 ms/iter
2025-03-04 14:39:43,464-main.py:467-INFO- * MAPE: 0.91737
2025-03-04 14:39:43,464-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:39:43,464-main.py:469-INFO- * Kendall's Tau: 0.30718954248366015
2025-03-04 14:39:43,465-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:39:43,465-main.py:473-INFO- Average Latency : 32.55090449 ms
2025-03-04 14:42:30,636-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:42:30,636-main.py:76-INFO-Loading dataset:
2025-03-04 14:42:30,641-main.py:274-INFO-Train data = 0, Test data = 0
2025-03-04 14:42:47,885-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:42:47,886-main.py:76-INFO-Loading dataset:
2025-03-04 14:42:57,542-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 14:42:58,444-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:42:58,444-main.py:109-INFO-Loading model:
2025-03-04 14:42:58,445-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:42:58,452-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:42:58,941-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:42:58,941-main.py:466-INFO- * Speed: 53.30288 ms/iter
2025-03-04 14:42:58,941-main.py:467-INFO- * MAPE: 0.94238
2025-03-04 14:42:58,941-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:42:58,941-main.py:469-INFO- * Kendall's Tau: -0.6428571428571428
2025-03-04 14:42:58,942-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:42:58,942-main.py:473-INFO- Average Latency : 51.55271292 ms
2025-03-04 14:45:28,018-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:45:28,019-main.py:76-INFO-Loading dataset:
2025-03-04 14:45:32,998-main.py:274-INFO-Train data = 1, Test data = 24
2025-03-04 14:45:34,107-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:45:34,108-main.py:109-INFO-Loading model:
2025-03-04 14:45:34,109-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:45:34,115-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:45:34,768-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:45:34,768-main.py:466-INFO- * Speed: 24.46642 ms/iter
2025-03-04 14:45:34,768-main.py:467-INFO- * MAPE: 0.88039
2025-03-04 14:45:34,768-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:45:34,768-main.py:469-INFO- * Kendall's Tau: -0.39855072463768115
2025-03-04 14:45:34,769-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:45:34,769-main.py:473-INFO- Average Latency : 22.81706532 ms
2025-03-04 14:49:23,573-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:49:23,573-main.py:76-INFO-Loading dataset:
2025-03-04 14:49:33,833-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 14:49:34,766-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:49:34,767-main.py:109-INFO-Loading model:
2025-03-04 14:49:34,768-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:49:34,775-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:49:35,261-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:49:35,261-main.py:466-INFO- * Speed: 52.33070 ms/iter
2025-03-04 14:49:35,261-main.py:467-INFO- * MAPE: 0.96136
2025-03-04 14:49:35,261-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:49:35,261-main.py:469-INFO- * Kendall's Tau: -0.7857142857142856
2025-03-04 14:49:35,261-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:49:35,262-main.py:473-INFO- Average Latency : 51.08064413 ms
2025-03-04 14:50:53,399-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:50:53,399-main.py:76-INFO-Loading dataset:
2025-03-04 14:51:00,283-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 14:51:01,144-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:51:01,144-main.py:109-INFO-Loading model:
2025-03-04 14:51:01,145-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:51:01,151-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:51:01,747-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:51:01,748-main.py:466-INFO- * Speed: 65.53972 ms/iter
2025-03-04 14:51:01,748-main.py:467-INFO- * MAPE: 0.91026
2025-03-04 14:51:01,748-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:51:01,748-main.py:469-INFO- * Kendall's Tau: -0.9285714285714285
2025-03-04 14:51:01,748-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:51:01,748-main.py:473-INFO- Average Latency : 63.91477585 ms
2025-03-04 14:53:42,386-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:53:42,386-main.py:76-INFO-Loading dataset:
2025-03-04 14:53:47,257-main.py:274-INFO-Train data = 1, Test data = 24
2025-03-04 14:53:48,191-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:53:48,192-main.py:109-INFO-Loading model:
2025-03-04 14:53:48,193-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:53:48,199-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:53:48,827-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:53:48,828-main.py:466-INFO- * Speed: 23.59557 ms/iter
2025-03-04 14:53:48,828-main.py:467-INFO- * MAPE: 0.88136
2025-03-04 14:53:48,828-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:53:48,828-main.py:469-INFO- * Kendall's Tau: -1.0
2025-03-04 14:53:48,828-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:53:48,828-main.py:473-INFO- Average Latency : 22.26214608 ms
2025-03-04 14:56:34,319-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:56:34,319-main.py:76-INFO-Loading dataset:
2025-03-04 14:56:38,593-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 14:56:39,550-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:56:39,551-main.py:109-INFO-Loading model:
2025-03-04 14:56:39,552-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:56:39,558-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:56:40,110-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:56:40,110-main.py:466-INFO- * Speed: 61.28344 ms/iter
2025-03-04 14:56:40,110-main.py:467-INFO- * MAPE: 0.91040
2025-03-04 14:56:40,110-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:56:40,110-main.py:469-INFO- * Kendall's Tau: -0.9999999999999998
2025-03-04 14:56:40,110-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:56:40,110-main.py:473-INFO- Average Latency : 59.78351831 ms
2025-03-04 14:59:40,367-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 14:59:40,368-main.py:76-INFO-Loading dataset:
2025-03-04 14:59:42,915-main.py:274-INFO-Train data = 1, Test data = 24
2025-03-04 14:59:43,776-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 14:59:43,776-main.py:109-INFO-Loading model:
2025-03-04 14:59:43,777-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:59:43,784-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 14:59:44,387-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 14:59:44,387-main.py:466-INFO- * Speed: 22.13719 ms/iter
2025-03-04 14:59:44,387-main.py:467-INFO- * MAPE: 0.86363
2025-03-04 14:59:44,387-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 14:59:44,387-main.py:469-INFO- * Kendall's Tau: -0.9130434782608696
2025-03-04 14:59:44,387-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 14:59:44,387-main.py:473-INFO- Average Latency : 20.59574922 ms
2025-03-04 15:11:09,089-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:11:09,089-main.py:76-INFO-Loading dataset:
2025-03-04 15:11:18,250-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 15:11:19,181-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:11:19,182-main.py:109-INFO-Loading model:
2025-03-04 15:11:19,183-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:11:19,202-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:11:20,160-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:11:20,160-main.py:466-INFO- * Speed: 101.59376 ms/iter
2025-03-04 15:11:20,160-main.py:467-INFO- * MAPE: 0.94264
2025-03-04 15:11:20,160-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:11:20,160-main.py:469-INFO- * Kendall's Tau: -0.9999999999999998
2025-03-04 15:11:20,160-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:11:20,160-main.py:473-INFO- Average Latency : 99.34309125 ms
2025-03-04 15:14:21,931-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:14:21,931-main.py:76-INFO-Loading dataset:
2025-03-04 15:14:24,503-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-04 15:14:25,370-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:14:25,370-main.py:109-INFO-Loading model:
2025-03-04 15:14:25,371-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:14:25,378-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:14:25,892-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:14:25,893-main.py:466-INFO- * Speed: 30.09421 ms/iter
2025-03-04 15:14:25,893-main.py:467-INFO- * MAPE: 0.89765
2025-03-04 15:14:25,893-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:14:25,893-main.py:469-INFO- * Kendall's Tau: -0.9047619047619049
2025-03-04 15:14:25,893-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:14:25,893-main.py:473-INFO- Average Latency : 28.73338064 ms
2025-03-04 15:19:24,288-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:19:24,289-main.py:76-INFO-Loading dataset:
2025-03-04 15:19:35,076-main.py:274-INFO-Train data = 1, Test data = 7
2025-03-04 15:19:35,961-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:19:35,968-main.py:109-INFO-Loading model:
2025-03-04 15:19:35,969-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:19:35,989-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:19:36,952-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:19:36,953-main.py:466-INFO- * Speed: 116.51901 ms/iter
2025-03-04 15:19:36,953-main.py:467-INFO- * MAPE: 0.94665
2025-03-04 15:19:36,953-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:19:36,953-main.py:469-INFO- * Kendall's Tau: -0.5238095238095238
2025-03-04 15:19:36,953-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:19:36,953-main.py:473-INFO- Average Latency : 113.80478314 ms
2025-03-04 15:25:13,126-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:25:13,126-main.py:76-INFO-Loading dataset:
2025-03-04 15:25:18,161-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 15:25:19,254-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:25:19,254-main.py:109-INFO-Loading model:
2025-03-04 15:25:19,255-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:25:19,261-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:25:19,889-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:25:19,889-main.py:466-INFO- * Speed: 31.34516 ms/iter
2025-03-04 15:25:19,890-main.py:467-INFO- * MAPE: 0.91317
2025-03-04 15:25:19,890-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:25:19,890-main.py:469-INFO- * Kendall's Tau: -0.9607843137254903
2025-03-04 15:25:19,890-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:25:19,890-main.py:473-INFO- Average Latency : 29.95075120 ms
2025-03-04 15:29:39,665-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:29:39,666-main.py:76-INFO-Loading dataset:
2025-03-04 15:29:57,771-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 15:29:58,721-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:29:58,722-main.py:109-INFO-Loading model:
2025-03-04 15:29:58,723-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:29:58,751-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:29:59,679-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:29:59,679-main.py:466-INFO- * Speed: 98.26934 ms/iter
2025-03-04 15:29:59,680-main.py:467-INFO- * MAPE: 0.95176
2025-03-04 15:29:59,680-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:29:59,680-main.py:469-INFO- * Kendall's Tau: -0.4999999999999999
2025-03-04 15:29:59,680-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:29:59,680-main.py:473-INFO- Average Latency : 95.39416432 ms
2025-03-04 15:32:17,546-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:32:17,546-main.py:76-INFO-Loading dataset:
2025-03-04 15:32:21,089-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-04 15:32:22,116-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:32:22,116-main.py:109-INFO-Loading model:
2025-03-04 15:32:22,117-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:32:22,124-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:32:22,666-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:32:22,666-main.py:466-INFO- * Speed: 28.19311 ms/iter
2025-03-04 15:32:22,666-main.py:467-INFO- * MAPE: 0.89492
2025-03-04 15:32:22,666-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:32:22,666-main.py:469-INFO- * Kendall's Tau: -0.926470588235294
2025-03-04 15:32:22,666-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:32:22,666-main.py:473-INFO- Average Latency : 26.89897313 ms
2025-03-04 15:36:18,294-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:36:18,295-main.py:76-INFO-Loading dataset:
2025-03-04 15:36:32,485-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 15:36:33,363-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:36:33,364-main.py:109-INFO-Loading model:
2025-03-04 15:36:33,364-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:36:33,383-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:36:34,309-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:36:34,309-main.py:466-INFO- * Speed: 98.09351 ms/iter
2025-03-04 15:36:34,309-main.py:467-INFO- * MAPE: 0.94367
2025-03-04 15:36:34,309-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:36:34,309-main.py:469-INFO- * Kendall's Tau: -0.9285714285714285
2025-03-04 15:36:34,309-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:36:34,309-main.py:473-INFO- Average Latency : 95.34344077 ms
2025-03-04 15:39:20,773-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:39:20,774-main.py:76-INFO-Loading dataset:
2025-03-04 15:39:25,886-main.py:274-INFO-Train data = 1, Test data = 24
2025-03-04 15:39:26,917-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:39:26,917-main.py:109-INFO-Loading model:
2025-03-04 15:39:26,918-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:39:26,924-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:39:27,522-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:39:27,522-main.py:466-INFO- * Speed: 21.56166 ms/iter
2025-03-04 15:39:27,522-main.py:467-INFO- * MAPE: 0.88993
2025-03-04 15:39:27,523-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:39:27,523-main.py:469-INFO- * Kendall's Tau: -0.9420289855072465
2025-03-04 15:39:27,523-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:39:27,523-main.py:473-INFO- Average Latency : 20.14504870 ms
2025-03-04 15:53:20,619-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:53:20,619-main.py:76-INFO-Loading dataset:
2025-03-04 15:54:41,653-main.py:274-INFO-Train data = 1, Test data = 31
2025-03-04 15:54:43,143-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:54:43,143-main.py:109-INFO-Loading model:
2025-03-04 15:54:43,144-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:54:43,167-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:54:44,291-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 15:54:44,292-main.py:466-INFO- * Speed: 31.44202 ms/iter
2025-03-04 15:54:44,292-main.py:467-INFO- * MAPE: 0.96385
2025-03-04 15:54:44,292-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 15:54:44,292-main.py:469-INFO- * Kendall's Tau: -0.48817204301075273
2025-03-04 15:54:44,292-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 15:54:44,292-main.py:473-INFO- Average Latency : 29.50653722 ms
2025-03-04 15:59:36,750-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 15:59:36,759-main.py:76-INFO-Loading dataset:
2025-03-04 15:59:58,236-main.py:274-INFO-Train data = 1, Test data = 31
2025-03-04 15:59:59,128-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 15:59:59,129-main.py:109-INFO-Loading model:
2025-03-04 15:59:59,130-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 15:59:59,149-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:00:00,188-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 16:00:00,188-main.py:466-INFO- * Speed: 28.88835 ms/iter
2025-03-04 16:00:00,188-main.py:467-INFO- * MAPE: 0.91597
2025-03-04 16:00:00,188-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 16:00:00,188-main.py:469-INFO- * Kendall's Tau: -0.9784946236559141
2025-03-04 16:00:00,188-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 16:00:00,188-main.py:473-INFO- Average Latency : 27.21094316 ms
2025-03-04 16:38:48,871-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 16:38:48,871-main.py:76-INFO-Loading dataset:
2025-03-04 16:38:51,690-main.py:274-INFO-Train data = 1, Test data = 7
2025-03-04 16:38:52,583-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 16:38:52,583-main.py:109-INFO-Loading model:
2025-03-04 16:38:52,584-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:38:52,591-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:38:53,193-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 16:38:53,193-main.py:466-INFO- * Speed: 76.23533 ms/iter
2025-03-04 16:38:53,193-main.py:467-INFO- * MAPE: 0.90018
2025-03-04 16:38:53,193-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 16:38:53,193-main.py:469-INFO- * Kendall's Tau: -0.5238095238095238
2025-03-04 16:38:53,193-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 16:38:53,193-main.py:473-INFO- Average Latency : 74.66404779 ms
2025-03-04 16:41:43,916-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 16:41:43,916-main.py:76-INFO-Loading dataset:
2025-03-04 16:41:45,479-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-04 16:41:46,362-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 16:41:46,363-main.py:109-INFO-Loading model:
2025-03-04 16:41:46,364-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:41:46,370-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:41:46,886-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 16:41:46,887-main.py:466-INFO- * Speed: 25.25679 ms/iter
2025-03-04 16:41:46,887-main.py:467-INFO- * MAPE: 0.82813
2025-03-04 16:41:46,887-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 16:41:46,887-main.py:469-INFO- * Kendall's Tau: -0.9869281045751636
2025-03-04 16:41:46,887-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 16:41:46,887-main.py:473-INFO- Average Latency : 24.09011788 ms
2025-03-04 16:46:54,633-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 16:46:54,634-main.py:76-INFO-Loading dataset:
2025-03-04 16:46:54,638-main.py:274-INFO-Train data = 0, Test data = 0
2025-03-04 16:47:06,285-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 16:47:06,285-main.py:76-INFO-Loading dataset:
2025-03-04 16:47:09,800-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 16:47:10,746-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 16:47:10,747-main.py:109-INFO-Loading model:
2025-03-04 16:47:10,747-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:47:10,754-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:47:11,324-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 16:47:11,324-main.py:466-INFO- * Speed: 63.55608 ms/iter
2025-03-04 16:47:11,324-main.py:467-INFO- * MAPE: 0.93054
2025-03-04 16:47:11,325-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 16:47:11,325-main.py:469-INFO- * Kendall's Tau: -0.4999999999999999
2025-03-04 16:47:11,325-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 16:47:11,325-main.py:473-INFO- Average Latency : 61.93113327 ms
2025-03-04 16:49:00,919-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 16:49:00,919-main.py:76-INFO-Loading dataset:
2025-03-04 16:49:02,291-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-04 16:49:03,175-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 16:49:03,176-main.py:109-INFO-Loading model:
2025-03-04 16:49:03,177-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:49:03,184-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:49:03,705-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 16:49:03,705-main.py:466-INFO- * Speed: 26.72810 ms/iter
2025-03-04 16:49:03,705-main.py:467-INFO- * MAPE: 0.83930
2025-03-04 16:49:03,705-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 16:49:03,705-main.py:469-INFO- * Kendall's Tau: -0.20588235294117643
2025-03-04 16:49:03,705-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 16:49:03,705-main.py:473-INFO- Average Latency : 25.37518389 ms
2025-03-04 16:52:31,446-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 16:52:31,447-main.py:76-INFO-Loading dataset:
2025-03-04 16:52:34,944-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 16:52:35,833-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 16:52:35,834-main.py:109-INFO-Loading model:
2025-03-04 16:52:35,835-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:52:35,841-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:52:36,332-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 16:52:36,333-main.py:466-INFO- * Speed: 53.71383 ms/iter
2025-03-04 16:52:36,333-main.py:467-INFO- * MAPE: 0.91508
2025-03-04 16:52:36,333-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 16:52:36,333-main.py:469-INFO- * Kendall's Tau: -0.6428571428571428
2025-03-04 16:52:36,333-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 16:52:36,333-main.py:473-INFO- Average Latency : 52.33880877 ms
2025-03-04 16:55:30,436-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 16:55:30,436-main.py:76-INFO-Loading dataset:
2025-03-04 16:55:33,460-main.py:274-INFO-Train data = 1, Test data = 24
2025-03-04 16:55:34,360-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 16:55:34,360-main.py:109-INFO-Loading model:
2025-03-04 16:55:34,361-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:55:34,368-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 16:55:34,972-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 16:55:34,972-main.py:466-INFO- * Speed: 22.63447 ms/iter
2025-03-04 16:55:34,972-main.py:467-INFO- * MAPE: 0.81964
2025-03-04 16:55:34,972-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 16:55:34,972-main.py:469-INFO- * Kendall's Tau: -0.43478260869565216
2025-03-04 16:55:34,972-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 16:55:34,972-main.py:473-INFO- Average Latency : 21.15502954 ms
2025-03-04 17:04:29,303-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 17:04:29,304-main.py:76-INFO-Loading dataset:
2025-03-04 17:04:33,995-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 17:04:35,057-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 17:04:35,057-main.py:109-INFO-Loading model:
2025-03-04 17:04:35,058-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:04:35,065-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:04:35,635-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 17:04:35,635-main.py:466-INFO- * Speed: 63.60981 ms/iter
2025-03-04 17:04:35,635-main.py:467-INFO- * MAPE: 0.95961
2025-03-04 17:04:35,635-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 17:04:35,635-main.py:469-INFO- * Kendall's Tau: -0.9999999999999998
2025-03-04 17:04:35,635-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 17:04:35,635-main.py:473-INFO- Average Latency : 61.98480725 ms
2025-03-04 17:05:30,557-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 17:05:30,558-main.py:76-INFO-Loading dataset:
2025-03-04 17:05:32,846-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 17:05:33,719-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 17:05:33,720-main.py:109-INFO-Loading model:
2025-03-04 17:05:33,721-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:05:33,728-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:05:34,210-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 17:05:34,210-main.py:466-INFO- * Speed: 52.35958 ms/iter
2025-03-04 17:05:34,210-main.py:467-INFO- * MAPE: 0.89015
2025-03-04 17:05:34,210-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 17:05:34,210-main.py:469-INFO- * Kendall's Tau: -0.9999999999999998
2025-03-04 17:05:34,210-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 17:05:34,210-main.py:473-INFO- Average Latency : 50.60961843 ms
2025-03-04 17:07:24,527-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 17:07:24,527-main.py:76-INFO-Loading dataset:
2025-03-04 17:07:25,521-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-04 17:07:26,409-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 17:07:26,410-main.py:109-INFO-Loading model:
2025-03-04 17:07:26,411-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:07:26,418-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:07:26,933-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 17:07:26,933-main.py:466-INFO- * Speed: 29.78981 ms/iter
2025-03-04 17:07:26,933-main.py:467-INFO- * MAPE: 0.77804
2025-03-04 17:07:26,933-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 17:07:26,933-main.py:469-INFO- * Kendall's Tau: -0.9428571428571428
2025-03-04 17:07:26,933-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 17:07:26,933-main.py:473-INFO- Average Latency : 28.52328618 ms
2025-03-04 17:10:56,237-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 17:10:56,237-main.py:76-INFO-Loading dataset:
2025-03-04 17:10:58,249-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-04 17:10:59,115-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 17:10:59,116-main.py:109-INFO-Loading model:
2025-03-04 17:10:59,117-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:10:59,123-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:10:59,598-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 17:10:59,598-main.py:466-INFO- * Speed: 51.45285 ms/iter
2025-03-04 17:10:59,598-main.py:467-INFO- * MAPE: 0.85320
2025-03-04 17:10:59,598-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 17:10:59,598-main.py:469-INFO- * Kendall's Tau: -0.9999999999999998
2025-03-04 17:10:59,598-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 17:10:59,598-main.py:473-INFO- Average Latency : 50.32789707 ms
2025-03-04 17:12:42,328-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-04 17:12:42,328-main.py:76-INFO-Loading dataset:
2025-03-04 17:12:43,225-main.py:274-INFO-Train data = 1, Test data = 16
2025-03-04 17:12:44,091-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-04 17:12:44,092-main.py:109-INFO-Loading model:
2025-03-04 17:12:44,092-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:12:44,100-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-04 17:12:44,619-main.py:465-INFO- ------------------------------------------------------------------
2025-03-04 17:12:44,619-main.py:466-INFO- * Speed: 28.28844 ms/iter
2025-03-04 17:12:44,619-main.py:467-INFO- * MAPE: 0.72101
2025-03-04 17:12:44,619-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-04 17:12:44,619-main.py:469-INFO- * Kendall's Tau: -0.9
2025-03-04 17:12:44,619-main.py:470-INFO- ------------------------------------------------------------------
2025-03-04 17:12:44,619-main.py:473-INFO- Average Latency : 27.03845501 ms
2025-03-05 13:24:52,891-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:24:52,892-main.py:76-INFO-Loading dataset:
2025-03-05 13:24:59,086-main.py:274-INFO-Train data = 0, Test data = 8
2025-03-05 13:25:13,109-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:25:13,109-main.py:76-INFO-Loading dataset:
2025-03-05 13:25:19,193-main.py:274-INFO-Train data = 1, Test data = 7
2025-03-05 13:25:20,206-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:25:20,207-main.py:109-INFO-Loading model:
2025-03-05 13:25:20,208-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:25:20,228-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:25:21,258-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:25:21,258-main.py:466-INFO- * Speed: 123.58185 ms/iter
2025-03-05 13:25:21,259-main.py:467-INFO- * MAPE: 0.88577
2025-03-05 13:25:21,259-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:25:21,259-main.py:469-INFO- * Kendall's Tau: -0.8095238095238096
2025-03-05 13:25:21,259-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:25:21,259-main.py:473-INFO- Average Latency : 120.43898446 ms
2025-03-05 13:31:40,219-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:31:40,220-main.py:76-INFO-Loading dataset:
2025-03-05 13:31:43,175-main.py:274-INFO-Train data = 1, Test data = 11
2025-03-05 13:31:44,072-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:31:44,073-main.py:109-INFO-Loading model:
2025-03-05 13:31:44,074-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:31:44,082-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:31:44,607-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:31:44,607-main.py:466-INFO- * Speed: 41.93742 ms/iter
2025-03-05 13:31:44,607-main.py:467-INFO- * MAPE: 0.87183
2025-03-05 13:31:44,607-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:31:44,607-main.py:469-INFO- * Kendall's Tau: 0.0909090909090909
2025-03-05 13:31:44,607-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:31:44,607-main.py:473-INFO- Average Latency : 40.57383537 ms
2025-03-05 13:35:20,437-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:35:20,445-main.py:76-INFO-Loading dataset:
2025-03-05 13:35:29,610-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 13:35:30,509-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:35:30,509-main.py:109-INFO-Loading model:
2025-03-05 13:35:30,510-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:35:30,516-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:35:31,024-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:35:31,024-main.py:466-INFO- * Speed: 55.37498 ms/iter
2025-03-05 13:35:31,024-main.py:467-INFO- * MAPE: 0.89998
2025-03-05 13:35:31,024-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:35:31,024-main.py:469-INFO- * Kendall's Tau: -0.7857142857142856
2025-03-05 13:35:31,024-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:35:31,025-main.py:473-INFO- Average Latency : 53.99996042 ms
2025-03-05 13:38:18,579-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:38:18,579-main.py:76-INFO-Loading dataset:
2025-03-05 13:38:24,631-main.py:274-INFO-Train data = 1, Test data = 16
2025-03-05 13:38:25,518-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:38:25,518-main.py:109-INFO-Loading model:
2025-03-05 13:38:25,519-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:38:25,525-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:38:26,063-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:38:26,063-main.py:466-INFO- * Speed: 29.45821 ms/iter
2025-03-05 13:38:26,063-main.py:467-INFO- * MAPE: 0.85580
2025-03-05 13:38:26,064-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:38:26,064-main.py:469-INFO- * Kendall's Tau: -0.8166666666666667
2025-03-05 13:38:26,064-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:38:26,064-main.py:473-INFO- Average Latency : 27.98277140 ms
2025-03-05 13:41:31,846-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:41:31,846-main.py:76-INFO-Loading dataset:
2025-03-05 13:41:39,518-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 13:41:40,553-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:41:40,554-main.py:109-INFO-Loading model:
2025-03-05 13:41:40,554-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:41:40,561-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:41:41,150-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:41:41,151-main.py:466-INFO- * Speed: 65.98696 ms/iter
2025-03-05 13:41:41,151-main.py:467-INFO- * MAPE: 0.89761
2025-03-05 13:41:41,151-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:41:41,151-main.py:469-INFO- * Kendall's Tau: -0.7142857142857142
2025-03-05 13:41:41,151-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:41:41,151-main.py:473-INFO- Average Latency : 64.40937519 ms
2025-03-05 13:44:42,871-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:44:42,871-main.py:76-INFO-Loading dataset:
2025-03-05 13:44:47,548-main.py:274-INFO-Train data = 1, Test data = 24
2025-03-05 13:44:48,481-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:44:48,482-main.py:109-INFO-Loading model:
2025-03-05 13:44:48,483-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:44:48,489-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:44:49,175-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:44:49,175-main.py:466-INFO- * Speed: 25.80357 ms/iter
2025-03-05 13:44:49,175-main.py:467-INFO- * MAPE: 0.80206
2025-03-05 13:44:49,175-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:44:49,175-main.py:469-INFO- * Kendall's Tau: -0.8840579710144928
2025-03-05 13:44:49,175-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:44:49,175-main.py:473-INFO- Average Latency : 24.38691258 ms
2025-03-05 13:49:33,636-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:49:33,637-main.py:76-INFO-Loading dataset:
2025-03-05 13:49:41,094-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 13:49:42,115-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:49:42,116-main.py:109-INFO-Loading model:
2025-03-05 13:49:42,117-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:49:42,123-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:49:42,716-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:49:42,716-main.py:466-INFO- * Speed: 66.32498 ms/iter
2025-03-05 13:49:42,717-main.py:467-INFO- * MAPE: 0.89549
2025-03-05 13:49:42,717-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:49:42,717-main.py:469-INFO- * Kendall's Tau: -0.7142857142857142
2025-03-05 13:49:42,717-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:49:42,717-main.py:473-INFO- Average Latency : 65.19439816 ms
2025-03-05 13:52:06,479-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:52:06,479-main.py:76-INFO-Loading dataset:
2025-03-05 13:52:11,513-main.py:274-INFO-Train data = 1, Test data = 19
2025-03-05 13:52:12,577-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:52:12,578-main.py:109-INFO-Loading model:
2025-03-05 13:52:12,578-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:52:12,586-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:52:13,169-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:52:13,169-main.py:466-INFO- * Speed: 27.41794 ms/iter
2025-03-05 13:52:13,169-main.py:467-INFO- * MAPE: 0.85711
2025-03-05 13:52:13,169-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:52:13,169-main.py:469-INFO- * Kendall's Tau: -0.5321637426900584
2025-03-05 13:52:13,169-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:52:13,170-main.py:473-INFO- Average Latency : 25.83896486 ms
2025-03-05 13:56:42,998-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 13:56:42,999-main.py:76-INFO-Loading dataset:
2025-03-05 13:56:49,667-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 13:56:50,747-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 13:56:50,748-main.py:109-INFO-Loading model:
2025-03-05 13:56:50,749-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:56:50,755-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 13:56:51,274-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 13:56:51,274-main.py:466-INFO- * Speed: 57.12491 ms/iter
2025-03-05 13:56:51,274-main.py:467-INFO- * MAPE: 0.90443
2025-03-05 13:56:51,275-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 13:56:51,275-main.py:469-INFO- * Kendall's Tau: -0.9285714285714285
2025-03-05 13:56:51,275-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 13:56:51,275-main.py:473-INFO- Average Latency : 55.62528968 ms
2025-03-05 14:00:21,344-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:00:21,344-main.py:76-INFO-Loading dataset:
2025-03-05 14:00:23,444-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-05 14:00:24,308-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:00:24,309-main.py:109-INFO-Loading model:
2025-03-05 14:00:24,310-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:00:24,316-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:00:24,832-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:00:24,832-main.py:466-INFO- * Speed: 26.68412 ms/iter
2025-03-05 14:00:24,832-main.py:467-INFO- * MAPE: 0.84657
2025-03-05 14:00:24,832-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:00:24,832-main.py:469-INFO- * Kendall's Tau: -0.14705882352941174
2025-03-05 14:00:24,833-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:00:24,833-main.py:473-INFO- Average Latency : 25.27248158 ms
2025-03-05 14:20:37,608-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:20:37,608-main.py:76-INFO-Loading dataset:
2025-03-05 14:20:39,460-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 14:20:40,332-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:20:40,333-main.py:109-INFO-Loading model:
2025-03-05 14:20:40,334-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:20:40,340-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:20:40,820-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:20:40,820-main.py:466-INFO- * Speed: 52.02520 ms/iter
2025-03-05 14:20:40,820-main.py:467-INFO- * MAPE: 0.74820
2025-03-05 14:20:40,820-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:20:40,820-main.py:469-INFO- * Kendall's Tau: -0.8571428571428571
2025-03-05 14:20:40,821-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:20:40,821-main.py:473-INFO- Average Latency : 50.64997077 ms
2025-03-05 14:23:03,954-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/lamp.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:23:03,954-main.py:76-INFO-Loading dataset:
2025-03-05 14:23:04,626-main.py:274-INFO-Train data = 1, Test data = 17
2025-03-05 14:23:05,503-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:23:05,503-main.py:109-INFO-Loading model:
2025-03-05 14:23:05,504-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:23:05,511-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:23:06,028-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:23:06,029-main.py:466-INFO- * Speed: 26.72738 ms/iter
2025-03-05 14:23:06,029-main.py:467-INFO- * MAPE: 0.53214
2025-03-05 14:23:06,029-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:23:06,029-main.py:469-INFO- * Kendall's Tau: -0.48529411764705876
2025-03-05 14:23:06,029-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:23:06,029-main.py:473-INFO- Average Latency : 25.19826328 ms
2025-03-05 14:25:27,689-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:25:27,690-main.py:76-INFO-Loading dataset:
2025-03-05 14:25:29,772-main.py:274-INFO-Train data = 1, Test data = 7
2025-03-05 14:25:30,638-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:25:30,639-main.py:109-INFO-Loading model:
2025-03-05 14:25:30,639-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:25:30,646-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:25:31,117-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:25:31,117-main.py:466-INFO- * Speed: 58.08680 ms/iter
2025-03-05 14:25:31,117-main.py:467-INFO- * MAPE: 0.68760
2025-03-05 14:25:31,117-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:25:31,117-main.py:469-INFO- * Kendall's Tau: -0.6190476190476191
2025-03-05 14:25:31,117-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:25:31,118-main.py:473-INFO- Average Latency : 56.65782520 ms
2025-03-05 14:28:15,225-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:28:15,225-main.py:76-INFO-Loading dataset:
2025-03-05 14:28:16,739-main.py:274-INFO-Train data = 1, Test data = 19
2025-03-05 14:28:17,596-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:28:17,596-main.py:109-INFO-Loading model:
2025-03-05 14:28:17,597-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:28:17,603-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:28:18,124-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:28:18,124-main.py:466-INFO- * Speed: 24.14156 ms/iter
2025-03-05 14:28:18,124-main.py:467-INFO- * MAPE: 0.56177
2025-03-05 14:28:18,124-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:28:18,124-main.py:469-INFO- * Kendall's Tau: -0.2982456140350877
2025-03-05 14:28:18,125-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:28:18,125-main.py:473-INFO- Average Latency : 22.77314036 ms
2025-03-05 14:30:50,743-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/FPGM.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:30:50,743-main.py:76-INFO-Loading dataset:
2025-03-05 14:30:50,749-main.py:274-INFO-Train data = 0, Test data = 0
2025-03-05 14:30:59,446-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:30:59,446-main.py:76-INFO-Loading dataset:
2025-03-05 14:31:02,431-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 14:31:03,295-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:31:03,296-main.py:109-INFO-Loading model:
2025-03-05 14:31:03,297-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:31:03,303-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:31:03,915-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:31:03,915-main.py:466-INFO- * Speed: 66.49014 ms/iter
2025-03-05 14:31:03,915-main.py:467-INFO- * MAPE: 0.79457
2025-03-05 14:31:03,915-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:31:03,916-main.py:469-INFO- * Kendall's Tau: -0.7142857142857142
2025-03-05 14:31:03,916-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:31:03,916-main.py:473-INFO- Average Latency : 64.98989463 ms
2025-03-05 14:49:55,136-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Greg.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:49:55,137-main.py:76-INFO-Loading dataset:
2025-03-05 14:49:55,467-main.py:274-INFO-Train data = 1, Test data = 18
2025-03-05 14:49:56,328-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:49:56,329-main.py:109-INFO-Loading model:
2025-03-05 14:49:56,330-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:49:56,336-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:49:56,871-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:49:56,871-main.py:466-INFO- * Speed: 26.12944 ms/iter
2025-03-05 14:49:56,871-main.py:467-INFO- * MAPE: 0.71102
2025-03-05 14:49:56,871-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:49:56,871-main.py:469-INFO- * Kendall's Tau: -0.8157894736842107
2025-03-05 14:49:56,871-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:49:56,872-main.py:473-INFO- Average Latency : 24.57389567 ms
2025-03-05 14:52:08,529-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:52:08,529-main.py:76-INFO-Loading dataset:
2025-03-05 14:52:11,675-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 14:52:12,545-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:52:12,546-main.py:109-INFO-Loading model:
2025-03-05 14:52:12,547-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:52:12,553-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:52:13,149-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:52:13,149-main.py:466-INFO- * Speed: 66.76567 ms/iter
2025-03-05 14:52:13,150-main.py:467-INFO- * MAPE: 0.86002
2025-03-05 14:52:13,150-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:52:13,150-main.py:469-INFO- * Kendall's Tau: -0.7142857142857142
2025-03-05 14:52:13,150-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:52:13,151-main.py:473-INFO- Average Latency : 65.51560760 ms
2025-03-05 14:55:20,298-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 14:55:20,298-main.py:76-INFO-Loading dataset:
2025-03-05 14:55:23,714-main.py:274-INFO-Train data = 1, Test data = 24
2025-03-05 14:55:24,579-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 14:55:24,579-main.py:109-INFO-Loading model:
2025-03-05 14:55:24,580-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:55:24,586-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 14:55:25,241-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 14:55:25,241-main.py:466-INFO- * Speed: 24.61627 ms/iter
2025-03-05 14:55:25,241-main.py:467-INFO- * MAPE: 0.73585
2025-03-05 14:55:25,241-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 14:55:25,241-main.py:469-INFO- * Kendall's Tau: 0.10869565217391304
2025-03-05 14:55:25,242-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 14:55:25,242-main.py:473-INFO- Average Latency : 23.24132125 ms
2025-03-05 15:03:06,839-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:03:06,839-main.py:76-INFO-Loading dataset:
2025-03-05 15:03:07,200-main.py:274-INFO-Train data = 1, Test data = 9
2025-03-05 15:03:08,066-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:03:08,067-main.py:109-INFO-Loading model:
2025-03-05 15:03:08,068-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:03:08,074-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:03:08,551-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:03:08,551-main.py:466-INFO- * Speed: 46.16237 ms/iter
2025-03-05 15:03:08,551-main.py:467-INFO- * MAPE: 0.46453
2025-03-05 15:03:08,552-main.py:468-INFO- * ErrorBound: [0.22222222 0.22222222 0.22222222]
2025-03-05 15:03:08,552-main.py:469-INFO- * Kendall's Tau: 0.030949223029508643
2025-03-05 15:03:08,552-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:03:08,552-main.py:473-INFO- Average Latency : 44.82875930 ms
2025-03-05 15:05:20,547-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:05:20,547-main.py:76-INFO-Loading dataset:
2025-03-05 15:05:22,896-main.py:274-INFO-Train data = 1, Test data = 11
2025-03-05 15:05:23,771-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:05:23,771-main.py:109-INFO-Loading model:
2025-03-05 15:05:23,772-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:05:23,779-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:05:24,269-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:05:24,269-main.py:466-INFO- * Speed: 38.94721 ms/iter
2025-03-05 15:05:24,269-main.py:467-INFO- * MAPE: 0.67861
2025-03-05 15:05:24,269-main.py:468-INFO- * ErrorBound: [0.18181818 0.18181818 0.18181818]
2025-03-05 15:05:24,269-main.py:469-INFO- * Kendall's Tau: -0.8118990304530631
2025-03-05 15:05:24,270-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:05:24,270-main.py:473-INFO- Average Latency : 37.58397969 ms
2025-03-05 15:07:23,794-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:07:23,794-main.py:76-INFO-Loading dataset:
2025-03-05 15:07:24,938-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-05 15:07:25,826-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:07:25,826-main.py:109-INFO-Loading model:
2025-03-05 15:07:25,827-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:07:25,833-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:07:26,334-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:07:26,334-main.py:466-INFO- * Speed: 29.30643 ms/iter
2025-03-05 15:07:26,334-main.py:467-INFO- * MAPE: 0.59154
2025-03-05 15:07:26,335-main.py:468-INFO- * ErrorBound: [0.13333333 0.13333333 0.13333333]
2025-03-05 15:07:26,335-main.py:469-INFO- * Kendall's Tau: -0.6250288943852585
2025-03-05 15:07:26,335-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:07:26,335-main.py:473-INFO- Average Latency : 27.97311147 ms
2025-03-05 15:10:03,811-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:10:03,811-main.py:76-INFO-Loading dataset:
2025-03-05 15:10:03,817-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-05 15:10:04,691-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:10:04,691-main.py:109-INFO-Loading model:
2025-03-05 15:10:04,692-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:10:04,698-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:10:05,209-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:10:05,209-main.py:466-INFO- * Speed: 30.12185 ms/iter
2025-03-05 15:10:05,209-main.py:467-INFO- * MAPE: 0.59154
2025-03-05 15:10:05,210-main.py:468-INFO- * ErrorBound: [0.13333333 0.13333333 0.13333333]
2025-03-05 15:10:05,210-main.py:469-INFO- * Kendall's Tau: -0.6250288943852585
2025-03-05 15:10:05,210-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:10:05,210-main.py:473-INFO- Average Latency : 28.72184118 ms
2025-03-05 15:10:16,643-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-L1.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:10:16,643-main.py:76-INFO-Loading dataset:
2025-03-05 15:10:17,797-main.py:274-INFO-Train data = 1, Test data = 15
2025-03-05 15:10:18,662-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:10:18,663-main.py:109-INFO-Loading model:
2025-03-05 15:10:18,663-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:10:18,669-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:10:19,171-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:10:19,171-main.py:466-INFO- * Speed: 29.25998 ms/iter
2025-03-05 15:10:19,171-main.py:467-INFO- * MAPE: 0.59154
2025-03-05 15:10:19,171-main.py:468-INFO- * ErrorBound: [0.13333333 0.13333333 0.13333333]
2025-03-05 15:10:19,171-main.py:469-INFO- * Kendall's Tau: -0.6250288943852585
2025-03-05 15:10:19,171-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:10:19,172-main.py:473-INFO- Average Latency : 28.12665304 ms
2025-03-05 15:12:31,267-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:12:31,267-main.py:76-INFO-Loading dataset:
2025-03-05 15:12:35,337-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 15:12:36,416-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:12:36,416-main.py:109-INFO-Loading model:
2025-03-05 15:12:36,417-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:12:36,423-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:12:37,026-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:12:37,027-main.py:466-INFO- * Speed: 66.53324 ms/iter
2025-03-05 15:12:37,027-main.py:467-INFO- * MAPE: 0.89106
2025-03-05 15:12:37,027-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 15:12:37,027-main.py:469-INFO- * Kendall's Tau: 0.21428571428571427
2025-03-05 15:12:37,027-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:12:37,027-main.py:473-INFO- Average Latency : 65.28353691 ms
2025-03-05 15:13:25,267-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:13:25,267-main.py:76-INFO-Loading dataset:
2025-03-05 15:13:27,583-main.py:274-INFO-Train data = 1, Test data = 8
2025-03-05 15:13:28,499-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:13:28,499-main.py:109-INFO-Loading model:
2025-03-05 15:13:28,500-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:13:28,506-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:13:28,976-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:13:28,976-main.py:466-INFO- * Speed: 51.12502 ms/iter
2025-03-05 15:13:28,977-main.py:467-INFO- * MAPE: 0.73381
2025-03-05 15:13:28,977-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 15:13:28,977-main.py:469-INFO- * Kendall's Tau: -0.7857142857142856
2025-03-05 15:13:28,977-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:13:28,977-main.py:473-INFO- Average Latency : 49.74991083 ms
2025-03-05 15:25:44,423-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/Group-Pruner.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset6/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-03-05 15:25:44,424-main.py:76-INFO-Loading dataset:
2025-03-05 15:25:44,978-main.py:274-INFO-Train data = 1, Test data = 16
2025-03-05 15:25:45,850-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-03-05 15:25:45,850-main.py:109-INFO-Loading model:
2025-03-05 15:25:45,851-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:25:45,858-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-03-05 15:25:46,384-main.py:465-INFO- ------------------------------------------------------------------
2025-03-05 15:25:46,384-main.py:466-INFO- * Speed: 29.10332 ms/iter
2025-03-05 15:25:46,384-main.py:467-INFO- * MAPE: 0.53101
2025-03-05 15:25:46,385-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-03-05 15:25:46,385-main.py:469-INFO- * Kendall's Tau: 0.6166666666666666
2025-03-05 15:25:46,385-main.py:470-INFO- ------------------------------------------------------------------
2025-03-05 15:25:46,385-main.py:473-INFO- Average Latency : 27.66579390 ms
2025-04-25 12:13:24,524-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/deepseek.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-25 12:13:24,525-main.py:76-INFO-Loading dataset:
2025-04-25 12:13:24,943-main.py:274-INFO-Train data = 1, Test data = 12
2025-04-25 12:13:26,302-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-25 12:13:26,302-main.py:109-INFO-Loading model:
2025-04-25 12:13:26,303-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-25 12:13:26,325-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-25 12:14:48,206-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/deepseek.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-25 12:14:48,206-main.py:76-INFO-Loading dataset:
2025-04-25 12:14:48,212-main.py:274-INFO-Train data = 1, Test data = 12
2025-04-25 12:14:49,066-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-25 12:14:49,067-main.py:109-INFO-Loading model:
2025-04-25 12:14:49,068-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-25 12:14:49,074-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-25 12:14:49,563-main.py:465-INFO- ------------------------------------------------------------------
2025-04-25 12:14:49,563-main.py:466-INFO- * Speed: 35.69100 ms/iter
2025-04-25 12:14:49,563-main.py:467-INFO- * MAPE: 3.45109
2025-04-25 12:14:49,564-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-25 12:14:49,564-main.py:469-INFO- * Kendall's Tau: -0.1515151515151515
2025-04-25 12:14:49,564-main.py:470-INFO- ------------------------------------------------------------------
2025-04-25 12:14:49,564-main.py:473-INFO- Average Latency : 34.10158555 ms
2025-04-25 12:16:09,746-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-25 12:16:09,746-main.py:76-INFO-Loading dataset:
2025-04-25 12:16:13,632-main.py:274-INFO-Train data = 1, Test data = 7
2025-04-25 12:16:14,606-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-25 12:16:14,606-main.py:109-INFO-Loading model:
2025-04-25 12:16:14,607-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-25 12:16:14,613-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-25 12:16:15,206-main.py:465-INFO- ------------------------------------------------------------------
2025-04-25 12:16:15,206-main.py:466-INFO- * Speed: 72.45592 ms/iter
2025-04-25 12:16:15,206-main.py:467-INFO- * MAPE: 1.05773
2025-04-25 12:16:15,206-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-25 12:16:15,207-main.py:469-INFO- * Kendall's Tau: -0.23809523809523814
2025-04-25 12:16:15,207-main.py:470-INFO- ------------------------------------------------------------------
2025-04-25 12:16:15,207-main.py:473-INFO- Average Latency : 70.88450023 ms
2025-04-26 11:45:46,022-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-26 11:45:46,022-main.py:76-INFO-Loading dataset:
2025-04-26 11:45:46,091-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-26 11:45:47,461-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-26 11:45:47,461-main.py:109-INFO-Loading model:
2025-04-26 11:45:47,462-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-26 11:45:47,484-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-26 11:45:48,375-main.py:465-INFO- ------------------------------------------------------------------
2025-04-26 11:45:48,375-main.py:466-INFO- * Speed: 743.78800 ms/iter
2025-04-26 11:45:48,375-main.py:467-INFO- * MAPE: 0.95213
2025-04-26 11:45:48,375-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-26 11:45:48,375-main.py:469-INFO- * Kendall's Tau: nan
2025-04-26 11:45:48,376-main.py:470-INFO- ------------------------------------------------------------------
2025-04-26 11:45:48,376-main.py:473-INFO- Average Latency : 728.83725166 ms
2025-04-26 12:52:52,070-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-26 12:52:52,071-main.py:76-INFO-Loading dataset:
2025-04-26 12:52:52,130-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-26 12:52:53,002-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-26 12:52:53,003-main.py:109-INFO-Loading model:
2025-04-26 12:52:53,004-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:52:53,011-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:52:53,480-main.py:465-INFO- ------------------------------------------------------------------
2025-04-26 12:52:53,480-main.py:466-INFO- * Speed: 407.32718 ms/iter
2025-04-26 12:52:53,480-main.py:467-INFO- * MAPE: 0.95213
2025-04-26 12:52:53,480-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-26 12:52:53,480-main.py:469-INFO- * Kendall's Tau: nan
2025-04-26 12:52:53,480-main.py:470-INFO- ------------------------------------------------------------------
2025-04-26 12:52:53,481-main.py:473-INFO- Average Latency : 404.33692932 ms
2025-04-26 12:53:37,598-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-26 12:53:37,599-main.py:76-INFO-Loading dataset:
2025-04-26 12:53:37,640-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-26 12:53:38,511-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-26 12:53:38,512-main.py:109-INFO-Loading model:
2025-04-26 12:53:38,513-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:53:38,519-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:53:38,978-main.py:465-INFO- ------------------------------------------------------------------
2025-04-26 12:53:38,978-main.py:466-INFO- * Speed: 395.49112 ms/iter
2025-04-26 12:53:38,979-main.py:467-INFO- * MAPE: 0.93983
2025-04-26 12:53:38,979-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-26 12:53:38,979-main.py:469-INFO- * Kendall's Tau: nan
2025-04-26 12:53:38,979-main.py:470-INFO- ------------------------------------------------------------------
2025-04-26 12:53:38,979-main.py:473-INFO- Average Latency : 392.50159264 ms
2025-04-26 12:54:44,817-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-26 12:54:44,817-main.py:76-INFO-Loading dataset:
2025-04-26 12:54:44,858-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-26 12:54:45,713-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-26 12:54:45,714-main.py:109-INFO-Loading model:
2025-04-26 12:54:45,714-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:54:45,721-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:54:46,168-main.py:465-INFO- ------------------------------------------------------------------
2025-04-26 12:54:46,168-main.py:466-INFO- * Speed: 386.46770 ms/iter
2025-04-26 12:54:46,168-main.py:467-INFO- * MAPE: 0.93980
2025-04-26 12:54:46,168-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-26 12:54:46,168-main.py:469-INFO- * Kendall's Tau: nan
2025-04-26 12:54:46,168-main.py:470-INFO- ------------------------------------------------------------------
2025-04-26 12:54:46,169-main.py:473-INFO- Average Latency : 383.47792625 ms
2025-04-26 12:57:19,355-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-26 12:57:19,355-main.py:76-INFO-Loading dataset:
2025-04-26 12:57:19,396-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-26 12:57:22,822-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-26 12:57:22,824-main.py:109-INFO-Loading model:
2025-04-26 12:57:22,825-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:57:22,847-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-26 12:57:24,713-main.py:465-INFO- ------------------------------------------------------------------
2025-04-26 12:57:24,713-main.py:466-INFO- * Speed: 1500.92673 ms/iter
2025-04-26 12:57:24,713-main.py:467-INFO- * MAPE: 0.90417
2025-04-26 12:57:24,714-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-26 12:57:24,714-main.py:469-INFO- * Kendall's Tau: nan
2025-04-26 12:57:24,714-main.py:470-INFO- ------------------------------------------------------------------
2025-04-26 12:57:24,714-main.py:473-INFO- Average Latency : 1494.96603012 ms
2025-04-27 23:23:14,421-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-27 23:23:14,422-main.py:76-INFO-Loading dataset:
2025-04-27 23:23:14,481-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-27 23:23:15,950-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-27 23:23:15,951-main.py:109-INFO-Loading model:
2025-04-27 23:23:15,952-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-27 23:23:15,974-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-27 23:23:16,944-main.py:465-INFO- ------------------------------------------------------------------
2025-04-27 23:23:16,944-main.py:466-INFO- * Speed: 818.45188 ms/iter
2025-04-27 23:23:16,944-main.py:467-INFO- * MAPE: 0.29016
2025-04-27 23:23:16,945-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-27 23:23:16,945-main.py:469-INFO- * Kendall's Tau: nan
2025-04-27 23:23:16,945-main.py:470-INFO- ------------------------------------------------------------------
2025-04-27 23:23:16,945-main.py:473-INFO- Average Latency : 802.46925354 ms
2025-04-29 14:56:42,381-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-29 14:56:42,382-main.py:76-INFO-Loading dataset:
2025-04-29 14:56:42,452-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-29 14:56:43,861-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-29 15:04:27,794-main.py:109-INFO-Loading model:
2025-04-29 15:04:27,795-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-29 15:04:27,845-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-29 15:04:28,858-main.py:465-INFO- ------------------------------------------------------------------
2025-04-29 15:04:28,858-main.py:466-INFO- * Speed: 808.75492 ms/iter
2025-04-29 15:04:28,858-main.py:467-INFO- * MAPE: 0.00430
2025-04-29 15:04:28,858-main.py:468-INFO- * ErrorBound: [1. 1. 1.]
2025-04-29 15:04:28,858-main.py:469-INFO- * Kendall's Tau: nan
2025-04-29 15:04:28,859-main.py:470-INFO- ------------------------------------------------------------------
2025-04-29 15:04:28,859-main.py:473-INFO- Average Latency : 794.15464401 ms
2025-04-29 16:17:42,745-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-04-29 16:17:42,745-main.py:76-INFO-Loading dataset:
2025-04-29 16:17:42,815-main.py:274-INFO-Train data = 1, Test data = 1
2025-04-29 16:17:43,677-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-04-29 16:17:43,677-main.py:109-INFO-Loading model:
2025-04-29 16:17:43,678-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-04-29 16:17:43,685-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-04-29 16:17:44,130-main.py:465-INFO- ------------------------------------------------------------------
2025-04-29 16:17:44,130-main.py:466-INFO- * Speed: 382.60603 ms/iter
2025-04-29 16:17:44,130-main.py:467-INFO- * MAPE: 0.13769
2025-04-29 16:17:44,130-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-04-29 16:17:44,130-main.py:469-INFO- * Kendall's Tau: nan
2025-04-29 16:17:44,130-main.py:470-INFO- ------------------------------------------------------------------
2025-04-29 16:17:44,131-main.py:473-INFO- Average Latency : 378.60631943 ms
2025-05-07 13:05:09,915-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-07 13:05:09,916-main.py:76-INFO-Loading dataset:
2025-05-07 13:05:10,240-main.py:274-INFO-Train data = 1, Test data = 4
2025-05-07 13:05:11,416-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-07 13:05:11,417-main.py:109-INFO-Loading model:
2025-05-07 13:05:11,418-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-07 13:05:11,439-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-07 13:05:12,131-main.py:465-INFO- ------------------------------------------------------------------
2025-05-07 13:05:12,131-main.py:466-INFO- * Speed: 148.93854 ms/iter
2025-05-07 13:05:12,132-main.py:467-INFO- * MAPE: 0.34420
2025-05-07 13:05:12,132-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-07 13:05:12,132-main.py:469-INFO- * Kendall's Tau: nan
2025-05-07 13:05:12,132-main.py:470-INFO- ------------------------------------------------------------------
2025-05-07 13:05:12,132-main.py:473-INFO- Average Latency : 145.68847418 ms
2025-05-07 13:06:25,329-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-07 13:06:25,330-main.py:76-INFO-Loading dataset:
2025-05-07 13:06:25,593-main.py:274-INFO-Train data = 1, Test data = 4
2025-05-07 13:06:26,764-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-07 13:06:26,765-main.py:109-INFO-Loading model:
2025-05-07 13:06:26,766-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-07 13:06:26,776-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-07 13:06:27,440-main.py:465-INFO- ------------------------------------------------------------------
2025-05-07 13:06:27,440-main.py:466-INFO- * Speed: 139.02295 ms/iter
2025-05-07 13:06:27,440-main.py:467-INFO- * MAPE: 1.43771
2025-05-07 13:06:27,440-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-07 13:06:27,440-main.py:469-INFO- * Kendall's Tau: 0.3333333333333334
2025-05-07 13:06:27,441-main.py:470-INFO- ------------------------------------------------------------------
2025-05-07 13:06:27,441-main.py:473-INFO- Average Latency : 135.77288389 ms
2025-05-12 01:33:54,601-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-12 01:33:54,601-main.py:76-INFO-Loading dataset:
2025-05-12 01:33:55,321-main.py:274-INFO-Train data = 0, Test data = 7
2025-05-12 01:34:19,368-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-12 01:34:19,368-main.py:76-INFO-Loading dataset:
2025-05-12 01:34:46,214-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-12 01:34:46,214-main.py:76-INFO-Loading dataset:
2025-05-12 01:34:46,911-main.py:274-INFO-Train data = 1, Test data = 6
2025-05-12 01:34:48,498-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-12 01:34:48,498-main.py:109-INFO-Loading model:
2025-05-12 01:34:48,499-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-12 01:34:48,528-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-12 01:34:49,660-main.py:465-INFO- ------------------------------------------------------------------
2025-05-12 01:34:49,660-main.py:466-INFO- * Speed: 162.64474 ms/iter
2025-05-12 01:34:49,660-main.py:467-INFO- * MAPE: 1.12820
2025-05-12 01:34:49,661-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-12 01:34:49,661-main.py:469-INFO- * Kendall's Tau: 0.3333333333333333
2025-05-12 01:34:49,661-main.py:470-INFO- ------------------------------------------------------------------
2025-05-12 01:34:49,661-main.py:473-INFO- Average Latency : 157.81144301 ms
2025-05-13 14:27:32,392-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-13 14:27:32,393-main.py:76-INFO-Loading dataset:
2025-05-13 14:27:34,003-main.py:274-INFO-Train data = 1, Test data = 4
2025-05-13 14:27:35,405-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-13 14:27:35,406-main.py:109-INFO-Loading model:
2025-05-13 14:27:35,407-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-13 14:27:35,430-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-13 14:27:36,527-main.py:465-INFO- ------------------------------------------------------------------
2025-05-13 14:27:36,527-main.py:466-INFO- * Speed: 238.62034 ms/iter
2025-05-13 14:27:36,527-main.py:467-INFO- * MAPE: 0.43549
2025-05-13 14:27:36,528-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-13 14:27:36,528-main.py:469-INFO- * Kendall's Tau: 0.0
2025-05-13 14:27:36,528-main.py:470-INFO- ------------------------------------------------------------------
2025-05-13 14:27:36,528-main.py:473-INFO- Average Latency : 231.39470816 ms
2025-05-15 03:59:43,526-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-15 03:59:43,527-main.py:76-INFO-Loading dataset:
2025-05-15 03:59:46,558-main.py:274-INFO-Train data = 1, Test data = 8
2025-05-15 03:59:47,914-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-15 03:59:47,915-main.py:109-INFO-Loading model:
2025-05-15 03:59:47,916-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-15 03:59:47,936-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-15 03:59:49,352-main.py:465-INFO- ------------------------------------------------------------------
2025-05-15 03:59:49,354-main.py:466-INFO- * Speed: 168.03402 ms/iter
2025-05-15 03:59:49,355-main.py:467-INFO- * MAPE: 0.38492
2025-05-15 03:59:49,357-main.py:468-INFO- * ErrorBound: [0.125 0.    0.   ]
2025-05-15 03:59:49,358-main.py:469-INFO- * Kendall's Tau: 0.4999999999999999
2025-05-15 03:59:49,359-main.py:470-INFO- ------------------------------------------------------------------
2025-05-15 03:59:49,361-main.py:473-INFO- Average Latency : 163.90916705 ms
2025-05-15 09:47:12,674-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-15 09:47:12,675-main.py:76-INFO-Loading dataset:
2025-05-15 09:47:15,494-main.py:274-INFO-Train data = 1, Test data = 9
2025-05-15 09:47:16,910-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-15 09:47:16,910-main.py:109-INFO-Loading model:
2025-05-15 09:47:16,912-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-15 09:47:16,934-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-15 09:47:17,972-main.py:465-INFO- ------------------------------------------------------------------
2025-05-15 09:47:17,972-main.py:466-INFO- * Speed: 97.25049 ms/iter
2025-05-15 09:47:17,972-main.py:467-INFO- * MAPE: 0.49765
2025-05-15 09:47:17,972-main.py:468-INFO- * ErrorBound: [0.11111111 0.         0.        ]
2025-05-15 09:47:17,972-main.py:469-INFO- * Kendall's Tau: 0.2222222222222222
2025-05-15 09:47:17,973-main.py:470-INFO- ------------------------------------------------------------------
2025-05-15 09:47:17,973-main.py:473-INFO- Average Latency : 94.25046709 ms
2025-05-23 11:31:53,367-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 11:31:53,368-main.py:76-INFO-Loading dataset:
2025-05-23 11:31:53,404-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-23 11:32:14,919-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 11:32:14,920-main.py:76-INFO-Loading dataset:
2025-05-23 11:32:14,955-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-23 11:55:24,530-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 11:55:24,531-main.py:76-INFO-Loading dataset:
2025-05-23 11:55:24,590-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-23 12:03:31,602-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 12:03:31,603-main.py:76-INFO-Loading dataset:
2025-05-23 12:03:31,649-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-23 12:03:58,706-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 12:03:58,706-main.py:76-INFO-Loading dataset:
2025-05-23 12:03:58,743-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-23 12:21:55,023-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 12:21:55,024-main.py:76-INFO-Loading dataset:
2025-05-23 12:21:55,062-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-23 12:30:44,209-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 12:30:44,209-main.py:76-INFO-Loading dataset:
2025-05-23 12:30:44,255-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-23 12:41:25,743-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-23 12:41:25,743-main.py:76-INFO-Loading dataset:
2025-05-23 12:41:25,790-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 17:43:24,933-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 17:43:24,933-main.py:76-INFO-Loading dataset:
2025-05-25 17:43:24,945-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 18:13:14,792-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 18:13:14,792-main.py:76-INFO-Loading dataset:
2025-05-25 18:13:14,801-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 18:13:55,690-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 18:13:55,690-main.py:76-INFO-Loading dataset:
2025-05-25 18:13:55,725-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 18:47:02,746-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 18:47:02,746-main.py:76-INFO-Loading dataset:
2025-05-25 18:47:02,753-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 18:47:55,261-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 18:47:55,261-main.py:76-INFO-Loading dataset:
2025-05-25 18:47:55,267-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 18:49:25,703-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 18:49:25,704-main.py:76-INFO-Loading dataset:
2025-05-25 18:49:25,712-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 18:55:16,806-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 18:55:16,806-main.py:76-INFO-Loading dataset:
2025-05-25 18:55:16,819-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-25 18:57:45,304-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 18:57:45,306-main.py:76-INFO-Loading dataset:
2025-05-25 18:57:45,328-main.py:274-INFO-Train data = 1, Test data = 1
2025-05-25 18:57:46,821-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-25 18:57:46,822-main.py:109-INFO-Loading model:
2025-05-25 18:57:46,826-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-25 18:57:46,848-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-25 18:57:47,883-main.py:465-INFO- ------------------------------------------------------------------
2025-05-25 18:57:47,883-main.py:466-INFO- * Speed: 888.01622 ms/iter
2025-05-25 18:57:47,884-main.py:467-INFO- * MAPE: 0.42869
2025-05-25 18:57:47,884-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-25 18:57:47,885-main.py:469-INFO- * Kendall's Tau: nan
2025-05-25 18:57:47,885-main.py:470-INFO- ------------------------------------------------------------------
2025-05-25 18:57:47,885-main.py:473-INFO- Average Latency : 873.06618690 ms
2025-05-25 20:12:07,163-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 20:12:07,163-main.py:76-INFO-Loading dataset:
2025-05-25 20:12:07,197-main.py:274-INFO-Train data = 1, Test data = 1
2025-05-25 20:12:08,223-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-25 20:12:08,224-main.py:109-INFO-Loading model:
2025-05-25 20:12:08,227-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-25 20:12:08,235-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-25 20:12:08,716-main.py:465-INFO- ------------------------------------------------------------------
2025-05-25 20:12:08,716-main.py:466-INFO- * Speed: 415.01760 ms/iter
2025-05-25 20:12:08,716-main.py:467-INFO- * MAPE: 0.42869
2025-05-25 20:12:08,716-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-25 20:12:08,716-main.py:469-INFO- * Kendall's Tau: nan
2025-05-25 20:12:08,717-main.py:470-INFO- ------------------------------------------------------------------
2025-05-25 20:12:08,717-main.py:473-INFO- Average Latency : 412.02640533 ms
2025-05-25 20:13:02,270-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 20:13:02,270-main.py:76-INFO-Loading dataset:
2025-05-25 20:13:02,307-main.py:274-INFO-Train data = 1, Test data = 2
2025-05-25 20:13:03,219-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-25 20:13:03,220-main.py:109-INFO-Loading model:
2025-05-25 20:13:03,224-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-25 20:13:03,232-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-25 20:13:03,739-main.py:465-INFO- ------------------------------------------------------------------
2025-05-25 20:13:03,739-main.py:466-INFO- * Speed: 220.16168 ms/iter
2025-05-25 20:13:03,739-main.py:467-INFO- * MAPE: 1.45002
2025-05-25 20:13:03,740-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-25 20:13:03,740-main.py:469-INFO- * Kendall's Tau: -1.0
2025-05-25 20:13:03,740-main.py:470-INFO- ------------------------------------------------------------------
2025-05-25 20:13:03,740-main.py:473-INFO- Average Latency : 217.16558933 ms
2025-05-25 20:16:07,725-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 20:16:07,725-main.py:76-INFO-Loading dataset:
2025-05-25 20:16:07,758-main.py:274-INFO-Train data = 1, Test data = 3
2025-05-25 20:16:08,642-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-25 20:16:08,643-main.py:109-INFO-Loading model:
2025-05-25 20:16:08,648-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-25 20:16:08,657-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-25 20:16:09,179-main.py:465-INFO- ------------------------------------------------------------------
2025-05-25 20:16:09,179-main.py:466-INFO- * Speed: 152.56111 ms/iter
2025-05-25 20:16:09,179-main.py:467-INFO- * MAPE: 2.27293
2025-05-25 20:16:09,179-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-25 20:16:09,179-main.py:469-INFO- * Kendall's Tau: -0.33333333333333337
2025-05-25 20:16:09,180-main.py:470-INFO- ------------------------------------------------------------------
2025-05-25 20:16:09,180-main.py:473-INFO- Average Latency : 150.56777000 ms
2025-05-25 20:29:27,304-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 20:29:27,304-main.py:76-INFO-Loading dataset:
2025-05-25 20:29:27,343-main.py:274-INFO-Train data = 0, Test data = 2
2025-05-25 20:30:52,375-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-25 20:30:52,375-main.py:76-INFO-Loading dataset:
2025-05-25 20:30:52,421-main.py:274-INFO-Train data = 0, Test data = 2
2025-05-27 05:52:48,876-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-27 05:52:48,877-main.py:76-INFO-Loading dataset:
2025-05-27 05:52:49,140-main.py:274-INFO-Train data = 1, Test data = 4
2025-05-27 05:52:50,777-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-27 05:52:50,777-main.py:109-INFO-Loading model:
2025-05-27 05:52:50,778-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-27 05:52:50,803-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-27 05:52:51,879-main.py:465-INFO- ------------------------------------------------------------------
2025-05-27 05:52:51,880-main.py:466-INFO- * Speed: 229.94095 ms/iter
2025-05-27 05:52:51,880-main.py:467-INFO- * MAPE: 4.62860
2025-05-27 05:52:51,880-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-27 05:52:51,880-main.py:469-INFO- * Kendall's Tau: -0.6666666666666669
2025-05-27 05:52:51,881-main.py:470-INFO- ------------------------------------------------------------------
2025-05-27 05:52:51,881-main.py:473-INFO- Average Latency : 222.44089842 ms
2025-05-27 06:12:50,242-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-27 06:12:50,243-main.py:76-INFO-Loading dataset:
2025-05-27 06:12:50,477-main.py:274-INFO-Train data = 1, Test data = 4
2025-05-27 06:12:51,416-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-27 06:12:51,416-main.py:109-INFO-Loading model:
2025-05-27 06:12:51,417-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-27 06:12:51,424-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-27 06:12:51,907-main.py:465-INFO- ------------------------------------------------------------------
2025-05-27 06:12:51,907-main.py:466-INFO- * Speed: 104.95853 ms/iter
2025-05-27 06:12:51,907-main.py:467-INFO- * MAPE: 3.75776
2025-05-27 06:12:51,907-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-27 06:12:51,907-main.py:469-INFO- * Kendall's Tau: 0.0
2025-05-27 06:12:51,907-main.py:470-INFO- ------------------------------------------------------------------
2025-05-27 06:12:51,907-main.py:473-INFO- Average Latency : 103.95842791 ms
2025-05-27 19:02:14,969-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-27 19:02:14,970-main.py:76-INFO-Loading dataset:
2025-05-27 19:02:14,976-main.py:274-INFO-Train data = 0, Test data = 0
2025-05-27 19:03:57,115-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-27 19:03:57,115-main.py:76-INFO-Loading dataset:
2025-05-27 19:03:57,481-main.py:274-INFO-Train data = 0, Test data = 9
2025-05-27 19:04:17,470-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-27 19:04:17,470-main.py:76-INFO-Loading dataset:
2025-05-27 19:04:17,866-main.py:274-INFO-Train data = 1, Test data = 9
2025-05-27 19:04:19,375-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-27 19:04:19,375-main.py:109-INFO-Loading model:
2025-05-27 19:04:19,376-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-27 19:04:19,398-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-27 19:04:20,481-main.py:465-INFO- ------------------------------------------------------------------
2025-05-27 19:04:20,481-main.py:466-INFO- * Speed: 104.50949 ms/iter
2025-05-27 19:04:20,481-main.py:467-INFO- * MAPE: 0.65133
2025-05-27 19:04:20,482-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-27 19:04:20,482-main.py:469-INFO- * Kendall's Tau: 0.16666666666666666
2025-05-27 19:04:20,482-main.py:470-INFO- ------------------------------------------------------------------
2025-05-27 19:04:20,482-main.py:473-INFO- Average Latency : 100.95450613 ms
2025-05-28 12:32:46,534-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/lama.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 12:32:46,534-main.py:76-INFO-Loading dataset:
2025-05-28 12:32:46,750-main.py:274-INFO-Train data = 1, Test data = 9
2025-05-28 12:32:48,225-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 12:32:48,226-main.py:109-INFO-Loading model:
2025-05-28 12:32:48,227-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 12:32:48,251-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 12:32:49,172-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 12:32:49,173-main.py:466-INFO- * Speed: 86.68545 ms/iter
2025-05-28 12:32:49,173-main.py:467-INFO- * MAPE: 0.56664
2025-05-28 12:32:49,173-main.py:468-INFO- * ErrorBound: [0.11111111 0.11111111 0.        ]
2025-05-28 12:32:49,173-main.py:469-INFO- * Kendall's Tau: -0.1111111111111111
2025-05-28 12:32:49,173-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 12:32:49,174-main.py:473-INFO- Average Latency : 83.69541168 ms
2025-05-28 12:41:40,558-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 12:41:40,558-main.py:76-INFO-Loading dataset:
2025-05-28 12:41:40,805-main.py:274-INFO-Train data = 1, Test data = 5
2025-05-28 12:41:41,699-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 12:41:41,700-main.py:109-INFO-Loading model:
2025-05-28 12:41:41,700-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 12:41:41,708-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 12:41:42,171-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 12:41:42,171-main.py:466-INFO- * Speed: 78.93600 ms/iter
2025-05-28 12:41:42,171-main.py:467-INFO- * MAPE: 4.86474
2025-05-28 12:41:42,172-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 12:41:42,172-main.py:469-INFO- * Kendall's Tau: -0.39999999999999997
2025-05-28 12:41:42,172-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 12:41:42,172-main.py:473-INFO- Average Latency : 77.34103203 ms
2025-05-28 12:59:42,543-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 12:59:42,543-main.py:76-INFO-Loading dataset:
2025-05-28 12:59:42,771-main.py:274-INFO-Train data = 1, Test data = 5
2025-05-28 12:59:43,641-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 12:59:43,641-main.py:109-INFO-Loading model:
2025-05-28 12:59:43,642-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 12:59:43,649-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 12:59:44,105-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 12:59:44,105-main.py:466-INFO- * Speed: 79.18000 ms/iter
2025-05-28 12:59:44,106-main.py:467-INFO- * MAPE: 4.86474
2025-05-28 12:59:44,106-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 12:59:44,106-main.py:469-INFO- * Kendall's Tau: -0.39999999999999997
2025-05-28 12:59:44,106-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 12:59:44,106-main.py:473-INFO- Average Latency : 77.78472900 ms
2025-05-28 13:00:57,373-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 13:00:57,374-main.py:76-INFO-Loading dataset:
2025-05-28 13:00:57,418-main.py:274-INFO-Train data = 1, Test data = 6
2025-05-28 13:00:58,287-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 13:00:58,287-main.py:109-INFO-Loading model:
2025-05-28 13:00:58,288-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:00:58,295-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:00:58,751-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 13:00:58,751-main.py:466-INFO- * Speed: 65.83548 ms/iter
2025-05-28 13:00:58,751-main.py:467-INFO- * MAPE: 5.56732
2025-05-28 13:00:58,751-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 13:00:58,751-main.py:469-INFO- * Kendall's Tau: -0.06666666666666665
2025-05-28 13:00:58,752-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 13:00:58,752-main.py:473-INFO- Average Latency : 64.17381763 ms
2025-05-28 13:13:09,444-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 13:13:09,444-main.py:76-INFO-Loading dataset:
2025-05-28 13:13:09,726-main.py:274-INFO-Train data = 1, Test data = 7
2025-05-28 13:13:10,597-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 13:13:10,598-main.py:109-INFO-Loading model:
2025-05-28 13:13:10,599-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:13:10,605-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:13:11,064-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 13:13:11,064-main.py:466-INFO- * Speed: 56.69086 ms/iter
2025-05-28 13:13:11,065-main.py:467-INFO- * MAPE: 6.56155
2025-05-28 13:13:11,065-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 13:13:11,065-main.py:469-INFO- * Kendall's Tau: -0.14285714285714288
2025-05-28 13:13:11,065-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 13:13:11,065-main.py:473-INFO- Average Latency : 55.40936334 ms
2025-05-28 13:23:54,169-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 13:23:54,170-main.py:76-INFO-Loading dataset:
2025-05-28 13:23:54,500-main.py:274-INFO-Train data = 1, Test data = 8
2025-05-28 13:23:55,363-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 13:23:55,363-main.py:109-INFO-Loading model:
2025-05-28 13:23:55,364-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:23:55,371-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:23:55,836-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 13:23:55,836-main.py:466-INFO- * Speed: 50.22895 ms/iter
2025-05-28 13:23:55,836-main.py:467-INFO- * MAPE: 7.23321
2025-05-28 13:23:55,836-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 13:23:55,837-main.py:469-INFO- * Kendall's Tau: -0.14285714285714285
2025-05-28 13:23:55,837-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 13:23:55,837-main.py:473-INFO- Average Latency : 49.10770059 ms
2025-05-28 13:50:30,407-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 13:50:30,407-main.py:76-INFO-Loading dataset:
2025-05-28 13:50:30,685-main.py:274-INFO-Train data = 1, Test data = 7
2025-05-28 13:50:31,574-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 13:50:31,575-main.py:109-INFO-Loading model:
2025-05-28 13:50:31,576-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:50:31,582-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 13:50:32,056-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 13:50:32,056-main.py:466-INFO- * Speed: 58.91391 ms/iter
2025-05-28 13:50:32,056-main.py:467-INFO- * MAPE: 6.20244
2025-05-28 13:50:32,056-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 13:50:32,056-main.py:469-INFO- * Kendall's Tau: 0.14285714285714288
2025-05-28 13:50:32,057-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 13:50:32,057-main.py:473-INFO- Average Latency : 57.49007634 ms
2025-05-28 14:56:11,470-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 14:56:11,470-main.py:76-INFO-Loading dataset:
2025-05-28 14:56:11,788-main.py:274-INFO-Train data = 1, Test data = 7
2025-05-28 14:56:12,692-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 14:56:12,693-main.py:109-INFO-Loading model:
2025-05-28 14:56:12,694-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 14:56:12,700-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 14:56:13,176-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 14:56:13,176-main.py:466-INFO- * Speed: 58.84906 ms/iter
2025-05-28 14:56:13,176-main.py:467-INFO- * MAPE: 6.20244
2025-05-28 14:56:13,176-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 14:56:13,176-main.py:469-INFO- * Kendall's Tau: 0.14285714285714288
2025-05-28 14:56:13,176-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 14:56:13,177-main.py:473-INFO- Average Latency : 57.71006857 ms
2025-05-28 14:58:25,568-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 14:58:25,568-main.py:76-INFO-Loading dataset:
2025-05-28 14:58:25,849-main.py:274-INFO-Train data = 1, Test data = 7
2025-05-28 14:58:26,725-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 14:58:26,725-main.py:109-INFO-Loading model:
2025-05-28 14:58:26,726-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 14:58:26,732-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 14:58:27,209-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 14:58:27,209-main.py:466-INFO- * Speed: 58.97014 ms/iter
2025-05-28 14:58:27,210-main.py:467-INFO- * MAPE: 6.20244
2025-05-28 14:58:27,210-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 14:58:27,210-main.py:469-INFO- * Kendall's Tau: 0.14285714285714288
2025-05-28 14:58:27,210-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 14:58:27,210-main.py:473-INFO- Average Latency : 57.68867901 ms
2025-05-28 15:12:47,148-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 15:12:47,149-main.py:76-INFO-Loading dataset:
2025-05-28 15:12:47,478-main.py:274-INFO-Train data = 1, Test data = 8
2025-05-28 15:12:48,354-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 15:12:48,355-main.py:109-INFO-Loading model:
2025-05-28 15:12:48,355-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 15:12:48,362-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 15:12:48,850-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 15:12:48,850-main.py:466-INFO- * Speed: 53.24331 ms/iter
2025-05-28 15:12:48,850-main.py:467-INFO- * MAPE: 5.76113
2025-05-28 15:12:48,851-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 15:12:48,851-main.py:469-INFO- * Kendall's Tau: 0.3571428571428571
2025-05-28 15:12:48,851-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 15:12:48,851-main.py:473-INFO- Average Latency : 51.25004053 ms
2025-05-28 15:49:06,898-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 15:49:06,898-main.py:76-INFO-Loading dataset:
2025-05-28 15:49:07,371-main.py:274-INFO-Train data = 1, Test data = 8
2025-05-28 15:49:08,247-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 15:49:08,247-main.py:109-INFO-Loading model:
2025-05-28 15:49:08,248-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 15:49:08,254-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 15:49:08,786-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 15:49:08,786-main.py:466-INFO- * Speed: 58.33772 ms/iter
2025-05-28 15:49:08,786-main.py:467-INFO- * MAPE: 0.72087
2025-05-28 15:49:08,787-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 15:49:08,787-main.py:469-INFO- * Kendall's Tau: -0.2857142857142857
2025-05-28 15:49:08,787-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 15:49:08,787-main.py:473-INFO- Average Latency : 55.72119355 ms
2025-05-28 16:39:23,836-main.py:69-INFO-Loading args: 
Namespace(all_latency_file='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/help.txt', batch_size=1, ckpt_save_freq=1000, data_root='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure/data', dataset='nnlqp', embed_type='trans', epochs=100, feat_shuffle=False, ffn_ratio=4, glt_norm='LN', gpu=0, hidden_size=512, lambda_cons=0, lambda_sr=0, log='log/test.log', lr=0.001, model_dir=None, multires_p=0, multires_x=0, n_attned_gnn=2, norm_sf=True, num_node_features=152, only_test=True, onnx_dir='D:/NAR/NAR-Former-V2-main/NAR-Former-V2-main/dataset/unseen_structure', optype='onehot', override_data=False, pretrain='checkpoints/ckpt_best.pth', print_freq=50, resume=None, test_freq=1, test_model_type=None, train_model_types=None, train_num=-1, train_test_stage=True, use_degree=True, warmup_rate=0.1)
2025-05-28 16:39:23,837-main.py:76-INFO-Loading dataset:
2025-05-28 16:39:24,702-main.py:274-INFO-Train data = 1, Test data = 15
2025-05-28 16:39:25,581-main.py:101-INFO-Init Model: Net(
  (gnn_layers): ModuleList(
    (0): GNN_LinearAttn(
      (lin_l): Linear(152, 512, bias=True)
      (lin_r): Linear(152, 512, bias=False)
      (lin_d): Linear(1, 152, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(152, 152, bias=True)
      (sigmoid_qk): Sigmoid()
    )
    (1): GNN_LinearAttn(
      (lin_l): Linear(512, 512, bias=True)
      (lin_r): Linear(512, 512, bias=False)
      (lin_d): Linear(1, 512, bias=True)
      (sigmoid_d): Sigmoid()
      (lin_qk): Linear(512, 512, bias=True)
      (sigmoid_qk): Sigmoid()
    )
  )
  (gnn_drops): ModuleList(
    (0): Dropout(p=0.05, inplace=False)
    (1): Dropout(p=0.05, inplace=False)
  )
  (gnn_relus): ModuleList(
    (0): ReLU()
    (1): ReLU()
  )
  (FFN_layers): ModuleList(
    (0): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
    (1): PreNorm(
      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      (fn): GroupedFeedForward(
        (net): Sequential(
          (0): GroupLinear(
            (normalization_fn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (1): ReLU()
          (2): Dropout(p=0.05, inplace=False)
          (3): GroupLinear(
            (normalization_fn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (4): Dropout(p=0.05, inplace=False)
        )
      )
    )
  )
  (layer_scale): ParameterList(
      (0): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
      (1): Parameter containing: [torch.cuda.FloatTensor of size 512 (GPU 0)]
  )
  (norm_sf_linear): Linear(in_features=40, out_features=512, bias=True)
  (norm_sf_drop): Dropout(p=0.05, inplace=False)
  (norm_sf_relu): ReLU()
  (fc_1): Linear(in_features=1024, out_features=512, bias=True)
  (fc_2): Linear(in_features=512, out_features=512, bias=True)
  (fc_drop_1): Dropout(p=0.05, inplace=False)
  (fc_drop_2): Dropout(p=0.05, inplace=False)
  (fc_relu1): ReLU()
  (fc_relu2): ReLU()
  (predictor): Linear(in_features=512, out_features=1, bias=True)
)
2025-05-28 16:39:25,582-main.py:109-INFO-Loading model:
2025-05-28 16:39:25,583-main.py:287-INFO-Loading pretrain: checkpoints/ckpt_best.pth
2025-05-28 16:39:25,589-main.py:290-INFO-Loaded pretrain: checkpoints/ckpt_best.pth
2025-05-28 16:39:26,198-main.py:465-INFO- ------------------------------------------------------------------
2025-05-28 16:39:26,198-main.py:466-INFO- * Speed: 35.95956 ms/iter
2025-05-28 16:39:26,198-main.py:467-INFO- * MAPE: 1.40693
2025-05-28 16:39:26,198-main.py:468-INFO- * ErrorBound: [0. 0. 0.]
2025-05-28 16:39:26,199-main.py:469-INFO- * Kendall's Tau: 0.0
2025-05-28 16:39:26,199-main.py:470-INFO- ------------------------------------------------------------------
2025-05-28 16:39:26,199-main.py:473-INFO- Average Latency : 33.36793582 ms
